{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 23:07:53.045103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 23:07:53.232473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-19 23:07:53.232516: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-19 23:07:54.132442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-19 23:07:54.132545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-19 23:07:54.132557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3693092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Long2</th>\n",
       "      <th>Lat2</th>\n",
       "      <th>Long1</th>\n",
       "      <th>Lat1</th>\n",
       "      <th>Mid_lat</th>\n",
       "      <th>Mid_long</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Paving_future</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.776925</td>\n",
       "      <td>37.777377</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tile_ID       Long2       Lat2       Long1       Lat1    Mid_lat  \\\n",
       "0       36 -122.514446  37.779636 -122.513306  37.778732  37.779184   \n",
       "1       37 -122.514446  37.778732 -122.513306  37.777829  37.778280   \n",
       "2      151 -122.513306  37.779636 -122.512166  37.778732  37.779184   \n",
       "3      152 -122.513306  37.778732 -122.512166  37.777829  37.778280   \n",
       "4      153 -122.513306  37.777829 -122.512166  37.776925  37.777377   \n",
       "\n",
       "     Mid_long  Stop_Signs  Paving_historical  Paving_future  ...  94129  \\\n",
       "0 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "1 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "2 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "3 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "4 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "\n",
       "   94130  94131 94132  94133  94134  94141  94143  94158  94188  \n",
       "0      0      0     0      0      0      0      0      0      0  \n",
       "1      0      0     0      0      0      0      0      0      0  \n",
       "2      0      0     0      0      0      0      0      0      0  \n",
       "3      0      0     0      0      0      0      0      0      0  \n",
       "4      0      0     0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = pd.read_csv(r'./Data/Tiles_binned_zipcode.csv')\n",
    "tiles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f0a51-0215-441f-ba8b-b128c308a998",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/66227003/reverse-geocoding-getting-postal-code-with-geopy-nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a2f0db-5324-4813-939d-1d1179dc68e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #!pip3 install geopy\n",
    "# import geopy\n",
    "# import pandas as pd\n",
    "\n",
    "# def get_zipcode(df, geolocator, lat_field, lon_field, attempt=1, max_attempts=100):\n",
    "#     try:\n",
    "#         location = geolocator.reverse((df[lat_field], df[lon_field]), timeout=None)\n",
    "#         return location.raw['address']['postcode']\n",
    "#     except KeyError:\n",
    "#         pass\n",
    "#     except GeocoderTimedOut:\n",
    "#         if attempt <= max_attempts:\n",
    "#             return get_zipcode (df, attempt=attempt+1)\n",
    "#         raise\n",
    "\n",
    "# geolocator = geopy.Nominatim(user_agent='1234')\n",
    "# #geolocator = geopy.Nominatim(user_agent='my-application')\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'Lat': [29.39291, 29.39923, 29.40147, 29.38752, 29.39291, 29.39537, 29.39343, 29.39291, 29.39556],\n",
    "#     'Lon': [-98.50925, -98.51256, -98.51123, -98.52372, -98.50925, -98.50402, -98.49707, -98.50925, -98.53148]\n",
    "# })\n",
    "# zipcodes = df.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='Lat', lon_field='Lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d87604-d12c-4d93-b51a-9826e685a36d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6add420-44cd-4a32-9bcb-6a1f974c8cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#zipcodes1 = tiles.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='Lat1', lon_field='Long1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "939c20e8-e1c1-44d5-93e6-8e8f58280f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#zipcodes2 = tiles.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='Lat2', lon_field='Long2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07133d32-9ab7-4145-8b10-a320db87cd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#zipcodes3 = tiles.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='Mid_lat', lon_field='Mid_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e18162b-88f8-4b5d-b4c1-e7bd9c3ca7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
       "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
       "       'Collisions_Future', 'Collisions_Historical', 'bin', 'RTTYP_I',\n",
       "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
       "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
       "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
       "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
       "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
       "       '94134', '94141', '94143', '94158', '94188'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tiles[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I',\n",
    "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']], \n",
    "                                   tiles['bin'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61669640-63d0-4b53-82ae-15849f63e67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eda\n",
    "img = tifffile.imread('../210_Capstone_Aditya_Arisa_Noriel/Satellite Imagery/Satellite Images Tiled/36.tif')[0:148, 0:188, :]\n",
    "img2 = tifffile.imread('../210_Capstone_Aditya_Arisa_Noriel/Satellite Imagery/Satellite Images Tiled/37.tif')[0:148, 0:188, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "346c181d-0bbf-4cb6-a88b-9f8d406932cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 188, 4)\n"
     ]
    }
   ],
   "source": [
    "# eda\n",
    "print(np.shape(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a56357e-96a0-4f1c-b20e-f649146b5458",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 148, 188, 4)\n",
      "(2, 148, 188, 4)\n"
     ]
    }
   ],
   "source": [
    "# eda\n",
    "test = []\n",
    "test.append(img[0:148, 0:188, :])\n",
    "test.append(img2[0:148, 0:188, :])\n",
    "print(np.shape(test))\n",
    "test = np.stack(test)\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58158eed-8426-483f-9986-2bcf254a1d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[185., 177., 160., 130.],\n",
       "        [184., 178., 161., 130.],\n",
       "        [184., 178., 160., 130.],\n",
       "        ...,\n",
       "        [105., 108.,  70., 173.],\n",
       "        [117., 117.,  82., 166.],\n",
       "        [112., 126.,  76., 182.]],\n",
       "\n",
       "       [[184., 178., 161., 131.],\n",
       "        [184., 178., 160., 130.],\n",
       "        [183., 177., 159., 129.],\n",
       "        ...,\n",
       "        [104., 108.,  71., 173.],\n",
       "        [113., 115.,  80., 163.],\n",
       "        [110., 123.,  76., 177.]],\n",
       "\n",
       "       [[183., 178., 159., 128.],\n",
       "        [183., 177., 159., 127.],\n",
       "        [183., 177., 159., 127.],\n",
       "        ...,\n",
       "        [101., 110.,  71., 170.],\n",
       "        [109., 116.,  77., 168.],\n",
       "        [110., 124.,  78., 179.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[141., 131., 103.,  53.],\n",
       "        [142., 131., 102.,  56.],\n",
       "        [148., 139., 108.,  62.],\n",
       "        ...,\n",
       "        [ 72.,  88.,  51., 101.],\n",
       "        [ 78.,  92.,  54., 109.],\n",
       "        [ 82.,  97.,  56., 116.]],\n",
       "\n",
       "       [[138., 130., 100.,  52.],\n",
       "        [140., 131., 101.,  54.],\n",
       "        [146., 136., 107.,  60.],\n",
       "        ...,\n",
       "        [ 71.,  85.,  51.,  95.],\n",
       "        [ 73.,  86.,  51.,  97.],\n",
       "        [ 71.,  85.,  52.,  93.]],\n",
       "\n",
       "       [[137., 129., 100.,  51.],\n",
       "        [139., 130.,  99.,  53.],\n",
       "        [141., 132., 103.,  57.],\n",
       "        ...,\n",
       "        [ 72.,  89.,  52., 106.],\n",
       "        [ 70.,  86.,  49., 101.],\n",
       "        [ 66.,  81.,  49.,  91.]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c7fe3ce-ba01-430b-9617-08ba2e611f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([185., 177., 160., 130.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2ad3db-b629-4b90-8fc4-cbd988e23a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([174., 130.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.mean(img[0][0][0:3]),img[0][0][3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1585ab58-1dda-4a29-8039-3e916df8fce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[174.      , 130.      ],\n",
       "       [174.33333 , 130.      ],\n",
       "       [174.      , 130.      ],\n",
       "       ...,\n",
       "       [ 71.      , 106.      ],\n",
       "       [ 68.333336, 101.      ],\n",
       "       [ 65.333336,  91.      ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_color = []\n",
    "for i in img:\n",
    "    for j in i:\n",
    "        img_color.append([np.mean(j[0:3]),j[3]])\n",
    "np.array(img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        for i in img:\n",
    "            for j in i:\n",
    "                data_mini.append([np.mean(j[0:3]),j[3]])\n",
    "                \n",
    "        #image = np.array(img_color)\n",
    "            \n",
    "        # append to images\n",
    "        #data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mini = preprocess_data_part1(IMAGE_PATH)\n",
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23790420-0c98-426f-8580-23f7d96e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part2(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        image = [np.mean(image[:3]), image[3]]\n",
    "        \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc8e3f65-2368-4092-9b09-ecda4e0a35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/capstone/lib/python3.10/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2095, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_t = preprocess_data_part2(IMAGE_PATH)\n",
    "np.shape(images_mini_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "399c28ed-448c-400c-99e9-5abf4acba2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.array([1,2,3,4])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f47ddf05-6f0d-4293-948c-cc3c0215a260",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82.35904, array([[116.,  94.,  67., 115.],\n",
       "                         [113.,  93.,  68., 128.],\n",
       "                         [ 96.,  91.,  62., 143.],\n",
       "                         [ 89.,  98.,  59., 159.],\n",
       "                         [ 87., 101.,  60., 174.],\n",
       "                         [ 89., 112.,  60., 182.],\n",
       "                         [ 81., 113.,  56., 185.],\n",
       "                         [ 69., 104.,  50., 184.],\n",
       "                         [ 67.,  98.,  48., 184.],\n",
       "                         [ 69., 101.,  47., 188.],\n",
       "                         [ 74., 108.,  48., 191.],\n",
       "                         [ 70., 102.,  46., 192.],\n",
       "                         [ 67., 101.,  46., 188.],\n",
       "                         [ 59.,  83.,  43., 171.],\n",
       "                         [ 67.,  90.,  44., 178.],\n",
       "                         [ 70.,  98.,  44., 186.],\n",
       "                         [ 62.,  93.,  43., 184.],\n",
       "                         [ 62.,  91.,  44., 185.],\n",
       "                         [ 65.,  92.,  42., 183.],\n",
       "                         [ 61.,  85.,  42., 183.],\n",
       "                         [ 58.,  82.,  43., 178.],\n",
       "                         [ 53.,  75.,  40., 156.],\n",
       "                         [ 71.,  93.,  45., 170.],\n",
       "                         [ 74., 100.,  48., 178.],\n",
       "                         [ 67.,  98.,  48., 173.],\n",
       "                         [ 73., 104.,  50., 175.],\n",
       "                         [ 81., 109.,  52., 180.],\n",
       "                         [ 76., 103.,  48., 173.],\n",
       "                         [ 69.,  99.,  49., 173.],\n",
       "                         [ 71.,  91.,  48., 164.],\n",
       "                         [ 78., 101.,  49., 163.],\n",
       "                         [ 81., 105.,  51., 167.],\n",
       "                         [ 80., 105.,  54., 168.],\n",
       "                         [ 77., 104.,  54., 167.],\n",
       "                         [ 78., 100.,  51., 167.],\n",
       "                         [ 78., 100.,  51., 171.],\n",
       "                         [ 75., 101.,  51., 163.],\n",
       "                         [ 81., 103.,  54., 169.],\n",
       "                         [ 80., 101.,  54., 168.],\n",
       "                         [ 79., 100.,  53., 160.],\n",
       "                         [ 82., 102.,  55., 157.],\n",
       "                         [ 81., 102.,  57., 151.],\n",
       "                         [ 76.,  98.,  57., 137.],\n",
       "                         [ 77.,  94.,  56., 134.],\n",
       "                         [ 78.,  94.,  55., 138.],\n",
       "                         [ 69.,  87.,  49., 136.],\n",
       "                         [ 62.,  83.,  47., 150.],\n",
       "                         [ 68.,  90.,  47., 162.],\n",
       "                         [ 68.,  89.,  48., 153.],\n",
       "                         [ 67.,  85.,  49., 139.],\n",
       "                         [ 74.,  89.,  50., 143.],\n",
       "                         [ 79.,  94.,  51., 159.],\n",
       "                         [ 72.,  92.,  50., 158.],\n",
       "                         [ 77.,  90.,  50., 149.],\n",
       "                         [ 75.,  88.,  50., 133.],\n",
       "                         [ 79.,  83.,  51., 117.],\n",
       "                         [ 86.,  89.,  55., 123.],\n",
       "                         [ 87.,  96.,  56., 127.],\n",
       "                         [ 84.,  93.,  54., 115.],\n",
       "                         [ 82.,  88.,  55., 104.],\n",
       "                         [ 87.,  93.,  57., 110.],\n",
       "                         [ 90.,  95.,  57., 115.],\n",
       "                         [ 97.,  93.,  58.,  92.],\n",
       "                         [ 93.,  93.,  59.,  90.],\n",
       "                         [ 91.,  91.,  58.,  87.],\n",
       "                         [ 89.,  88.,  55.,  86.],\n",
       "                         [ 90.,  87.,  57.,  84.],\n",
       "                         [ 94.,  91.,  61.,  79.],\n",
       "                         [ 97.,  97.,  62.,  75.],\n",
       "                         [ 91.,  87.,  58.,  75.],\n",
       "                         [ 81.,  78.,  54.,  66.],\n",
       "                         [ 93.,  87.,  58.,  70.],\n",
       "                         [ 86.,  82.,  58.,  62.],\n",
       "                         [ 89.,  85.,  59.,  62.],\n",
       "                         [106.,  99.,  67.,  80.],\n",
       "                         [115., 108.,  73., 101.],\n",
       "                         [113., 106.,  73., 106.],\n",
       "                         [125., 115.,  77., 104.],\n",
       "                         [145., 136., 102., 115.],\n",
       "                         [136., 129.,  98.,  99.],\n",
       "                         [113., 109.,  84.,  67.],\n",
       "                         [110., 109.,  82.,  53.],\n",
       "                         [119., 120.,  92.,  51.],\n",
       "                         [129., 128.,  95.,  72.],\n",
       "                         [131., 126.,  87.,  96.],\n",
       "                         [116., 112.,  77.,  79.],\n",
       "                         [ 94.,  93.,  66.,  52.],\n",
       "                         [100.,  95.,  68.,  62.],\n",
       "                         [106., 106.,  76.,  56.],\n",
       "                         [112., 107.,  74.,  84.],\n",
       "                         [103., 100.,  68.,  92.],\n",
       "                         [ 92.,  92.,  64.,  66.],\n",
       "                         [ 85.,  86.,  60.,  36.],\n",
       "                         [ 76.,  83.,  58.,  24.],\n",
       "                         [ 82.,  91.,  60.,  23.],\n",
       "                         [ 85.,  97.,  63.,  25.],\n",
       "                         [ 88., 103.,  64.,  21.],\n",
       "                         [ 92., 101.,  67.,  26.],\n",
       "                         [ 94.,  97.,  66.,  41.],\n",
       "                         [ 88.,  92.,  63.,  48.],\n",
       "                         [ 86.,  88.,  64.,  44.],\n",
       "                         [ 90.,  90.,  65.,  38.],\n",
       "                         [ 88.,  96.,  65.,  34.],\n",
       "                         [ 95., 109.,  71.,  26.],\n",
       "                         [ 90., 110.,  66.,  16.],\n",
       "                         [ 90., 114.,  66.,  12.],\n",
       "                         [ 90., 116.,  66.,  12.],\n",
       "                         [ 89., 117.,  67.,  12.],\n",
       "                         [ 89., 118.,  66.,  11.],\n",
       "                         [ 90., 118.,  65.,  11.],\n",
       "                         [ 88., 114.,  65.,  13.],\n",
       "                         [ 84., 107.,  68.,  17.],\n",
       "                         [ 83.,  97.,  64.,  25.],\n",
       "                         [ 88.,  95.,  65.,  27.],\n",
       "                         [ 86.,  97.,  66.,  23.],\n",
       "                         [ 87., 100.,  65.,  22.],\n",
       "                         [ 87., 101.,  64.,  17.],\n",
       "                         [ 85., 104.,  64.,  11.],\n",
       "                         [ 87., 109.,  65.,  11.],\n",
       "                         [ 87., 110.,  67.,  15.],\n",
       "                         [ 91., 109.,  68.,  18.],\n",
       "                         [ 85., 109.,  68.,  16.],\n",
       "                         [ 87., 104.,  69.,  19.],\n",
       "                         [ 88., 100.,  66.,  21.],\n",
       "                         [ 91.,  96.,  67.,  28.],\n",
       "                         [ 90.,  93.,  70.,  33.],\n",
       "                         [ 82.,  89.,  70.,  29.],\n",
       "                         [ 75.,  85.,  65.,  22.],\n",
       "                         [ 82.,  92.,  63.,  22.],\n",
       "                         [ 79.,  99.,  65.,  21.],\n",
       "                         [ 90., 106.,  70.,  19.],\n",
       "                         [ 94., 113.,  71.,  17.],\n",
       "                         [ 94., 115.,  69.,  12.],\n",
       "                         [ 95., 120.,  70.,  10.],\n",
       "                         [ 95., 124.,  71.,  10.],\n",
       "                         [ 92., 121.,  68.,   9.],\n",
       "                         [ 93., 120.,  64.,   9.],\n",
       "                         [ 92., 119.,  65.,   9.],\n",
       "                         [ 91., 121.,  65.,   8.],\n",
       "                         [ 91., 120.,  64.,   9.],\n",
       "                         [ 93., 120.,  66.,   9.],\n",
       "                         [ 93., 122.,  67.,   9.],\n",
       "                         [ 94., 122.,  67.,   9.],\n",
       "                         [ 95., 122.,  66.,   9.],\n",
       "                         [ 92., 120.,  66.,   9.],\n",
       "                         [ 94., 122.,  67.,   9.],\n",
       "                         [ 98., 121.,  68.,  10.],\n",
       "                         [104., 133.,  83.,  15.],\n",
       "                         [ 95., 127.,  74.,  11.],\n",
       "                         [ 92., 123.,  66.,  10.],\n",
       "                         [ 92., 123.,  68.,  10.],\n",
       "                         [ 92., 121.,  69.,   9.],\n",
       "                         [ 93., 121.,  66.,   9.],\n",
       "                         [ 93., 124.,  66.,   9.],\n",
       "                         [ 95., 124.,  65.,   9.],\n",
       "                         [ 92., 121.,  66.,   9.],\n",
       "                         [ 94., 122.,  66.,  10.],\n",
       "                         [ 93., 122.,  66.,   9.],\n",
       "                         [ 93., 121.,  66.,   9.],\n",
       "                         [ 96., 123.,  68.,   9.],\n",
       "                         [ 96., 125.,  68.,   8.],\n",
       "                         [ 92., 120.,  65.,   9.],\n",
       "                         [ 91., 121.,  66.,  10.],\n",
       "                         [ 92., 122.,  66.,   9.],\n",
       "                         [ 95., 121.,  66.,   8.],\n",
       "                         [ 92., 121.,  64.,   8.],\n",
       "                         [ 92., 122.,  65.,   9.],\n",
       "                         [ 93., 122.,  66.,   9.],\n",
       "                         [ 91., 120.,  66.,   9.],\n",
       "                         [ 91., 119.,  67.,   8.],\n",
       "                         [ 94., 121.,  68.,   7.],\n",
       "                         [ 91., 121.,  67.,   9.],\n",
       "                         [ 94., 122.,  65.,   8.],\n",
       "                         [ 92., 121.,  66.,   8.],\n",
       "                         [ 93., 120.,  67.,   8.],\n",
       "                         [ 93., 122.,  67.,   8.],\n",
       "                         [ 91., 123.,  66.,   7.],\n",
       "                         [ 91., 121.,  66.,   7.],\n",
       "                         [ 92., 119.,  67.,   8.],\n",
       "                         [ 92., 121.,  67.,   9.],\n",
       "                         [ 95., 123.,  68.,   9.],\n",
       "                         [ 92., 121.,  66.,   7.],\n",
       "                         [ 91., 122.,  67.,   8.],\n",
       "                         [ 91., 121.,  67.,   8.],\n",
       "                         [ 93., 120.,  65.,   7.],\n",
       "                         [ 95., 121.,  64.,   7.],\n",
       "                         [ 93., 120.,  63.,   8.],\n",
       "                         [ 91., 121.,  66.,   8.]], dtype=float32)],\n",
       "       [136.23892, array([[206., 204., 204., 188.],\n",
       "                          [206., 204., 204., 188.],\n",
       "                          [206., 205., 204., 188.],\n",
       "                          [206., 206., 204., 189.],\n",
       "                          [205., 203., 203., 181.],\n",
       "                          [191., 186., 190., 136.],\n",
       "                          [147., 150., 152.,  61.],\n",
       "                          [141., 143., 133.,  52.],\n",
       "                          [142., 142., 129.,  52.],\n",
       "                          [140., 141., 128.,  51.],\n",
       "                          [139., 141., 127.,  51.],\n",
       "                          [138., 141., 127.,  50.],\n",
       "                          [138., 139., 126.,  47.],\n",
       "                          [139., 139., 127.,  48.],\n",
       "                          [139., 138., 127.,  49.],\n",
       "                          [137., 138., 126.,  51.],\n",
       "                          [138., 139., 126.,  49.],\n",
       "                          [138., 140., 126.,  48.],\n",
       "                          [137., 140., 129.,  50.],\n",
       "                          [148., 151., 142.,  64.],\n",
       "                          [160., 158., 150.,  73.],\n",
       "                          [130., 123., 121.,  50.],\n",
       "                          [ 83.,  81.,  84.,  21.],\n",
       "                          [102.,  95.,  87.,  31.],\n",
       "                          [ 95.,  99.,  93.,  30.],\n",
       "                          [119., 123., 109.,  39.],\n",
       "                          [132., 134., 118.,  46.],\n",
       "                          [132., 132., 119.,  47.],\n",
       "                          [132., 131., 119.,  47.],\n",
       "                          [133., 133., 119.,  47.],\n",
       "                          [132., 133., 120.,  46.],\n",
       "                          [132., 133., 119.,  48.],\n",
       "                          [132., 133., 119.,  48.],\n",
       "                          [134., 134., 120.,  48.],\n",
       "                          [134., 134., 121.,  48.],\n",
       "                          [134., 134., 121.,  48.],\n",
       "                          [135., 135., 121.,  48.],\n",
       "                          [135., 135., 121.,  48.],\n",
       "                          [142., 142., 128.,  58.],\n",
       "                          [175., 177., 163., 104.],\n",
       "                          [188., 184., 179., 130.],\n",
       "                          [184., 180., 177., 128.],\n",
       "                          [177., 174., 171., 114.],\n",
       "                          [179., 176., 171., 112.],\n",
       "                          [181., 178., 173., 114.],\n",
       "                          [179., 176., 173., 114.],\n",
       "                          [183., 180., 176., 126.],\n",
       "                          [188., 187., 184., 138.],\n",
       "                          [189., 189., 185., 143.],\n",
       "                          [190., 189., 187., 137.],\n",
       "                          [194., 193., 189., 150.],\n",
       "                          [195., 194., 190., 154.],\n",
       "                          [185., 183., 174., 133.],\n",
       "                          [174., 171., 155., 113.],\n",
       "                          [173., 167., 149., 112.],\n",
       "                          [162., 157., 137.,  94.],\n",
       "                          [165., 167., 131.,  83.],\n",
       "                          [131., 122., 104.,  56.],\n",
       "                          [123., 120., 102.,  55.],\n",
       "                          [130., 123., 105.,  57.],\n",
       "                          [104.,  97.,  92.,  40.],\n",
       "                          [ 91.,  86.,  84.,  30.],\n",
       "                          [122., 114.,  98.,  44.],\n",
       "                          [136., 134., 113.,  55.],\n",
       "                          [146., 143., 121.,  67.],\n",
       "                          [163., 158., 138.,  90.],\n",
       "                          [165., 160., 143.,  90.],\n",
       "                          [156., 151., 133.,  77.],\n",
       "                          [154., 147., 129.,  79.],\n",
       "                          [156., 150., 130.,  85.],\n",
       "                          [154., 151., 129.,  81.],\n",
       "                          [149., 146., 126.,  71.],\n",
       "                          [136., 130., 113.,  56.],\n",
       "                          [ 96.,  93.,  84.,  27.],\n",
       "                          [ 59.,  66.,  62.,  11.],\n",
       "                          [ 56.,  62.,  62.,  10.],\n",
       "                          [ 64.,  67.,  68.,  14.],\n",
       "                          [ 83.,  80.,  77.,  21.],\n",
       "                          [108., 103.,  92.,  33.],\n",
       "                          [128., 128., 111.,  46.],\n",
       "                          [144., 140., 123.,  57.],\n",
       "                          [143., 141., 126.,  56.],\n",
       "                          [141., 139., 125.,  55.],\n",
       "                          [139., 138., 122.,  51.],\n",
       "                          [137., 136., 120.,  49.],\n",
       "                          [137., 136., 121.,  49.],\n",
       "                          [138., 137., 123.,  51.],\n",
       "                          [139., 137., 123.,  52.],\n",
       "                          [139., 138., 123.,  53.],\n",
       "                          [141., 138., 123.,  50.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [140., 138., 123.,  52.],\n",
       "                          [140., 139., 123.,  53.],\n",
       "                          [141., 140., 124.,  54.],\n",
       "                          [142., 139., 124.,  53.],\n",
       "                          [142., 140., 124.,  53.],\n",
       "                          [140., 140., 125.,  52.],\n",
       "                          [142., 140., 127.,  53.],\n",
       "                          [141., 139., 125.,  52.],\n",
       "                          [141., 139., 124.,  51.],\n",
       "                          [140., 138., 124.,  51.],\n",
       "                          [140., 137., 124.,  51.],\n",
       "                          [141., 138., 125.,  52.],\n",
       "                          [142., 140., 126.,  54.],\n",
       "                          [143., 143., 128.,  56.],\n",
       "                          [146., 143., 128.,  59.],\n",
       "                          [148., 146., 130.,  62.],\n",
       "                          [148., 145., 130.,  63.],\n",
       "                          [147., 143., 127.,  62.],\n",
       "                          [147., 144., 127.,  63.],\n",
       "                          [148., 145., 128.,  64.],\n",
       "                          [147., 144., 128.,  63.],\n",
       "                          [146., 143., 126.,  59.],\n",
       "                          [147., 148., 131.,  63.],\n",
       "                          [175., 177., 170., 116.],\n",
       "                          [194., 197., 193., 156.],\n",
       "                          [196., 192., 191., 141.],\n",
       "                          [163., 156., 155.,  87.],\n",
       "                          [150., 147., 135.,  72.],\n",
       "                          [165., 163., 144.,  95.],\n",
       "                          [177., 171., 157., 110.],\n",
       "                          [177., 174., 163., 107.],\n",
       "                          [175., 173., 165.,  98.],\n",
       "                          [177., 174., 164., 110.],\n",
       "                          [171., 168., 155., 102.],\n",
       "                          [166., 161., 145.,  91.],\n",
       "                          [165., 162., 148.,  89.],\n",
       "                          [168., 167., 154.,  90.],\n",
       "                          [168., 166., 151.,  86.],\n",
       "                          [163., 159., 146.,  81.],\n",
       "                          [163., 160., 147.,  82.],\n",
       "                          [164., 162., 148.,  83.],\n",
       "                          [165., 162., 149.,  84.],\n",
       "                          [164., 161., 149.,  85.],\n",
       "                          [166., 164., 153.,  89.],\n",
       "                          [170., 169., 158.,  95.],\n",
       "                          [172., 170., 160.,  98.],\n",
       "                          [173., 169., 158.,  99.],\n",
       "                          [173., 170., 156.,  99.],\n",
       "                          [175., 171., 158., 101.],\n",
       "                          [176., 171., 157., 103.],\n",
       "                          [173., 168., 154.,  97.],\n",
       "                          [171., 166., 153.,  92.],\n",
       "                          [172., 167., 152.,  95.],\n",
       "                          [177., 172., 159., 108.],\n",
       "                          [186., 183., 171., 131.],\n",
       "                          [190., 188., 178., 142.],\n",
       "                          [182., 178., 169., 112.],\n",
       "                          [178., 175., 165., 107.],\n",
       "                          [178., 175., 165., 109.],\n",
       "                          [179., 175., 165., 109.],\n",
       "                          [179., 175., 165., 109.],\n",
       "                          [175., 174., 165., 108.],\n",
       "                          [173., 175., 165., 108.],\n",
       "                          [179., 178., 169., 114.],\n",
       "                          [184., 181., 174., 121.],\n",
       "                          [184., 179., 172., 118.],\n",
       "                          [183., 178., 169., 116.],\n",
       "                          [182., 177., 168., 115.],\n",
       "                          [181., 177., 167., 115.],\n",
       "                          [180., 176., 166., 114.],\n",
       "                          [177., 172., 161., 106.],\n",
       "                          [171., 166., 154.,  93.],\n",
       "                          [165., 161., 148.,  82.],\n",
       "                          [164., 158., 145.,  80.],\n",
       "                          [175., 163., 148., 104.],\n",
       "                          [188., 180., 165., 141.],\n",
       "                          [197., 191., 182., 163.],\n",
       "                          [193., 188., 179., 151.],\n",
       "                          [177., 170., 154., 119.],\n",
       "                          [158., 147., 122.,  90.],\n",
       "                          [148., 130., 103.,  77.],\n",
       "                          [146., 125.,  99.,  74.],\n",
       "                          [160., 140., 119.,  86.],\n",
       "                          [143., 118.,  97.,  68.],\n",
       "                          [144., 116.,  88.,  70.],\n",
       "                          [146., 121.,  90.,  72.],\n",
       "                          [147., 127.,  98.,  75.],\n",
       "                          [149., 131., 106.,  77.],\n",
       "                          [149., 129., 103.,  71.],\n",
       "                          [143., 121.,  92.,  67.],\n",
       "                          [146., 118.,  88.,  68.],\n",
       "                          [146., 117.,  90.,  74.],\n",
       "                          [156., 128., 104.,  80.],\n",
       "                          [148., 124.,  99.,  73.],\n",
       "                          [146., 131., 102.,  74.],\n",
       "                          [171., 165., 142., 115.]], dtype=float32)],\n",
       "       [132.03369, array([[184., 182., 171., 135.],\n",
       "                          [196., 195., 191., 165.],\n",
       "                          [205., 202., 199., 189.],\n",
       "                          [205., 203., 201., 190.],\n",
       "                          [205., 203., 201., 188.],\n",
       "                          [205., 203., 201., 188.],\n",
       "                          [205., 203., 201., 188.],\n",
       "                          [206., 203., 202., 190.],\n",
       "                          [206., 204., 204., 191.],\n",
       "                          [207., 205., 204., 191.],\n",
       "                          [207., 205., 205., 191.],\n",
       "                          [207., 205., 204., 191.],\n",
       "                          [207., 205., 204., 191.],\n",
       "                          [207., 206., 205., 192.],\n",
       "                          [206., 205., 204., 191.],\n",
       "                          [206., 204., 203., 192.],\n",
       "                          [191., 187., 180., 154.],\n",
       "                          [177., 171., 155., 123.],\n",
       "                          [163., 160., 141.,  95.],\n",
       "                          [147., 151., 137.,  65.],\n",
       "                          [162., 161., 148.,  87.],\n",
       "                          [170., 169., 157.,  97.],\n",
       "                          [169., 168., 156.,  96.],\n",
       "                          [170., 167., 155.,  96.],\n",
       "                          [171., 168., 156.,  98.],\n",
       "                          [170., 168., 156.,  98.],\n",
       "                          [169., 167., 155.,  96.],\n",
       "                          [168., 166., 154.,  95.],\n",
       "                          [166., 164., 153.,  92.],\n",
       "                          [164., 163., 152.,  88.],\n",
       "                          [163., 162., 151.,  89.],\n",
       "                          [162., 162., 150.,  88.],\n",
       "                          [158., 160., 148.,  91.],\n",
       "                          [134., 142., 108., 145.],\n",
       "                          [106., 132.,  69., 185.],\n",
       "                          [ 96., 133.,  59., 188.],\n",
       "                          [101., 132.,  67., 179.],\n",
       "                          [111., 132.,  80., 148.],\n",
       "                          [123., 137.,  97., 133.],\n",
       "                          [117., 138.,  91., 139.],\n",
       "                          [134., 142.,  95., 144.],\n",
       "                          [161., 145., 115., 139.],\n",
       "                          [165., 137., 119., 135.],\n",
       "                          [160., 133., 116., 122.],\n",
       "                          [174., 153., 139., 112.],\n",
       "                          [189., 187., 178., 131.],\n",
       "                          [186., 185., 178., 131.],\n",
       "                          [175., 174., 166., 118.],\n",
       "                          [174., 172., 162., 111.],\n",
       "                          [178., 178., 166., 114.],\n",
       "                          [184., 182., 172., 129.],\n",
       "                          [187., 182., 174., 139.],\n",
       "                          [170., 162., 158., 117.],\n",
       "                          [138., 128., 130.,  78.],\n",
       "                          [148., 133., 136., 104.],\n",
       "                          [116., 122., 112., 120.],\n",
       "                          [146., 138., 126., 126.],\n",
       "                          [173., 166., 157., 129.],\n",
       "                          [183., 181., 174., 121.],\n",
       "                          [154., 150., 146.,  74.],\n",
       "                          [114., 110., 105.,  32.],\n",
       "                          [101., 103.,  94.,  32.],\n",
       "                          [102., 102.,  94.,  34.],\n",
       "                          [100., 102.,  92.,  35.],\n",
       "                          [105., 103.,  95.,  36.],\n",
       "                          [115., 123., 111.,  48.],\n",
       "                          [161., 162., 152., 104.],\n",
       "                          [182., 176., 168., 132.],\n",
       "                          [173., 164., 151., 124.],\n",
       "                          [154., 143., 122., 109.],\n",
       "                          [138., 128., 102., 101.],\n",
       "                          [143., 144., 108.,  94.],\n",
       "                          [134., 134., 106.,  87.],\n",
       "                          [135., 135., 110.,  89.],\n",
       "                          [119., 117.,  97.,  72.],\n",
       "                          [ 79.,  79.,  68.,  56.],\n",
       "                          [ 64.,  67.,  56.,  61.],\n",
       "                          [ 77.,  79.,  65.,  64.],\n",
       "                          [ 78.,  78.,  68.,  49.],\n",
       "                          [ 64.,  61.,  55.,  57.],\n",
       "                          [ 65.,  68.,  55.,  70.],\n",
       "                          [ 55.,  61.,  50.,  67.],\n",
       "                          [ 53.,  57.,  48.,  62.],\n",
       "                          [ 52.,  57.,  47.,  64.],\n",
       "                          [ 66.,  67.,  50.,  79.],\n",
       "                          [110., 106.,  87.,  81.],\n",
       "                          [151., 150., 140.,  65.],\n",
       "                          [146., 146., 140.,  55.],\n",
       "                          [133., 137., 128.,  48.],\n",
       "                          [134., 137., 127.,  47.],\n",
       "                          [134., 137., 127.,  48.],\n",
       "                          [134., 137., 125.,  48.],\n",
       "                          [134., 138., 126.,  48.],\n",
       "                          [135., 137., 126.,  47.],\n",
       "                          [132., 134., 123.,  46.],\n",
       "                          [129., 130., 120.,  44.],\n",
       "                          [133., 137., 125.,  46.],\n",
       "                          [134., 137., 124.,  48.],\n",
       "                          [142., 139., 126.,  56.],\n",
       "                          [142., 139., 127.,  57.],\n",
       "                          [146., 140., 126.,  68.],\n",
       "                          [146., 141., 126.,  71.],\n",
       "                          [135., 131., 120.,  52.],\n",
       "                          [115., 113., 107.,  29.],\n",
       "                          [103., 105., 100.,  25.],\n",
       "                          [103., 105.,  99.,  25.],\n",
       "                          [103., 105.,  99.,  26.],\n",
       "                          [103., 105.,  99.,  25.],\n",
       "                          [103., 105.,  98.,  24.],\n",
       "                          [103., 105.,  98.,  25.],\n",
       "                          [106., 108., 102.,  27.],\n",
       "                          [108., 110., 104.,  28.],\n",
       "                          [104., 104.,  98.,  25.],\n",
       "                          [104., 106.,  99.,  25.],\n",
       "                          [104., 105.,  97.,  26.],\n",
       "                          [105., 105.,  98.,  26.],\n",
       "                          [104., 106.,  98.,  27.],\n",
       "                          [106., 107.,  99.,  27.],\n",
       "                          [ 93.,  94.,  87.,  29.],\n",
       "                          [ 91.,  89.,  79.,  51.],\n",
       "                          [113., 108.,  91.,  86.],\n",
       "                          [119., 114.,  98.,  98.],\n",
       "                          [105., 109.,  92., 118.],\n",
       "                          [110., 115.,  97., 129.],\n",
       "                          [122., 128., 109., 140.],\n",
       "                          [127., 132., 115., 152.],\n",
       "                          [126., 133., 115., 148.],\n",
       "                          [115., 125., 107., 101.],\n",
       "                          [107., 111.,  96.,  46.],\n",
       "                          [116., 112.,  96.,  43.],\n",
       "                          [123., 119., 102.,  44.],\n",
       "                          [133., 128., 120.,  62.],\n",
       "                          [154., 141., 131.,  83.],\n",
       "                          [157., 140., 132.,  84.],\n",
       "                          [152., 139., 134.,  75.],\n",
       "                          [141., 136., 131.,  65.],\n",
       "                          [147., 144., 134.,  70.],\n",
       "                          [177., 172., 157., 101.],\n",
       "                          [189., 187., 183., 140.],\n",
       "                          [189., 188., 185., 137.],\n",
       "                          [189., 188., 184., 136.],\n",
       "                          [189., 188., 184., 137.],\n",
       "                          [189., 188., 183., 137.],\n",
       "                          [189., 188., 183., 137.],\n",
       "                          [188., 186., 181., 135.],\n",
       "                          [187., 185., 179., 132.],\n",
       "                          [187., 186., 179., 132.],\n",
       "                          [189., 187., 182., 136.],\n",
       "                          [189., 187., 182., 137.],\n",
       "                          [189., 187., 182., 136.],\n",
       "                          [189., 187., 182., 137.],\n",
       "                          [189., 187., 182., 137.],\n",
       "                          [189., 187., 183., 137.],\n",
       "                          [191., 189., 185., 137.],\n",
       "                          [183., 178., 171., 122.],\n",
       "                          [144., 130., 117.,  80.],\n",
       "                          [119., 117., 102.,  76.],\n",
       "                          [149., 152., 147.,  85.],\n",
       "                          [162., 165., 161.,  97.],\n",
       "                          [173., 173., 170., 114.],\n",
       "                          [179., 178., 173., 135.],\n",
       "                          [177., 174., 170., 139.],\n",
       "                          [174., 169., 166., 123.],\n",
       "                          [177., 176., 168., 124.],\n",
       "                          [171., 167., 165., 110.],\n",
       "                          [171., 165., 161., 110.],\n",
       "                          [170., 164., 157., 107.],\n",
       "                          [149., 141., 118., 112.],\n",
       "                          [128., 119.,  89., 115.],\n",
       "                          [ 98., 104.,  72., 125.],\n",
       "                          [ 73.,  95.,  60., 148.],\n",
       "                          [ 77.,  94.,  61., 160.],\n",
       "                          [ 77.,  91.,  61., 137.],\n",
       "                          [ 87.,  93.,  67., 100.],\n",
       "                          [ 87.,  96.,  70.,  77.],\n",
       "                          [ 87.,  95.,  65.,  98.],\n",
       "                          [ 84.,  95.,  65.,  95.],\n",
       "                          [ 75.,  83.,  63.,  60.],\n",
       "                          [ 61.,  64.,  55.,  35.],\n",
       "                          [ 50.,  55.,  49.,  37.],\n",
       "                          [ 46.,  53.,  46.,  42.],\n",
       "                          [ 51.,  64.,  48.,  59.],\n",
       "                          [ 53.,  64.,  46.,  78.],\n",
       "                          [ 48.,  59.,  44.,  78.],\n",
       "                          [ 54.,  66.,  47.,  93.],\n",
       "                          [ 51.,  62.,  46.,  77.],\n",
       "                          [ 48.,  57.,  45.,  53.],\n",
       "                          [ 55.,  62.,  48.,  52.]], dtype=float32)],\n",
       "       ...,\n",
       "       [140.71454, array([[124., 117.,  91.,  52.],\n",
       "                          [140., 138., 114.,  66.],\n",
       "                          [158., 152., 128.,  84.],\n",
       "                          [167., 160., 138.,  96.],\n",
       "                          [169., 163., 141., 100.],\n",
       "                          [167., 162., 141.,  99.],\n",
       "                          [167., 161., 141.,  98.],\n",
       "                          [168., 162., 142.,  98.],\n",
       "                          [168., 162., 143., 100.],\n",
       "                          [168., 162., 142., 101.],\n",
       "                          [167., 160., 143.,  98.],\n",
       "                          [166., 160., 142.,  98.],\n",
       "                          [165., 161., 142.,  97.],\n",
       "                          [165., 160., 143.,  84.],\n",
       "                          [133., 132., 127.,  50.],\n",
       "                          [ 84.,  95.,  99.,  22.],\n",
       "                          [101., 115., 107.,  64.],\n",
       "                          [184., 185., 185., 171.],\n",
       "                          [165., 166., 175., 132.],\n",
       "                          [131., 120., 106.,  68.],\n",
       "                          [162., 159., 152., 117.],\n",
       "                          [165., 170., 170., 115.],\n",
       "                          [143., 148., 145.,  76.],\n",
       "                          [129., 131., 126.,  63.],\n",
       "                          [128., 124., 113.,  61.],\n",
       "                          [157., 144., 116.,  87.],\n",
       "                          [185., 182., 165., 137.],\n",
       "                          [185., 181., 166., 137.],\n",
       "                          [187., 184., 171., 139.],\n",
       "                          [189., 183., 173., 141.],\n",
       "                          [179., 174., 161., 121.],\n",
       "                          [165., 162., 148.,  93.],\n",
       "                          [160., 154., 144.,  82.],\n",
       "                          [157., 153., 141.,  81.],\n",
       "                          [163., 159., 146.,  87.],\n",
       "                          [164., 160., 147.,  83.],\n",
       "                          [160., 156., 144.,  80.],\n",
       "                          [154., 151., 138.,  73.],\n",
       "                          [154., 151., 138.,  73.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [161., 156., 145.,  78.],\n",
       "                          [161., 158., 146.,  78.],\n",
       "                          [163., 160., 148.,  82.],\n",
       "                          [165., 160., 147.,  88.],\n",
       "                          [162., 157., 143.,  86.],\n",
       "                          [162., 158., 144.,  85.],\n",
       "                          [165., 160., 147.,  90.],\n",
       "                          [168., 165., 151., 100.],\n",
       "                          [177., 175., 160., 120.],\n",
       "                          [191., 189., 177., 149.],\n",
       "                          [190., 189., 180., 148.],\n",
       "                          [174., 176., 165., 121.],\n",
       "                          [174., 169., 149., 133.],\n",
       "                          [177., 172., 152., 139.],\n",
       "                          [185., 180., 163., 142.],\n",
       "                          [189., 184., 169., 145.],\n",
       "                          [187., 182., 169., 142.],\n",
       "                          [184., 179., 166., 138.],\n",
       "                          [182., 177., 163., 134.],\n",
       "                          [182., 178., 161., 135.],\n",
       "                          [182., 177., 162., 135.],\n",
       "                          [181., 175., 160., 135.],\n",
       "                          [181., 180., 163., 137.],\n",
       "                          [192., 193., 182., 160.],\n",
       "                          [196., 189., 185., 163.],\n",
       "                          [174., 157., 146., 112.],\n",
       "                          [169., 161., 137.,  99.],\n",
       "                          [174., 163., 134., 106.],\n",
       "                          [174., 164., 134., 106.],\n",
       "                          [174., 164., 135., 105.],\n",
       "                          [174., 162., 133., 104.],\n",
       "                          [176., 169., 150., 106.],\n",
       "                          [181., 181., 172., 121.],\n",
       "                          [187., 185., 175., 140.],\n",
       "                          [184., 182., 172., 131.],\n",
       "                          [182., 180., 163., 126.],\n",
       "                          [191., 188., 176., 150.],\n",
       "                          [185., 181., 172., 133.],\n",
       "                          [186., 183., 169., 136.],\n",
       "                          [189., 186., 174., 149.],\n",
       "                          [191., 187., 177., 155.],\n",
       "                          [191., 187., 176., 158.],\n",
       "                          [192., 188., 177., 159.],\n",
       "                          [193., 188., 177., 161.],\n",
       "                          [191., 187., 176., 154.],\n",
       "                          [190., 187., 175., 151.],\n",
       "                          [190., 185., 172., 151.],\n",
       "                          [191., 187., 174., 155.],\n",
       "                          [192., 188., 177., 157.],\n",
       "                          [192., 188., 177., 157.],\n",
       "                          [191., 187., 178., 156.],\n",
       "                          [191., 187., 177., 154.],\n",
       "                          [192., 188., 177., 159.],\n",
       "                          [191., 187., 178., 157.],\n",
       "                          [191., 188., 177., 157.],\n",
       "                          [194., 186., 178., 149.],\n",
       "                          [135., 126., 117., 101.],\n",
       "                          [ 82.,  77.,  60.,  83.],\n",
       "                          [100.,  94.,  71., 129.],\n",
       "                          [117., 100.,  81., 138.],\n",
       "                          [110., 101.,  82., 106.],\n",
       "                          [107., 104.,  78., 121.],\n",
       "                          [124., 119.,  89., 141.],\n",
       "                          [ 89.,  90.,  64.,  94.],\n",
       "                          [ 73.,  77.,  54.,  64.],\n",
       "                          [103.,  99.,  71.,  77.],\n",
       "                          [150., 133., 101., 113.],\n",
       "                          [164., 143., 120., 127.],\n",
       "                          [123., 100.,  87.,  65.],\n",
       "                          [170., 165., 154.,  95.],\n",
       "                          [ 95., 113., 118.,  33.],\n",
       "                          [ 77.,  81.,  83.,  17.],\n",
       "                          [ 81.,  89.,  76.,  19.],\n",
       "                          [121., 126., 104.,  49.],\n",
       "                          [160., 154., 132.,  79.],\n",
       "                          [157., 152., 133.,  77.],\n",
       "                          [154., 153., 133.,  75.],\n",
       "                          [157., 152., 137.,  77.],\n",
       "                          [159., 154., 133.,  77.],\n",
       "                          [157., 152., 133.,  77.],\n",
       "                          [159., 150., 133.,  76.],\n",
       "                          [104., 113., 101.,  43.],\n",
       "                          [ 70.,  87.,  79.,  18.],\n",
       "                          [ 95.,  96.,  88.,  28.],\n",
       "                          [ 98.,  98.,  89.,  31.],\n",
       "                          [ 99., 101.,  92.,  32.],\n",
       "                          [ 98., 101.,  93.,  32.],\n",
       "                          [ 98., 100.,  91.,  31.],\n",
       "                          [100., 100.,  92.,  29.],\n",
       "                          [100., 101.,  92.,  31.],\n",
       "                          [ 99., 100.,  91.,  31.],\n",
       "                          [ 99.,  99.,  90.,  31.],\n",
       "                          [ 98.,  99.,  89.,  33.],\n",
       "                          [ 96.,  95.,  85.,  30.],\n",
       "                          [ 69.,  67.,  64.,  24.],\n",
       "                          [ 65.,  69.,  51.,  43.],\n",
       "                          [ 87.,  88.,  61.,  78.],\n",
       "                          [106., 106.,  76., 113.],\n",
       "                          [106., 111.,  76., 131.],\n",
       "                          [110., 119.,  78., 144.],\n",
       "                          [117., 128.,  86., 155.],\n",
       "                          [ 94., 103.,  76., 124.],\n",
       "                          [ 76.,  82.,  74.,  23.],\n",
       "                          [ 76.,  78.,  71.,  19.],\n",
       "                          [ 79.,  80.,  74.,  19.],\n",
       "                          [ 69.,  67.,  64.,  26.],\n",
       "                          [ 69.,  73.,  55.,  75.],\n",
       "                          [ 72.,  90.,  57., 113.],\n",
       "                          [ 77.,  98.,  63., 118.],\n",
       "                          [ 91.,  99.,  63., 131.],\n",
       "                          [101., 104.,  66., 132.],\n",
       "                          [ 77.,  79.,  59.,  79.],\n",
       "                          [ 63.,  65.,  49.,  60.],\n",
       "                          [ 63.,  68.,  52.,  58.],\n",
       "                          [110., 111.,  87.,  73.],\n",
       "                          [156., 152., 126.,  99.],\n",
       "                          [170., 164., 144., 116.],\n",
       "                          [171., 164., 145., 117.],\n",
       "                          [173., 167., 147., 119.],\n",
       "                          [171., 165., 146., 116.],\n",
       "                          [175., 170., 152., 121.],\n",
       "                          [176., 172., 154., 129.],\n",
       "                          [175., 169., 147., 130.],\n",
       "                          [174., 167., 144., 129.],\n",
       "                          [170., 167., 149., 109.],\n",
       "                          [165., 165., 154.,  81.],\n",
       "                          [164., 165., 155.,  81.],\n",
       "                          [176., 180., 171., 105.],\n",
       "                          [198., 197., 194., 168.],\n",
       "                          [202., 201., 199., 181.],\n",
       "                          [202., 201., 200., 183.],\n",
       "                          [202., 201., 200., 181.],\n",
       "                          [202., 201., 199., 181.],\n",
       "                          [202., 201., 199., 182.],\n",
       "                          [202., 201., 199., 182.],\n",
       "                          [201., 200., 199., 178.],\n",
       "                          [196., 193., 193., 152.],\n",
       "                          [187., 187., 181., 134.],\n",
       "                          [198., 197., 193., 170.],\n",
       "                          [203., 202., 200., 185.],\n",
       "                          [203., 202., 200., 184.],\n",
       "                          [203., 201., 200., 184.],\n",
       "                          [202., 201., 200., 184.],\n",
       "                          [202., 201., 199., 182.],\n",
       "                          [202., 201., 199., 182.],\n",
       "                          [198., 198., 197., 163.],\n",
       "                          [164., 159., 155.,  88.]], dtype=float32)],\n",
       "       [132.38696, array([[105., 119., 120.,  27.],\n",
       "                          [ 91., 110., 105.,  19.],\n",
       "                          [105., 103., 101.,  31.],\n",
       "                          [132., 120., 111.,  56.],\n",
       "                          [151., 145., 127.,  80.],\n",
       "                          [155., 153., 134.,  90.],\n",
       "                          [157., 154., 135.,  89.],\n",
       "                          [157., 153., 138.,  91.],\n",
       "                          [157., 155., 138.,  93.],\n",
       "                          [135., 137., 121.,  72.],\n",
       "                          [128., 137., 117.,  65.],\n",
       "                          [134., 148., 125.,  75.],\n",
       "                          [141., 151., 130.,  85.],\n",
       "                          [148., 149., 128.,  91.],\n",
       "                          [160., 154., 132., 104.],\n",
       "                          [171., 162., 145., 123.],\n",
       "                          [175., 169., 153., 125.],\n",
       "                          [178., 171., 153., 126.],\n",
       "                          [182., 174., 157., 130.],\n",
       "                          [183., 176., 159., 132.],\n",
       "                          [182., 175., 159., 132.],\n",
       "                          [180., 174., 157., 129.],\n",
       "                          [177., 172., 155., 126.],\n",
       "                          [174., 170., 153., 121.],\n",
       "                          [173., 169., 154., 118.],\n",
       "                          [170., 166., 149., 112.],\n",
       "                          [166., 162., 146., 101.],\n",
       "                          [163., 157., 142.,  96.],\n",
       "                          [160., 151., 139.,  89.],\n",
       "                          [154., 145., 134.,  77.],\n",
       "                          [148., 142., 129.,  67.],\n",
       "                          [146., 141., 128.,  67.],\n",
       "                          [146., 143., 128.,  66.],\n",
       "                          [143., 143., 129.,  67.],\n",
       "                          [146., 142., 130.,  67.],\n",
       "                          [147., 142., 129.,  68.],\n",
       "                          [146., 141., 130.,  68.],\n",
       "                          [145., 141., 130.,  67.],\n",
       "                          [145., 142., 129.,  66.],\n",
       "                          [144., 142., 129.,  66.],\n",
       "                          [143., 142., 129.,  66.],\n",
       "                          [143., 142., 130.,  64.],\n",
       "                          [144., 140., 128.,  65.],\n",
       "                          [143., 140., 127.,  62.],\n",
       "                          [142., 139., 125.,  62.],\n",
       "                          [143., 140., 127.,  66.],\n",
       "                          [144., 141., 128.,  66.],\n",
       "                          [143., 141., 128.,  65.],\n",
       "                          [144., 141., 128.,  67.],\n",
       "                          [144., 140., 127.,  66.],\n",
       "                          [145., 140., 129.,  66.],\n",
       "                          [143., 142., 127.,  65.],\n",
       "                          [144., 142., 127.,  65.],\n",
       "                          [144., 141., 127.,  65.],\n",
       "                          [143., 141., 128.,  65.],\n",
       "                          [144., 143., 130.,  64.],\n",
       "                          [147., 144., 132.,  64.],\n",
       "                          [145., 142., 131.,  67.],\n",
       "                          [146., 143., 132.,  68.],\n",
       "                          [147., 145., 131.,  66.],\n",
       "                          [146., 142., 131.,  65.],\n",
       "                          [145., 142., 131.,  67.],\n",
       "                          [145., 143., 129.,  68.],\n",
       "                          [146., 142., 130.,  67.],\n",
       "                          [146., 143., 132.,  67.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [225.,  34.,  49., 255.],\n",
       "                          [147., 143., 129.,  65.],\n",
       "                          [145., 143., 130.,  67.],\n",
       "                          [145., 144., 130.,  68.],\n",
       "                          [145., 144., 132.,  68.],\n",
       "                          [147., 144., 131.,  70.],\n",
       "                          [148., 143., 133.,  68.],\n",
       "                          [147., 143., 132.,  65.],\n",
       "                          [146., 143., 129.,  64.],\n",
       "                          [145., 141., 129.,  64.],\n",
       "                          [145., 141., 129.,  64.],\n",
       "                          [144., 140., 129.,  65.],\n",
       "                          [142., 139., 126.,  63.],\n",
       "                          [142., 137., 124.,  63.],\n",
       "                          [141., 137., 124.,  62.],\n",
       "                          [139., 137., 125.,  63.],\n",
       "                          [139., 137., 125.,  62.],\n",
       "                          [141., 138., 125.,  60.],\n",
       "                          [143., 140., 124.,  65.],\n",
       "                          [144., 142., 129.,  66.],\n",
       "                          [144., 143., 129.,  68.],\n",
       "                          [147., 146., 131.,  72.],\n",
       "                          [151., 148., 133.,  77.],\n",
       "                          [154., 149., 133.,  80.],\n",
       "                          [156., 151., 132.,  84.],\n",
       "                          [158., 153., 134.,  89.],\n",
       "                          [158., 155., 135.,  90.],\n",
       "                          [160., 154., 133.,  95.],\n",
       "                          [159., 151., 131.,  95.],\n",
       "                          [156., 150., 132.,  92.],\n",
       "                          [154., 149., 127.,  89.],\n",
       "                          [147., 139., 118.,  79.],\n",
       "                          [130., 126., 113.,  61.],\n",
       "                          [121., 119., 111.,  54.],\n",
       "                          [134., 127., 114.,  82.],\n",
       "                          [155., 150., 122., 127.],\n",
       "                          [159., 152., 125., 111.],\n",
       "                          [156., 150., 124.,  98.],\n",
       "                          [153., 148., 113., 138.],\n",
       "                          [160., 149., 110., 154.],\n",
       "                          [161., 147., 108., 156.],\n",
       "                          [155., 144., 108., 131.],\n",
       "                          [147., 142., 115.,  92.],\n",
       "                          [143., 140., 117.,  80.],\n",
       "                          [140., 137., 112.,  81.],\n",
       "                          [142., 139., 117.,  80.],\n",
       "                          [145., 139., 112., 100.],\n",
       "                          [144., 133.,  96., 130.],\n",
       "                          [140., 130.,  88., 130.],\n",
       "                          [133., 126.,  92.,  93.],\n",
       "                          [113., 113.,  94.,  53.],\n",
       "                          [ 91., 100.,  95.,  40.],\n",
       "                          [ 98., 106., 106.,  40.],\n",
       "                          [ 75.,  85.,  85.,  31.],\n",
       "                          [ 52.,  70.,  62.,  55.],\n",
       "                          [ 53.,  74.,  59.,  42.],\n",
       "                          [ 54.,  70.,  61.,  20.],\n",
       "                          [ 47.,  57.,  50.,  14.],\n",
       "                          [ 70.,  74.,  50.,  62.],\n",
       "                          [122., 120.,  73., 133.],\n",
       "                          [144., 140.,  92., 135.],\n",
       "                          [123., 131., 104.,  84.],\n",
       "                          [107., 113., 104.,  41.],\n",
       "                          [105., 113.,  98.,  39.],\n",
       "                          [110., 114.,  98.,  41.],\n",
       "                          [112., 116.,  99.,  42.],\n",
       "                          [113., 118., 100.,  44.],\n",
       "                          [117., 118., 102.,  46.],\n",
       "                          [121., 123., 107.,  48.],\n",
       "                          [125., 127., 114.,  49.],\n",
       "                          [129., 132., 119.,  53.],\n",
       "                          [136., 135., 121.,  54.],\n",
       "                          [126., 125., 111.,  47.],\n",
       "                          [114., 116., 102.,  40.],\n",
       "                          [121., 129., 110.,  46.],\n",
       "                          [135., 147., 123.,  49.],\n",
       "                          [123., 127., 110.,  32.],\n",
       "                          [ 78.,  76.,  70.,  19.],\n",
       "                          [ 82.,  88.,  83.,  52.],\n",
       "                          [186., 185., 177., 176.],\n",
       "                          [206., 205., 202., 197.],\n",
       "                          [208., 206., 205., 199.],\n",
       "                          [207., 206., 204., 199.],\n",
       "                          [207., 206., 205., 199.],\n",
       "                          [207., 205., 204., 198.],\n",
       "                          [206., 204., 203., 195.],\n",
       "                          [205., 203., 203., 192.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [206., 204., 203., 193.],\n",
       "                          [205., 204., 203., 192.],\n",
       "                          [205., 204., 202., 188.],\n",
       "                          [191., 190., 191., 115.],\n",
       "                          [ 96.,  98., 100.,  37.],\n",
       "                          [ 89.,  93.,  78.,  30.],\n",
       "                          [140., 141., 110.,  62.],\n",
       "                          [147., 145., 121.,  62.],\n",
       "                          [112., 111., 101.,  33.],\n",
       "                          [110., 111.,  99.,  34.],\n",
       "                          [107., 109.,  98.,  36.],\n",
       "                          [113., 116., 102.,  38.],\n",
       "                          [128., 128., 119.,  45.],\n",
       "                          [117., 119., 114.,  35.],\n",
       "                          [108., 109., 100.,  32.],\n",
       "                          [105., 105.,  94.,  32.],\n",
       "                          [106., 106.,  96.,  32.],\n",
       "                          [107., 108.,  95.,  35.],\n",
       "                          [105., 110.,  95.,  35.],\n",
       "                          [104., 107.,  96.,  35.],\n",
       "                          [107., 109.,  97.,  32.],\n",
       "                          [113., 114., 100.,  41.],\n",
       "                          [119., 115., 101.,  44.]], dtype=float32)],\n",
       "       [64.2438, array([[122., 139., 149.,  38.],\n",
       "                        [127., 142., 150.,  40.],\n",
       "                        [117., 131., 134.,  39.],\n",
       "                        [101., 108., 107.,  32.],\n",
       "                        [130., 127., 125.,  44.],\n",
       "                        [161., 153., 154.,  66.],\n",
       "                        [174., 169., 164.,  94.],\n",
       "                        [170., 169., 155., 105.],\n",
       "                        [156., 153., 140.,  79.],\n",
       "                        [142., 143., 135.,  65.],\n",
       "                        [121., 122., 115.,  55.],\n",
       "                        [112., 110., 106.,  47.],\n",
       "                        [ 92.,  94.,  92.,  37.],\n",
       "                        [ 75.,  80.,  77.,  28.],\n",
       "                        [ 70.,  76.,  72.,  23.],\n",
       "                        [ 72.,  77.,  74.,  22.],\n",
       "                        [ 68.,  77.,  75.,  21.],\n",
       "                        [ 68.,  75.,  72.,  22.],\n",
       "                        [ 67.,  70.,  73.,  20.],\n",
       "                        [ 63.,  73.,  70.,  23.],\n",
       "                        [ 62.,  69.,  69.,  21.],\n",
       "                        [ 59.,  69.,  67.,  19.],\n",
       "                        [ 60.,  69.,  67.,  19.],\n",
       "                        [ 59.,  68.,  65.,  19.],\n",
       "                        [ 55.,  67.,  63.,  19.],\n",
       "                        [ 59.,  64.,  64.,  20.],\n",
       "                        [ 58.,  66.,  63.,  18.],\n",
       "                        [ 54.,  63.,  63.,  18.],\n",
       "                        [ 55.,  65.,  64.,  18.],\n",
       "                        [ 57.,  65.,  64.,  19.],\n",
       "                        [ 58.,  64.,  65.,  19.],\n",
       "                        [ 56.,  63.,  65.,  18.],\n",
       "                        [ 55.,  62.,  63.,  17.],\n",
       "                        [ 55.,  62.,  62.,  18.],\n",
       "                        [ 55.,  60.,  61.,  18.],\n",
       "                        [ 55.,  61.,  61.,  16.],\n",
       "                        [ 53.,  61.,  62.,  17.],\n",
       "                        [ 53.,  63.,  60.,  17.],\n",
       "                        [ 52.,  61.,  60.,  17.],\n",
       "                        [ 51.,  60.,  61.,  17.],\n",
       "                        [ 52.,  60.,  61.,  17.],\n",
       "                        [ 51.,  60.,  59.,  17.],\n",
       "                        [ 52.,  58.,  57.,  17.],\n",
       "                        [ 50.,  58.,  56.,  16.],\n",
       "                        [ 51.,  58.,  57.,  16.],\n",
       "                        [ 53.,  59.,  59.,  18.],\n",
       "                        [ 52.,  58.,  58.,  18.],\n",
       "                        [ 52.,  59.,  59.,  18.],\n",
       "                        [ 53.,  60.,  60.,  17.],\n",
       "                        [ 52.,  60.,  61.,  17.],\n",
       "                        [ 53.,  62.,  63.,  18.],\n",
       "                        [ 54.,  60.,  62.,  18.],\n",
       "                        [ 56.,  61.,  64.,  20.],\n",
       "                        [ 56.,  63.,  62.,  19.],\n",
       "                        [ 53.,  61.,  62.,  18.],\n",
       "                        [ 55.,  64.,  66.,  18.],\n",
       "                        [ 61.,  66.,  73.,  19.],\n",
       "                        [ 64.,  69.,  80.,  20.],\n",
       "                        [ 66.,  74.,  82.,  21.],\n",
       "                        [ 71.,  77.,  84.,  25.],\n",
       "                        [ 80.,  87.,  89.,  37.],\n",
       "                        [ 76.,  80.,  80.,  40.],\n",
       "                        [ 64.,  71.,  71.,  29.],\n",
       "                        [ 55.,  62.,  65.,  25.],\n",
       "                        [ 67.,  71.,  75.,  33.],\n",
       "                        [ 93.,  97.,  96.,  51.],\n",
       "                        [105., 113., 103.,  62.],\n",
       "                        [ 83.,  95.,  89.,  45.],\n",
       "                        [ 69.,  76.,  76.,  30.],\n",
       "                        [ 55.,  61.,  63.,  23.],\n",
       "                        [ 54.,  58.,  58.,  19.],\n",
       "                        [ 52.,  58.,  58.,  19.],\n",
       "                        [ 53.,  57.,  58.,  19.],\n",
       "                        [ 54.,  58.,  59.,  18.],\n",
       "                        [ 53.,  59.,  59.,  18.],\n",
       "                        [ 53.,  60.,  59.,  18.],\n",
       "                        [ 51.,  61.,  57.,  16.],\n",
       "                        [ 52.,  57.,  57.,  18.],\n",
       "                        [ 54.,  58.,  55.,  19.],\n",
       "                        [ 52.,  58.,  57.,  20.],\n",
       "                        [ 50.,  57.,  56.,  19.],\n",
       "                        [ 50.,  58.,  55.,  17.],\n",
       "                        [ 51.,  58.,  56.,  18.],\n",
       "                        [ 53.,  57.,  56.,  20.],\n",
       "                        [ 51.,  56.,  56.,  18.],\n",
       "                        [ 51.,  56.,  57.,  18.],\n",
       "                        [ 49.,  56.,  54.,  20.],\n",
       "                        [ 49.,  55.,  53.,  22.],\n",
       "                        [ 46.,  54.,  51.,  24.],\n",
       "                        [ 45.,  53.,  51.,  24.],\n",
       "                        [ 50.,  55.,  54.,  22.],\n",
       "                        [ 55.,  60.,  58.,  21.],\n",
       "                        [ 53.,  61.,  59.,  19.],\n",
       "                        [ 56.,  62.,  59.,  19.],\n",
       "                        [ 54.,  60.,  58.,  18.],\n",
       "                        [ 59.,  63.,  67.,  19.],\n",
       "                        [ 69.,  73.,  80.,  22.],\n",
       "                        [ 71.,  76.,  78.,  23.],\n",
       "                        [ 66.,  71.,  71.,  22.],\n",
       "                        [ 63.,  68.,  67.,  19.],\n",
       "                        [ 60.,  66.,  61.,  19.],\n",
       "                        [ 52.,  59.,  58.,  18.],\n",
       "                        [ 51.,  56.,  58.,  16.],\n",
       "                        [ 49.,  58.,  57.,  17.],\n",
       "                        [ 55.,  59.,  59.,  17.],\n",
       "                        [ 56.,  59.,  59.,  18.],\n",
       "                        [ 53.,  58.,  58.,  18.],\n",
       "                        [ 52.,  56.,  57.,  18.],\n",
       "                        [ 53.,  55.,  56.,  18.],\n",
       "                        [ 51.,  57.,  56.,  17.],\n",
       "                        [ 50.,  55.,  57.,  17.],\n",
       "                        [ 54.,  59.,  57.,  16.],\n",
       "                        [ 52.,  59.,  57.,  17.],\n",
       "                        [ 50.,  58.,  57.,  17.],\n",
       "                        [ 50.,  57.,  57.,  17.],\n",
       "                        [ 50.,  57.,  57.,  17.],\n",
       "                        [ 50.,  56.,  57.,  17.],\n",
       "                        [ 52.,  57.,  57.,  17.],\n",
       "                        [225.,  34.,  49., 255.],\n",
       "                        [225.,  34.,  49., 255.],\n",
       "                        [225.,  34.,  49., 255.],\n",
       "                        [ 52.,  58.,  55.,  17.],\n",
       "                        [ 50.,  58.,  56.,  16.],\n",
       "                        [ 49.,  57.,  56.,  16.],\n",
       "                        [ 50.,  57.,  57.,  17.],\n",
       "                        [ 51.,  60.,  57.,  16.],\n",
       "                        [ 48.,  59.,  55.,  17.],\n",
       "                        [ 50.,  57.,  55.,  18.],\n",
       "                        [ 48.,  56.,  51.,  19.],\n",
       "                        [ 49.,  58.,  55.,  18.],\n",
       "                        [ 55.,  69.,  69.,  17.],\n",
       "                        [ 65.,  82.,  84.,  19.],\n",
       "                        [ 70.,  87.,  91.,  19.],\n",
       "                        [ 67.,  85.,  92.,  18.],\n",
       "                        [ 66.,  84.,  96.,  19.],\n",
       "                        [ 69.,  85.,  95.,  19.],\n",
       "                        [ 59.,  73.,  80.,  19.],\n",
       "                        [ 51.,  63.,  64.,  18.],\n",
       "                        [ 64.,  74.,  86.,  19.],\n",
       "                        [ 82.,  97., 116.,  23.],\n",
       "                        [ 89., 109., 127.,  27.],\n",
       "                        [ 85., 106., 123.,  26.],\n",
       "                        [ 82.,  99., 118.,  24.],\n",
       "                        [ 74.,  94., 109.,  23.],\n",
       "                        [ 72.,  92., 102.,  24.],\n",
       "                        [ 80.,  99., 110.,  25.],\n",
       "                        [ 81., 102., 117.,  25.],\n",
       "                        [ 81., 100., 118.,  25.],\n",
       "                        [ 78.,  96., 115.,  24.],\n",
       "                        [ 78.,  97., 118.,  24.],\n",
       "                        [ 86., 106., 129.,  27.],\n",
       "                        [ 91., 114., 136.,  27.],\n",
       "                        [ 93., 116., 138.,  27.],\n",
       "                        [ 98., 118., 142.,  28.],\n",
       "                        [100., 120., 145.,  27.],\n",
       "                        [104., 124., 146.,  30.],\n",
       "                        [102., 123., 144.,  31.],\n",
       "                        [ 97., 121., 142.,  29.],\n",
       "                        [ 95., 120., 141.,  28.],\n",
       "                        [ 94., 117., 140.,  27.],\n",
       "                        [ 95., 118., 139.,  30.],\n",
       "                        [ 98., 120., 139.,  31.],\n",
       "                        [ 95., 116., 138.,  28.],\n",
       "                        [ 93., 113., 133.,  28.],\n",
       "                        [ 93., 113., 133.,  28.],\n",
       "                        [ 94., 115., 136.,  28.],\n",
       "                        [ 95., 116., 136.,  29.],\n",
       "                        [ 94., 114., 135.,  29.],\n",
       "                        [ 94., 114., 132.,  28.],\n",
       "                        [ 89., 109., 128.,  26.],\n",
       "                        [ 87., 108., 123.,  28.],\n",
       "                        [ 72.,  89.,  95.,  23.],\n",
       "                        [ 58.,  70.,  72.,  19.],\n",
       "                        [ 54.,  65.,  73.,  19.],\n",
       "                        [ 63.,  76.,  91.,  21.],\n",
       "                        [ 76.,  91., 106.,  23.],\n",
       "                        [ 77.,  94., 104.,  23.],\n",
       "                        [ 74.,  86.,  96.,  24.],\n",
       "                        [ 63.,  76.,  84.,  20.],\n",
       "                        [ 55.,  66.,  72.,  19.],\n",
       "                        [ 52.,  59.,  63.,  17.],\n",
       "                        [ 50.,  57.,  60.,  17.],\n",
       "                        [ 48.,  57.,  59.,  17.],\n",
       "                        [ 47.,  57.,  58.,  17.],\n",
       "                        [ 47.,  57.,  58.,  17.],\n",
       "                        [ 46.,  56.,  57.,  16.],\n",
       "                        [ 50.,  57.,  56.,  18.],\n",
       "                        [ 50.,  58.,  56.,  17.]], dtype=float32)]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00cc6d2a-01fb-4865-98f8-31375928224b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.mean(test[:3]), test[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 1, 1, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street = np.asarray(x_train[['Tile_ID', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical']]).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c28b0428-174b-4e10-b151-1354cf44bf79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 1, 1, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_t = np.asarray(x_test[['Tile_ID', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical']]).astype('float32')\n",
    "street_mini_t = []\n",
    "for row in range(len(street_t)):\n",
    "    street_mini_t.append([[street_t[row]]])\n",
    "street_mini_t = np.stack(street_mini_t)\n",
    "np.shape(street_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0d0a-47df-45ce-8bd4-9c31ed9d0cc3",
   "metadata": {},
   "source": [
    "**Noriel's Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea7d7f38-92f3-4993-89a5-1a97b79168c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 1, 1, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcaa6128-f08b-4230-8945-bb60610c4f01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 148, 188, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5275800-edf8-4225-a07c-998b25870208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street = np.hstack(\n",
    "    (street_mini.reshape((8376,9)),\n",
    "     images_mini.reshape(8376,111296))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2677cbd-a7b1-4e7b-91d7-532bac37cee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda \n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tifffile\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6335f7f-ee80-4aba-a63e-939320dfb117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[images_mini, street_mini]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a910ea-340e-4e99-a626-7187735f8f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a13e660c-d9ed-4991-ba6a-c0cece399b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8419     C\n",
       "10129    B\n",
       "7641     A\n",
       "5215     A\n",
       "7784     A\n",
       "        ..\n",
       "6310     B\n",
       "8846     B\n",
       "729      A\n",
       "5825     A\n",
       "8261     B\n",
       "Name: bin, Length: 8376, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217a2b4-a4fb-4407-8f08-cf72e15cdbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e009aa6-17b0-4b25-a570-aba1ce6100ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3c59de5-593f-420d-9ad8-f73547eaf9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>111295</th>\n",
       "      <th>111296</th>\n",
       "      <th>111297</th>\n",
       "      <th>111298</th>\n",
       "      <th>111299</th>\n",
       "      <th>111300</th>\n",
       "      <th>111301</th>\n",
       "      <th>111302</th>\n",
       "      <th>111303</th>\n",
       "      <th>111304</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10993.0</td>\n",
       "      <td>37.750271</td>\n",
       "      <td>-122.405563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13338.0</td>\n",
       "      <td>37.709606</td>\n",
       "      <td>-122.382767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10163.0</td>\n",
       "      <td>37.772858</td>\n",
       "      <td>-122.413544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7523.0</td>\n",
       "      <td>37.768341</td>\n",
       "      <td>-122.439766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314.0</td>\n",
       "      <td>37.740330</td>\n",
       "      <td>-122.412407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>8701.0</td>\n",
       "      <td>37.743038</td>\n",
       "      <td>-122.428368</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>11464.0</td>\n",
       "      <td>37.740330</td>\n",
       "      <td>-122.401001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>1831.0</td>\n",
       "      <td>37.715931</td>\n",
       "      <td>-122.496773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>8179.0</td>\n",
       "      <td>37.799065</td>\n",
       "      <td>-122.432930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>10826.0</td>\n",
       "      <td>37.797256</td>\n",
       "      <td>-122.406708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8376 rows Ã— 111305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1           2       3       4       5       6       7       \\\n",
       "0     10993.0  37.750271 -122.405563     0.0     0.0     0.0     0.0     3.0   \n",
       "1     13338.0  37.709606 -122.382767     0.0     0.0     0.0     0.0     1.0   \n",
       "2     10163.0  37.772858 -122.413544     0.0     0.0     0.0     0.0     0.0   \n",
       "3      7523.0  37.768341 -122.439766     1.0     0.0     0.0     1.0     0.0   \n",
       "4     10314.0  37.740330 -122.412407     2.0     0.0     0.0     0.0     0.0   \n",
       "...       ...        ...         ...     ...     ...     ...     ...     ...   \n",
       "8371   8701.0  37.743038 -122.428368     4.0     0.0     3.0     0.0     1.0   \n",
       "8372  11464.0  37.740330 -122.401001     0.0     1.0     2.0     0.0     1.0   \n",
       "8373   1831.0  37.715931 -122.496773     0.0     0.0     0.0     0.0     0.0   \n",
       "8374   8179.0  37.799065 -122.432930     4.0     6.0     0.0     0.0     0.0   \n",
       "8375  10826.0  37.797256 -122.406708     0.0     0.0     0.0     1.0     2.0   \n",
       "\n",
       "      8       9       ...  111295  111296  111297  111298  111299  111300  \\\n",
       "0        2.0   167.0  ...    84.0   129.0   158.0   154.0   104.0   175.0   \n",
       "1        0.0   142.0  ...   114.0   118.0   147.0   141.0   113.0   132.0   \n",
       "2        0.0   191.0  ...   161.0   112.0   166.0   169.0   159.0   107.0   \n",
       "3        0.0    60.0  ...    52.0    98.0    64.0    81.0    55.0   101.0   \n",
       "4        0.0    47.0  ...    60.0    26.0    53.0    64.0    57.0    32.0   \n",
       "...      ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "8371     0.0   168.0  ...   159.0   122.0   185.0   182.0   168.0   128.0   \n",
       "8372     0.0   187.0  ...    81.0    26.0    69.0    79.0    76.0    37.0   \n",
       "8373     0.0   209.0  ...    59.0    72.0    73.0    72.0    59.0    66.0   \n",
       "8374     1.0   130.0  ...   110.0    45.0   138.0   123.0   116.0    56.0   \n",
       "8375     2.0   171.0  ...   123.0    40.0   104.0   111.0   112.0    35.0   \n",
       "\n",
       "      111301  111302  111303  111304  \n",
       "0      149.0   145.0   106.0   177.0  \n",
       "1      155.0   147.0   119.0   130.0  \n",
       "2      173.0   172.0   163.0   120.0  \n",
       "3       54.0    66.0    49.0    78.0  \n",
       "4       60.0    68.0    61.0    36.0  \n",
       "...      ...     ...     ...     ...  \n",
       "8371   182.0   174.0   163.0   118.0  \n",
       "8372    86.0    89.0    76.0    78.0  \n",
       "8373    74.0    71.0    56.0    73.0  \n",
       "8374   166.0   164.0   146.0    84.0  \n",
       "8375   103.0   112.0   113.0    34.0  \n",
       "\n",
       "[8376 rows x 111305 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(input_image_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4f0f7-a7dc-43f6-94db-d59f5b204b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp0k3y6ehj as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 22:22:46.243451: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3729162720 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "rf_model = tfdf.keras.RandomForestModel(categorical_algorithm = 'CART', num_trees=100)\n",
    "\n",
    "rf_model.fit(input_image_street,\n",
    "    y_train,\n",
    "    #validation_data=[x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']], y_test],     \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14110520-7657-467c-83af-ca78d8e431de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (47):\n",
      "\tdata:0.0\n",
      "\tdata:0.1\n",
      "\tdata:0.10\n",
      "\tdata:0.11\n",
      "\tdata:0.12\n",
      "\tdata:0.13\n",
      "\tdata:0.14\n",
      "\tdata:0.15\n",
      "\tdata:0.16\n",
      "\tdata:0.17\n",
      "\tdata:0.18\n",
      "\tdata:0.19\n",
      "\tdata:0.2\n",
      "\tdata:0.20\n",
      "\tdata:0.21\n",
      "\tdata:0.22\n",
      "\tdata:0.23\n",
      "\tdata:0.24\n",
      "\tdata:0.25\n",
      "\tdata:0.26\n",
      "\tdata:0.27\n",
      "\tdata:0.28\n",
      "\tdata:0.29\n",
      "\tdata:0.3\n",
      "\tdata:0.30\n",
      "\tdata:0.31\n",
      "\tdata:0.32\n",
      "\tdata:0.33\n",
      "\tdata:0.34\n",
      "\tdata:0.35\n",
      "\tdata:0.36\n",
      "\tdata:0.37\n",
      "\tdata:0.38\n",
      "\tdata:0.39\n",
      "\tdata:0.4\n",
      "\tdata:0.40\n",
      "\tdata:0.41\n",
      "\tdata:0.42\n",
      "\tdata:0.43\n",
      "\tdata:0.44\n",
      "\tdata:0.45\n",
      "\tdata:0.46\n",
      "\tdata:0.5\n",
      "\tdata:0.6\n",
      "\tdata:0.7\n",
      "\tdata:0.8\n",
      "\tdata:0.9\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1. \"data:0.20\"  0.216889 ################\n",
      "    2. \"data:0.11\"  0.216219 ###############\n",
      "    3. \"data:0.12\"  0.189766 ###########\n",
      "    4. \"data:0.19\"  0.173091 ########\n",
      "    5.  \"data:0.7\"  0.170695 #######\n",
      "    6. \"data:0.18\"  0.167326 ######\n",
      "    7.  \"data:0.0\"  0.157780 #####\n",
      "    8. \"data:0.10\"  0.156645 #####\n",
      "    9. \"data:0.21\"  0.154189 ####\n",
      "   10. \"data:0.23\"  0.147501 ###\n",
      "   11.  \"data:0.3\"  0.144992 ##\n",
      "   12.  \"data:0.2\"  0.143185 ##\n",
      "   13.  \"data:0.1\"  0.142460 ##\n",
      "   14.  \"data:0.6\"  0.140879 ##\n",
      "   15.  \"data:0.5\"  0.140730 ##\n",
      "   16.  \"data:0.4\"  0.138018 #\n",
      "   17. \"data:0.22\"  0.132680 \n",
      "   18.  \"data:0.8\"  0.130667 \n",
      "   19. \"data:0.41\"  0.130514 \n",
      "   20. \"data:0.42\"  0.130478 \n",
      "   21. \"data:0.24\"  0.130349 \n",
      "   22. \"data:0.25\"  0.130255 \n",
      "   23. \"data:0.32\"  0.129966 \n",
      "   24.  \"data:0.9\"  0.129821 \n",
      "   25. \"data:0.26\"  0.129642 \n",
      "   26. \"data:0.35\"  0.129625 \n",
      "   27. \"data:0.44\"  0.129594 \n",
      "   28. \"data:0.45\"  0.129534 \n",
      "   29. \"data:0.37\"  0.129344 \n",
      "   30. \"data:0.33\"  0.129306 \n",
      "   31. \"data:0.46\"  0.129294 \n",
      "   32. \"data:0.36\"  0.129278 \n",
      "   33. \"data:0.31\"  0.129254 \n",
      "   34. \"data:0.27\"  0.129251 \n",
      "   35. \"data:0.34\"  0.129251 \n",
      "   36. \"data:0.28\"  0.129230 \n",
      "   37. \"data:0.38\"  0.129227 \n",
      "   38. \"data:0.39\"  0.129224 \n",
      "   39. \"data:0.14\"  0.129216 \n",
      "   40. \"data:0.40\"  0.129206 \n",
      "   41. \"data:0.29\"  0.129174 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"data:0.18\" 15.000000 ################\n",
      "    2. \"data:0.11\" 12.000000 ############\n",
      "    3. \"data:0.19\" 12.000000 ############\n",
      "    4. \"data:0.12\"  9.000000 #########\n",
      "    5. \"data:0.20\"  9.000000 #########\n",
      "    6. \"data:0.10\"  8.000000 ########\n",
      "    7. \"data:0.21\"  7.000000 ######\n",
      "    8.  \"data:0.7\"  6.000000 #####\n",
      "    9.  \"data:0.0\"  5.000000 ####\n",
      "   10.  \"data:0.2\"  4.000000 ###\n",
      "   11.  \"data:0.3\"  4.000000 ###\n",
      "   12. \"data:0.22\"  2.000000 #\n",
      "   13.  \"data:0.5\"  2.000000 #\n",
      "   14.  \"data:0.1\"  1.000000 \n",
      "   15.  \"data:0.4\"  1.000000 \n",
      "   16. \"data:0.41\"  1.000000 \n",
      "   17. \"data:0.42\"  1.000000 \n",
      "   18.  \"data:0.6\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1. \"data:0.11\" 1190.000000 ################\n",
      "    2. \"data:0.20\" 921.000000 ############\n",
      "    3. \"data:0.12\" 285.000000 ###\n",
      "    4.  \"data:0.0\" 211.000000 ##\n",
      "    5.  \"data:0.7\" 146.000000 #\n",
      "    6.  \"data:0.2\" 143.000000 #\n",
      "    7.  \"data:0.5\" 138.000000 #\n",
      "    8. \"data:0.10\" 131.000000 #\n",
      "    9. \"data:0.21\" 129.000000 #\n",
      "   10.  \"data:0.3\" 126.000000 #\n",
      "   11.  \"data:0.1\" 124.000000 #\n",
      "   12. \"data:0.18\" 124.000000 #\n",
      "   13.  \"data:0.4\" 121.000000 #\n",
      "   14.  \"data:0.6\" 111.000000 #\n",
      "   15. \"data:0.19\" 63.000000 \n",
      "   16. \"data:0.23\" 47.000000 \n",
      "   17.  \"data:0.8\" 27.000000 \n",
      "   18. \"data:0.32\"  8.000000 \n",
      "   19. \"data:0.26\"  7.000000 \n",
      "   20. \"data:0.35\"  7.000000 \n",
      "   21. \"data:0.22\"  6.000000 \n",
      "   22. \"data:0.45\"  6.000000 \n",
      "   23. \"data:0.44\"  5.000000 \n",
      "   24.  \"data:0.9\"  5.000000 \n",
      "   25. \"data:0.33\"  4.000000 \n",
      "   26. \"data:0.25\"  3.000000 \n",
      "   27. \"data:0.27\"  3.000000 \n",
      "   28. \"data:0.28\"  3.000000 \n",
      "   29. \"data:0.37\"  3.000000 \n",
      "   30. \"data:0.39\"  3.000000 \n",
      "   31. \"data:0.42\"  3.000000 \n",
      "   32. \"data:0.24\"  2.000000 \n",
      "   33. \"data:0.34\"  2.000000 \n",
      "   34. \"data:0.36\"  2.000000 \n",
      "   35. \"data:0.38\"  2.000000 \n",
      "   36. \"data:0.40\"  2.000000 \n",
      "   37. \"data:0.41\"  2.000000 \n",
      "   38. \"data:0.46\"  2.000000 \n",
      "   39. \"data:0.14\"  1.000000 \n",
      "   40. \"data:0.29\"  1.000000 \n",
      "   41. \"data:0.31\"  1.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1. \"data:0.11\" 203504.316877 ################\n",
      "    2. \"data:0.20\" 183359.541298 ##############\n",
      "    3. \"data:0.18\" 135042.604093 ##########\n",
      "    4. \"data:0.19\" 24031.345199 #\n",
      "    5. \"data:0.12\" 23967.399164 #\n",
      "    6.  \"data:0.7\" 5280.114413 \n",
      "    7. \"data:0.10\" 4220.962525 \n",
      "    8.  \"data:0.0\" 3308.596797 \n",
      "    9. \"data:0.21\" 3285.324516 \n",
      "   10.  \"data:0.3\" 1715.922919 \n",
      "   11.  \"data:0.2\" 1511.707730 \n",
      "   12.  \"data:0.1\" 1483.471942 \n",
      "   13. \"data:0.23\" 1414.711063 \n",
      "   14.  \"data:0.5\" 1300.157517 \n",
      "   15.  \"data:0.6\" 1242.367065 \n",
      "   16.  \"data:0.4\" 887.249193 \n",
      "   17.  \"data:0.8\" 182.254481 \n",
      "   18. \"data:0.22\" 157.255164 \n",
      "   19. \"data:0.42\" 109.946715 \n",
      "   20. \"data:0.32\" 72.038793 \n",
      "   21. \"data:0.44\" 52.234479 \n",
      "   22. \"data:0.35\" 41.602867 \n",
      "   23. \"data:0.41\" 41.009786 \n",
      "   24. \"data:0.26\" 37.950673 \n",
      "   25. \"data:0.45\" 35.221360 \n",
      "   26.  \"data:0.9\" 23.896070 \n",
      "   27. \"data:0.25\" 23.097345 \n",
      "   28. \"data:0.37\" 21.850743 \n",
      "   29. \"data:0.33\" 18.792957 \n",
      "   30. \"data:0.27\" 15.211249 \n",
      "   31. \"data:0.38\" 14.574484 \n",
      "   32. \"data:0.36\" 14.519106 \n",
      "   33. \"data:0.31\" 13.766158 \n",
      "   34. \"data:0.46\" 13.292934 \n",
      "   35. \"data:0.24\" 13.036621 \n",
      "   36. \"data:0.14\" 12.536843 \n",
      "   37. \"data:0.40\" 11.800049 \n",
      "   38. \"data:0.39\" 11.767367 \n",
      "   39. \"data:0.28\" 10.464534 \n",
      "   40. \"data:0.34\"  8.578134 \n",
      "   41. \"data:0.29\"  1.546868 \n",
      "\n",
      "\n",
      "\n",
      "Winner takes all: true\n",
      "Out-of-bag evaluation: accuracy:0.997732 logloss:0.0198674\n",
      "Number of trees: 100\n",
      "Total number of nodes: 8340\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 100 Average: 83.4 StdDev: 33.1349\n",
      "Min: 23 Max: 169 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  23,  30)  3   3.00%   3.00% ###\n",
      "[  30,  37)  2   2.00%   5.00% ##\n",
      "[  37,  45)  6   6.00%  11.00% #####\n",
      "[  45,  52)  9   9.00%  20.00% ########\n",
      "[  52,  59)  6   6.00%  26.00% #####\n",
      "[  59,  67)  8   8.00%  34.00% #######\n",
      "[  67,  74) 11  11.00%  45.00% ##########\n",
      "[  74,  81)  5   5.00%  50.00% #####\n",
      "[  81,  89)  6   6.00%  56.00% #####\n",
      "[  89,  96)  7   7.00%  63.00% ######\n",
      "[  96, 103)  9   9.00%  72.00% ########\n",
      "[ 103, 111)  6   6.00%  78.00% #####\n",
      "[ 111, 118)  4   4.00%  82.00% ####\n",
      "[ 118, 125)  3   3.00%  85.00% ###\n",
      "[ 125, 133)  9   9.00%  94.00% ########\n",
      "[ 133, 140)  1   1.00%  95.00% #\n",
      "[ 140, 147)  1   1.00%  96.00% #\n",
      "[ 147, 155)  2   2.00%  98.00% ##\n",
      "[ 155, 162)  0   0.00%  98.00%\n",
      "[ 162, 169]  2   2.00% 100.00% ##\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 4220 Average: 6.95237 StdDev: 2.00765\n",
      "Min: 1 Max: 14 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  1,  2)  36   0.85%   0.85%\n",
      "[  2,  3)  66   1.56%   2.42% #\n",
      "[  3,  4) 105   2.49%   4.91% #\n",
      "[  4,  5) 235   5.57%  10.47% ###\n",
      "[  5,  6) 487  11.54%  22.01% ######\n",
      "[  6,  7) 727  17.23%  39.24% #########\n",
      "[  7,  8) 854  20.24%  59.48% ##########\n",
      "[  8,  9) 782  18.53%  78.01% #########\n",
      "[  9, 10) 553  13.10%  91.11% ######\n",
      "[ 10, 11) 266   6.30%  97.42% ###\n",
      "[ 11, 12)  73   1.73%  99.15% #\n",
      "[ 12, 13)  25   0.59%  99.74%\n",
      "[ 13, 14)   9   0.21%  99.95%\n",
      "[ 14, 14]   2   0.05% 100.00%\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 4220 Average: 198.483 StdDev: 852.181\n",
      "Min: 5 Max: 6703 Ignored: 0\n",
      "----------------------------------------------\n",
      "[    5,  339) 3913  92.73%  92.73% ##########\n",
      "[  339,  674)  119   2.82%  95.55%\n",
      "[  674, 1009)   32   0.76%  96.30%\n",
      "[ 1009, 1344)   16   0.38%  96.68%\n",
      "[ 1344, 1679)    5   0.12%  96.80%\n",
      "[ 1679, 2014)   14   0.33%  97.13%\n",
      "[ 2014, 2349)    9   0.21%  97.35%\n",
      "[ 2349, 2684)   16   0.38%  97.73%\n",
      "[ 2684, 3019)    4   0.09%  97.82%\n",
      "[ 3019, 3354)   13   0.31%  98.13%\n",
      "[ 3354, 3689)    7   0.17%  98.29%\n",
      "[ 3689, 4024)    0   0.00%  98.29%\n",
      "[ 4024, 4359)    6   0.14%  98.44%\n",
      "[ 4359, 4694)    1   0.02%  98.46%\n",
      "[ 4694, 5029)    2   0.05%  98.51%\n",
      "[ 5029, 5364)    2   0.05%  98.55%\n",
      "[ 5364, 5699)    3   0.07%  98.63%\n",
      "[ 5699, 6034)   17   0.40%  99.03%\n",
      "[ 6034, 6369)    5   0.12%  99.15%\n",
      "[ 6369, 6703]   36   0.85% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t1190 : data:0.11 [NUMERICAL]\n",
      "\t921 : data:0.20 [NUMERICAL]\n",
      "\t285 : data:0.12 [NUMERICAL]\n",
      "\t211 : data:0.0 [NUMERICAL]\n",
      "\t146 : data:0.7 [NUMERICAL]\n",
      "\t143 : data:0.2 [NUMERICAL]\n",
      "\t138 : data:0.5 [NUMERICAL]\n",
      "\t131 : data:0.10 [NUMERICAL]\n",
      "\t129 : data:0.21 [NUMERICAL]\n",
      "\t126 : data:0.3 [NUMERICAL]\n",
      "\t124 : data:0.18 [NUMERICAL]\n",
      "\t124 : data:0.1 [NUMERICAL]\n",
      "\t121 : data:0.4 [NUMERICAL]\n",
      "\t111 : data:0.6 [NUMERICAL]\n",
      "\t63 : data:0.19 [NUMERICAL]\n",
      "\t47 : data:0.23 [NUMERICAL]\n",
      "\t27 : data:0.8 [NUMERICAL]\n",
      "\t8 : data:0.32 [NUMERICAL]\n",
      "\t7 : data:0.35 [NUMERICAL]\n",
      "\t7 : data:0.26 [NUMERICAL]\n",
      "\t6 : data:0.45 [NUMERICAL]\n",
      "\t6 : data:0.22 [NUMERICAL]\n",
      "\t5 : data:0.9 [NUMERICAL]\n",
      "\t5 : data:0.44 [NUMERICAL]\n",
      "\t4 : data:0.33 [NUMERICAL]\n",
      "\t3 : data:0.42 [NUMERICAL]\n",
      "\t3 : data:0.39 [NUMERICAL]\n",
      "\t3 : data:0.37 [NUMERICAL]\n",
      "\t3 : data:0.28 [NUMERICAL]\n",
      "\t3 : data:0.27 [NUMERICAL]\n",
      "\t3 : data:0.25 [NUMERICAL]\n",
      "\t2 : data:0.46 [NUMERICAL]\n",
      "\t2 : data:0.41 [NUMERICAL]\n",
      "\t2 : data:0.40 [NUMERICAL]\n",
      "\t2 : data:0.38 [NUMERICAL]\n",
      "\t2 : data:0.36 [NUMERICAL]\n",
      "\t2 : data:0.34 [NUMERICAL]\n",
      "\t2 : data:0.24 [NUMERICAL]\n",
      "\t1 : data:0.31 [NUMERICAL]\n",
      "\t1 : data:0.29 [NUMERICAL]\n",
      "\t1 : data:0.14 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t15 : data:0.18 [NUMERICAL]\n",
      "\t12 : data:0.19 [NUMERICAL]\n",
      "\t12 : data:0.11 [NUMERICAL]\n",
      "\t9 : data:0.20 [NUMERICAL]\n",
      "\t9 : data:0.12 [NUMERICAL]\n",
      "\t8 : data:0.10 [NUMERICAL]\n",
      "\t7 : data:0.21 [NUMERICAL]\n",
      "\t6 : data:0.7 [NUMERICAL]\n",
      "\t5 : data:0.0 [NUMERICAL]\n",
      "\t4 : data:0.3 [NUMERICAL]\n",
      "\t4 : data:0.2 [NUMERICAL]\n",
      "\t2 : data:0.5 [NUMERICAL]\n",
      "\t2 : data:0.22 [NUMERICAL]\n",
      "\t1 : data:0.6 [NUMERICAL]\n",
      "\t1 : data:0.42 [NUMERICAL]\n",
      "\t1 : data:0.41 [NUMERICAL]\n",
      "\t1 : data:0.4 [NUMERICAL]\n",
      "\t1 : data:0.1 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t38 : data:0.20 [NUMERICAL]\n",
      "\t38 : data:0.11 [NUMERICAL]\n",
      "\t35 : data:0.18 [NUMERICAL]\n",
      "\t25 : data:0.19 [NUMERICAL]\n",
      "\t22 : data:0.12 [NUMERICAL]\n",
      "\t20 : data:0.7 [NUMERICAL]\n",
      "\t15 : data:0.0 [NUMERICAL]\n",
      "\t13 : data:0.21 [NUMERICAL]\n",
      "\t12 : data:0.10 [NUMERICAL]\n",
      "\t10 : data:0.23 [NUMERICAL]\n",
      "\t8 : data:0.1 [NUMERICAL]\n",
      "\t5 : data:0.6 [NUMERICAL]\n",
      "\t5 : data:0.3 [NUMERICAL]\n",
      "\t5 : data:0.2 [NUMERICAL]\n",
      "\t4 : data:0.5 [NUMERICAL]\n",
      "\t3 : data:0.4 [NUMERICAL]\n",
      "\t2 : data:0.22 [NUMERICAL]\n",
      "\t1 : data:0.8 [NUMERICAL]\n",
      "\t1 : data:0.42 [NUMERICAL]\n",
      "\t1 : data:0.41 [NUMERICAL]\n",
      "\t1 : data:0.24 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t98 : data:0.11 [NUMERICAL]\n",
      "\t89 : data:0.20 [NUMERICAL]\n",
      "\t58 : data:0.18 [NUMERICAL]\n",
      "\t42 : data:0.7 [NUMERICAL]\n",
      "\t42 : data:0.12 [NUMERICAL]\n",
      "\t41 : data:0.19 [NUMERICAL]\n",
      "\t24 : data:0.10 [NUMERICAL]\n",
      "\t23 : data:0.0 [NUMERICAL]\n",
      "\t19 : data:0.23 [NUMERICAL]\n",
      "\t18 : data:0.21 [NUMERICAL]\n",
      "\t14 : data:0.1 [NUMERICAL]\n",
      "\t12 : data:0.6 [NUMERICAL]\n",
      "\t12 : data:0.3 [NUMERICAL]\n",
      "\t10 : data:0.2 [NUMERICAL]\n",
      "\t8 : data:0.5 [NUMERICAL]\n",
      "\t5 : data:0.4 [NUMERICAL]\n",
      "\t2 : data:0.35 [NUMERICAL]\n",
      "\t2 : data:0.22 [NUMERICAL]\n",
      "\t1 : data:0.8 [NUMERICAL]\n",
      "\t1 : data:0.42 [NUMERICAL]\n",
      "\t1 : data:0.41 [NUMERICAL]\n",
      "\t1 : data:0.39 [NUMERICAL]\n",
      "\t1 : data:0.32 [NUMERICAL]\n",
      "\t1 : data:0.25 [NUMERICAL]\n",
      "\t1 : data:0.24 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t203 : data:0.11 [NUMERICAL]\n",
      "\t185 : data:0.20 [NUMERICAL]\n",
      "\t80 : data:0.12 [NUMERICAL]\n",
      "\t79 : data:0.18 [NUMERICAL]\n",
      "\t62 : data:0.7 [NUMERICAL]\n",
      "\t50 : data:0.19 [NUMERICAL]\n",
      "\t41 : data:0.0 [NUMERICAL]\n",
      "\t38 : data:0.10 [NUMERICAL]\n",
      "\t32 : data:0.21 [NUMERICAL]\n",
      "\t28 : data:0.23 [NUMERICAL]\n",
      "\t27 : data:0.3 [NUMERICAL]\n",
      "\t24 : data:0.1 [NUMERICAL]\n",
      "\t23 : data:0.2 [NUMERICAL]\n",
      "\t19 : data:0.6 [NUMERICAL]\n",
      "\t14 : data:0.4 [NUMERICAL]\n",
      "\t12 : data:0.5 [NUMERICAL]\n",
      "\t6 : data:0.8 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t3 : data:0.25 [NUMERICAL]\n",
      "\t2 : data:0.45 [NUMERICAL]\n",
      "\t2 : data:0.42 [NUMERICAL]\n",
      "\t2 : data:0.35 [NUMERICAL]\n",
      "\t1 : data:0.44 [NUMERICAL]\n",
      "\t1 : data:0.41 [NUMERICAL]\n",
      "\t1 : data:0.39 [NUMERICAL]\n",
      "\t1 : data:0.37 [NUMERICAL]\n",
      "\t1 : data:0.33 [NUMERICAL]\n",
      "\t1 : data:0.32 [NUMERICAL]\n",
      "\t1 : data:0.27 [NUMERICAL]\n",
      "\t1 : data:0.26 [NUMERICAL]\n",
      "\t1 : data:0.24 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t631 : data:0.11 [NUMERICAL]\n",
      "\t513 : data:0.20 [NUMERICAL]\n",
      "\t175 : data:0.12 [NUMERICAL]\n",
      "\t113 : data:0.18 [NUMERICAL]\n",
      "\t106 : data:0.0 [NUMERICAL]\n",
      "\t99 : data:0.7 [NUMERICAL]\n",
      "\t78 : data:0.10 [NUMERICAL]\n",
      "\t64 : data:0.2 [NUMERICAL]\n",
      "\t62 : data:0.1 [NUMERICAL]\n",
      "\t61 : data:0.21 [NUMERICAL]\n",
      "\t59 : data:0.19 [NUMERICAL]\n",
      "\t58 : data:0.3 [NUMERICAL]\n",
      "\t56 : data:0.5 [NUMERICAL]\n",
      "\t47 : data:0.6 [NUMERICAL]\n",
      "\t44 : data:0.4 [NUMERICAL]\n",
      "\t38 : data:0.23 [NUMERICAL]\n",
      "\t15 : data:0.8 [NUMERICAL]\n",
      "\t6 : data:0.22 [NUMERICAL]\n",
      "\t5 : data:0.35 [NUMERICAL]\n",
      "\t4 : data:0.44 [NUMERICAL]\n",
      "\t4 : data:0.26 [NUMERICAL]\n",
      "\t3 : data:0.32 [NUMERICAL]\n",
      "\t3 : data:0.25 [NUMERICAL]\n",
      "\t2 : data:0.9 [NUMERICAL]\n",
      "\t2 : data:0.45 [NUMERICAL]\n",
      "\t2 : data:0.42 [NUMERICAL]\n",
      "\t2 : data:0.41 [NUMERICAL]\n",
      "\t2 : data:0.38 [NUMERICAL]\n",
      "\t2 : data:0.37 [NUMERICAL]\n",
      "\t2 : data:0.27 [NUMERICAL]\n",
      "\t2 : data:0.24 [NUMERICAL]\n",
      "\t1 : data:0.46 [NUMERICAL]\n",
      "\t1 : data:0.40 [NUMERICAL]\n",
      "\t1 : data:0.39 [NUMERICAL]\n",
      "\t1 : data:0.36 [NUMERICAL]\n",
      "\t1 : data:0.34 [NUMERICAL]\n",
      "\t1 : data:0.33 [NUMERICAL]\n",
      "\t1 : data:0.28 [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t4120 : HigherCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t100 : HigherCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t264 : HigherCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t526 : HigherCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t945 : HigherCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t2267 : HigherCondition\n",
      "Node format: NOT_SET\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.996485 logloss:0.126711\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.995911 logloss:0.0663482\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.997015 logloss:0.0383829\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.997254 logloss:0.0306119\n",
      "\ttrees: 41, Out-of-bag evaluation: accuracy:0.997373 logloss:0.0267929\n",
      "\ttrees: 51, Out-of-bag evaluation: accuracy:0.997373 logloss:0.0265672\n",
      "\ttrees: 61, Out-of-bag evaluation: accuracy:0.997612 logloss:0.0229495\n",
      "\ttrees: 71, Out-of-bag evaluation: accuracy:0.997612 logloss:0.0231856\n",
      "\ttrees: 81, Out-of-bag evaluation: accuracy:0.997732 logloss:0.0194937\n",
      "\ttrees: 91, Out-of-bag evaluation: accuracy:0.997732 logloss:0.0197469\n",
      "\ttrees: 100, Out-of-bag evaluation: accuracy:0.997732 logloss:0.0198674\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rf_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b594c40-eec6-4cff-afc6-c93870de0de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(num_examples=8376, accuracy=0.9977316141356256, loss=0.019867436299874395, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##uncomment to show training log\n",
    "#rf_model_train.make_inspector().training_logs()\n",
    "rf_model.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7078a13f-031f-4516-befd-3e8bbad12679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.979999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8376 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2    3    4    5    6    7    8    9    10\n",
       "0     0.000000  0.020000  0.979999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1     0.000000  0.999999  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2     0.999999  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3     0.999999  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4     0.999999  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "8371  0.000000  0.999999  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8372  0.000000  0.999999  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8373  0.999999  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8374  0.999999  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8375  0.000000  0.999999  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[8376 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_model.predict(x_train[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I',\n",
    "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8af3edc9-2e32-4bc8-8c5b-5bf3085d8060",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = rf_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.evaluation.num_examples for log in logs], [log.evaluation.loss for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0dbb-2532-4c3a-b053-1f6f687be79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f8956",
   "metadata": {},
   "source": [
    "Helpful Links: <br>\n",
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 <br>\n",
    "https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py <BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032bd29",
   "metadata": {},
   "source": [
    "**Model 2.1: CNN (layers added, ResNet-18)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b198024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: Satellite Images, 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,1,11), name='Input_Street')\n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(11, (4,4), activation=\"relu\")(input1)\n",
    "    pooling = tf.keras.layers.MaxPooling2D((4, 4), strides=2)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "    combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet = resnet18(combined)\n",
    "    output = tf.keras.layers.Dense(units=12, activation='softmax', name='output')(resnet)\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "class_weight = {0: 100,\n",
    "                1: 1000,\n",
    "                2: 1000,\n",
    "                3: 1000,\n",
    "                4: 1000,\n",
    "                5: 1000,\n",
    "                6: 1000,\n",
    "                7: 1000,\n",
    "                8: 1000,\n",
    "                9: 1000,\n",
    "                10: 1000,\n",
    "                11: 1000,\n",
    "               }\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [images_mini, street_mini],\n",
    "    np.stack(y_train),\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2,\n",
    "    class_weight = class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529937cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6816d-4465-4a90-b2f4-6930be4d6efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b29fdc-932b-4504-813b-a692525348e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = cnn_model.predict([images_mini_t, street_mini_t])\n",
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fbae2-bbfa-416f-ba2c-7fae81b75d67",
   "metadata": {},
   "source": [
    "**Model 2.2: Second CNN (layers added, ResNet-34)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb0ab1-0afc-439b-823b-43932327e271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: Satellite Images, 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,1,11), name='Input_Street')\n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(11, (4,4), activation=\"relu\")(input1)\n",
    "    pooling = tf.keras.layers.MaxPooling2D((4, 4), strides=2)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "    combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet = resnet34(combined)\n",
    "    output = tf.keras.layers.Dense(units=12, activation='softmax', name='output')(resnet)\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "class_weight = {0: 100,\n",
    "                1: 1000,\n",
    "                2: 1000,\n",
    "                3: 1000,\n",
    "                4: 1000,\n",
    "                5: 1000,\n",
    "                6: 1000,\n",
    "                7: 1000,\n",
    "                8: 1000,\n",
    "                9: 1000,\n",
    "                10: 1000,\n",
    "                11: 1000,\n",
    "               }\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [images_mini, street_mini],\n",
    "    np.stack(y_train),\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2,\n",
    "    class_weight = class_weight, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dbe4a-ea51-4ab3-9b86-6906419144b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb61fd5-f83f-48fc-b445-ff2169f5c885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb71b6e-667c-47fd-b36a-2ffe39bd22f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_result = cnn_model.predict([images_mini_t, street_mini_t])\n",
    "predicted_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718b71a-4e14-4e1a-b17e-ffdb5e6f9d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "test_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661b615-bbdb-43e4-9dee-23150f18c9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2117f5-3472-44d7-9b22-cba0914012d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b54cf29-9972-4d60-9493-25bc651ada7f",
   "metadata": {},
   "source": [
    "**Model 2.3: CNN (layers concatenated, ResNet-18)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3c69b-3b60-4e5e-a7fd-1005eecfec1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street_mini_2 = [] \n",
    "for k in range(len(street)):\n",
    "    for i in range(71): \n",
    "        for j in range(91):\n",
    "            street_mini_2.append(street[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b975a2-c6dc-4f07-a4ae-5c83d1bf9aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street_mini_2 = np.reshape(street_mini_2, (len(street),71,91,11))\n",
    "np.shape(street_mini_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44b747-8c12-427e-9d12-010dcfdd6c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe3d33-18de-4e73-9735-c1faaf102f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: Satellite Images, 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(71,91,11), name='Input_Street')\n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(11, (4,4), activation=\"relu\")(input1)\n",
    "    pooling = tf.keras.layers.MaxPooling2D((4, 4), strides=2)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    combined = tf.keras.layers.Concatenate(axis = 3)([images.output, input2])\n",
    "    #combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet = resnet18(combined)\n",
    "    output = tf.keras.layers.Dense(units=12, activation='softmax', name='output')(resnet)\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "class_weight = {0: 100,\n",
    "                1: 1000,\n",
    "                2: 1000,\n",
    "                3: 1000,\n",
    "                4: 1000,\n",
    "                5: 1000,\n",
    "                6: 1000,\n",
    "                7: 1000,\n",
    "                8: 1000,\n",
    "                9: 1000,\n",
    "                10: 1000,\n",
    "                11: 1000,\n",
    "               }\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [images_mini, street_mini_2],\n",
    "    np.stack(y_train),\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2,\n",
    "    class_weight = class_weight,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56133e1d-a889-4fb4-8850-a8afeb3e9ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecba962-271b-4404-80a8-acc856cb8696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb65fa-626e-4355-b319-3f3bc190dd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street_mini_2_t = [] \n",
    "for k in range(len(street_t)):\n",
    "    for i in range(71): \n",
    "        for j in range(91):\n",
    "            street_mini_2_t.append(street_t[k])\n",
    "street_mini_2_t = np.reshape(street_mini_2_t, (len(street_t),71,91,11))\n",
    "np.shape(street_mini_2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2525c-833a-494c-92de-ae16b52dec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = cnn_model.predict([images_mini_t, street_mini_2_t])\n",
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ccfec-b018-48a1-9be9-45e67d98c005",
   "metadata": {},
   "source": [
    "**Model 2.4 CNN (layers added, RESNET 50 FROM TENSORFLOW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fd1a2-6a63-4219-b710-aa2aa2b8c5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: Satellite Images, 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,1,11), name='Input_Street')\n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(11, (4,4), activation=\"relu\")(input1)\n",
    "    pooling = tf.keras.layers.MaxPooling2D((4, 4), strides=2)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "    combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    # RESNET50 FROM TENSORFLOW \n",
    "    resnet = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_tensor=combined,\n",
    "    input_shape=(71, 91, 11,),\n",
    "    pooling=None,\n",
    "    classes=12,\n",
    "    #**kwargs\n",
    "    )\n",
    "    \n",
    "    flatten = tf.keras.layers.Flatten()(resnet.output)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(units=12, activation='softmax', name='output')(flatten)\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model #cnn_model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= ['sparse_categorical_crossentropy'],\n",
    "    metrics = ['accuracy'],\n",
    "    )\n",
    "\n",
    "class_weight = {0: 100,\n",
    "                1: 1000,\n",
    "                2: 1000,\n",
    "                3: 1000,\n",
    "                4: 1000,\n",
    "                5: 1000,\n",
    "                6: 1000,\n",
    "                7: 1000,\n",
    "                8: 1000,\n",
    "                9: 1000,\n",
    "                10: 1000,\n",
    "                11: 1000,\n",
    "               }\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [images_mini, street_mini],\n",
    "    np.stack(y_train),\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2,\n",
    "    class_weight = class_weight,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92081966-4f86-4889-a4bc-1d970d678459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f399215-cee3-458b-8b16-28857072dc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491af29-b55b-4f1f-a061-c4887ddb538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = cnn_model.predict([images_mini_t, street_mini_t])\n",
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739af5b-a7e3-4888-964f-3c9f68c83fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
