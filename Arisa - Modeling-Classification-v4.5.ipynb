{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 01:07:35.372382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 01:07:37.209815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-26 01:07:37.209855: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-26 01:07:41.502933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-26 01:07:41.503171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-26 01:07:41.503184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow_addons as tfa\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9459b53d-c4e9-4304-9ea5-699ebb32f4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_f1(history):\n",
    "    plt.plot(history.history['f1'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1']),\n",
    "                max(history.history['val_f1'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd28b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x1 = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x2 = make_layer(x1, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x3 = make_layer(x2, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x4 = make_layer(x3, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x4)\n",
    "    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    return resnet(x, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Pulling in Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_train = pd.read_csv(r'./Data/Tiles_TRAIN.csv')\n",
    "#x_train = tiles_train.drop(['bins_numeric'], axis = 1)\n",
    "#y_train = tiles_train['bins_numeric']\n",
    "#x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6453b058-407b-4097-a463-b18eb8ebb124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>11426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>13993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>3201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>13779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "1762     1526         0.0                0.0       0.0                    0.0   \n",
       "4603    11426         0.0                7.0       0.0                    8.0   \n",
       "6484    13993         0.0                0.0       0.0                    0.0   \n",
       "6950     3201         0.0                0.0       0.0                    0.0   \n",
       "4254    13779         0.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "1762        0        1        0        0        0  ...      0      0      0   \n",
       "4603        0        1        0        0        0  ...      0      0      0   \n",
       "6484        0        1        0        0        0  ...      0      0      0   \n",
       "6950        0        1        0        0        0  ...      0      0      0   \n",
       "4254        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "1762      0      0      0      0      0      0      0  \n",
       "4603      0      0      0      0      0      0      0  \n",
       "6484      0      0      0      0      0      0      1  \n",
       "6950      1      0      0      0      0      0      0  \n",
       "4254      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(tiles_train.drop(['bins_numeric'], axis = 1), tiles_train['bins_numeric'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5971c10e-9c78-4cd5-bf77-a213f4e70ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>7123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>12171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td>1096</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "2732     2948         0.0                0.0       0.0                    0.0   \n",
       "630      2945         4.0                0.0       2.0                    1.0   \n",
       "2887     7123         1.0                0.0       0.0                    0.0   \n",
       "752     12171         0.0                0.0       2.0                    1.0   \n",
       "8106     1096         2.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "2732        0        1        0        0        0  ...      0      0      0   \n",
       "630         0        1        0        0        0  ...      0      0      0   \n",
       "2887        0        1        0        0        0  ...      0      0      0   \n",
       "752         0        1        0        0        0  ...      0      0      0   \n",
       "8106        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "2732      0      0      0      0      0      0      0  \n",
       "630       0      0      0      0      0      0      0  \n",
       "2887      0      0      0      0      0      0      0  \n",
       "752       0      0      0      0      0      0      0  \n",
       "8106      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18a322c-14fa-44a5-89ec-8b6ae7411008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>94101</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  RTTYP_I  \\\n",
       "0         0.0                0.0       0.0                    0.0        0   \n",
       "1         1.0                0.0       3.0                    6.0        0   \n",
       "2         0.0                0.0       0.0                    0.0        0   \n",
       "3         0.0                0.0       0.0                    0.0        0   \n",
       "4         0.0                0.0       0.0                    0.0        0   \n",
       "\n",
       "   RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  94101  ...  94129  94130  94131  94132  \\\n",
       "0        1        0        0        0      0  ...      0      0      0      1   \n",
       "1        1        0        0        0      0  ...      0      0      0      0   \n",
       "2        1        0        0        0      0  ...      0      0      0      0   \n",
       "3        1        0        0        0      0  ...      0      1      0      0   \n",
       "4        1        0        0        0      0  ...      0      0      0      0   \n",
       "\n",
       "   94133  94134  94141  94143  94158  94188  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      1      0      0      0      0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_test = pd.read_csv(r'./Data/Tiles_TEST.csv')\n",
    "x_test = tiles_test.drop(['Tile_ID','bins_numeric'], axis = 1)\n",
    "y_test = tiles_test['bins_numeric']\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 148, 188, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini = preprocess_data_part1(IMAGE_PATH)\n",
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e4bbbe-914b-47dd-9e82-93722404f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e1f01e-fc42-4bb8-9d18-e40fe8d215c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part15(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_val['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcfd6d0-bf6d-48b1-a404-00afbc2b9633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 148, 188, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_v = preprocess_data_part15(IMAGE_PATH)\n",
    "np.shape(images_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c499c7-9ec4-4f6c-8e9c-482de86f536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23790420-0c98-426f-8580-23f7d96e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part2(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in tiles_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8e3f65-2368-4092-9b09-ecda4e0a35d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 148, 188, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_t = preprocess_data_part2(IMAGE_PATH)\n",
    "np.shape(images_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 1, 1, 39)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "street = np.asarray(x_train).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c923520c-ed3c-4165-abd9-7b3cc932b35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 1, 1, 39)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAL SET \n",
    "\n",
    "street_v = np.asarray(x_val).astype('float32')\n",
    "street_mini_v = []\n",
    "for row in range(len(street_v)):\n",
    "    street_mini_v.append([[street_v[row]]])\n",
    "street_mini_v = np.stack(street_mini_v)\n",
    "np.shape(street_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c28b0428-174b-4e10-b151-1354cf44bf79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 1, 1, 39)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST SET \n",
    "\n",
    "street_t = np.asarray(x_test).astype('float32')\n",
    "street_mini_t = []\n",
    "for row in range(len(street_t)):\n",
    "    street_mini_t.append([[street_t[row]]])\n",
    "street_mini_t = np.stack(street_mini_t)\n",
    "np.shape(street_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0dbb-2532-4c3a-b053-1f6f687be79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f8956",
   "metadata": {},
   "source": [
    "Helpful Links: <br>\n",
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 <br>\n",
    "https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py <BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032bd29",
   "metadata": {},
   "source": [
    "**Model 2.4.0: Baseline (Best From Stage 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b198024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# # x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# # y: Future collision bin\n",
    "\n",
    "# # ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# # THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# # REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "# def create_cnn_model():\n",
    "\n",
    "#     # INPUT LAYERS\n",
    "#     input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "#     input2 = tf.keras.layers.Input(shape=(1,1,39), name='Input_Street') \n",
    "    \n",
    "#     #CNN FOR IMAGE PROCESSING\n",
    "#     cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(input1) # layers = street data dimension\n",
    "#     pooling = tf.keras.layers.MaxPooling2D((2, 2), strides=1)(cnn)\n",
    "#     images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "#     #ADDING STREET DATA\n",
    "#     #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "#     combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "#     # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "#     resnet = resnet18(combined)\n",
    "#     output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(resnet) # units = number of classes\n",
    "    \n",
    "#     #instantiation layer \n",
    "#     cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "#     return cnn_model\n",
    "\n",
    "# cnn_model = create_cnn_model()\n",
    "\n",
    "# cnn_model.summary()\n",
    "\n",
    "# f1 = tfa.metrics.F1Score(\n",
    "#     num_classes = 11,\n",
    "#     average = 'macro',\n",
    "#     threshold = None,\n",
    "#     name = 'f1',\n",
    "#     )\n",
    "\n",
    "# cnn_model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics = ['accuracy', f1])\n",
    "\n",
    "# class_weight = {0: 1,\n",
    "#                 1: 10,\n",
    "#                 2: 10,\n",
    "#                 3: 10,\n",
    "#                 4: 10,\n",
    "#                 5: 10,\n",
    "#                 6: 10,\n",
    "#                 7: 10,\n",
    "#                 8: 10,\n",
    "#                 9: 10,\n",
    "#                 10: 10,\n",
    "#                 # 11: 10,\n",
    "#                }\n",
    "\n",
    "# y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "# y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "# cnn_model.layers[-1].bias.assign([0,0,0,0,0,0,0,0,0,0,0]) # no bias\n",
    "\n",
    "# history = cnn_model.fit(\n",
    "#     [images_mini, street_mini],\n",
    "#     y_t,\n",
    "#     epochs=10,\n",
    "#     # Suppress logging.\n",
    "#      verbose=1,\n",
    "#     validation_data=([images_mini_v, street_mini_v], y_v),\n",
    "#     # Calculate validation results on 20% of the training data.\n",
    "#     #validation_split = 0.2,\n",
    "#     class_weight = class_weight\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "529937cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efd6816d-4465-4a90-b2f4-6930be4d6efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f08af3e9-1d63-4692-8c55-3b026165818f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62229db9-d5df-40ae-a7a6-b6f4b5c0195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = cnn_model.predict([images_mini_v, street_mini_v])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abfec036-19d0-44e7-8ef8-bfc6ad648f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_values = []\n",
    "# for i in y_pred: \n",
    "#     input_list = i\n",
    "#     max_value = max(input_list)\n",
    "#     index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "#     pred_values.append(index[0])\n",
    "# pred_values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b42084-924f-47ab-9106-7b0e61f668e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = list(y_val)\n",
    "# y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa293b67-66ca-45a3-abff-1fdfbd3a648e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_true, pred_values)\n",
    "# df_cm = pd.DataFrame(cm, index = [i for i in \"0123456789\"],\n",
    "#                   columns = [i for i in \"0123456789\"])\n",
    "# df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b610655-b969-43a7-bc06-75cd6d3a1ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # saving initial weights to be used in other models\n",
    "# import tempfile\n",
    "# initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "# cnn_model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fec7ce-3248-4ceb-8f73-a04a58e0beb2",
   "metadata": {},
   "source": [
    "**Model 2.4.1: Initial Bias Corrected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be1a18dc-6c57-4d53-8da6-5fce036926b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "# pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "# print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c010a935-6b80-484b-8d96-4ef5e90fb036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial_bias = []\n",
    "# for i in range(len(pivot['ones'])):\n",
    "#     b = np.log(pivot['ones'][i] / (sum(pivot['ones'][:i]) + sum(pivot['ones'][i + 1:])))\n",
    "#     initial_bias.append(b)\n",
    "# initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fb0a9d6-a962-4ea5-bfd5-b717023da145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# # x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# # y: Future collision bin\n",
    "\n",
    "# # ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# # THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# # REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "# def create_cnn_model1(output_bias = None):\n",
    "\n",
    "#     # INPUT LAYERS\n",
    "#     input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "#     input2 = tf.keras.layers.Input(shape=(1,1,39), name='Input_Street') \n",
    "    \n",
    "#     #CNN FOR IMAGE PROCESSING\n",
    "#     cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(input1) # layers = street data dimension\n",
    "#     pooling = tf.keras.layers.MaxPooling2D((2, 2), strides=1)(cnn)\n",
    "#     images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "#     #ADDING STREET DATA\n",
    "#     #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "#     combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "#     # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "#     resnet = resnet18(combined)\n",
    "    \n",
    "#     if output_bias is not None:\n",
    "#         # initial bias added\n",
    "#         output_bias = tf.keras.initializers.Constant(output_bias)    \n",
    "#         output = tf.keras.layers.Dense(units=11, activation='softmax', name='output', bias_initializer=output_bias)(resnet) # units = number of classes\n",
    "#     else: \n",
    "#         output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(resnet) # units = number of classes\n",
    "        \n",
    "#     #instantiation layer \n",
    "#     cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "#     return cnn_model\n",
    "\n",
    "# # initial bias added\n",
    "# cnn_model1 = create_cnn_model1(output_bias = initial_bias)\n",
    "\n",
    "# cnn_model1.summary()\n",
    "\n",
    "# f1 = tfa.metrics.F1Score(\n",
    "#     num_classes = 11,\n",
    "#     average = 'macro',\n",
    "#     threshold = None,\n",
    "#     name = 'f1',\n",
    "#     )\n",
    "\n",
    "# cnn_model1.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics = ['accuracy', f1])\n",
    "\n",
    "# class_weight = {0: 1,\n",
    "#                 1: 10,\n",
    "#                 2: 10,\n",
    "#                 3: 10,\n",
    "#                 4: 10,\n",
    "#                 5: 10,\n",
    "#                 6: 10,\n",
    "#                 7: 10,\n",
    "#                 8: 10,\n",
    "#                 9: 10,\n",
    "#                 10: 10,\n",
    "#                 # 11: 10,\n",
    "#                }\n",
    "\n",
    "# y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "# y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "# cnn_model1.load_weights(initial_weights) # initial weights from first model to make it comparable\n",
    "\n",
    "# history = cnn_model1.fit(\n",
    "#     [images_mini, street_mini],\n",
    "#     y_t,\n",
    "#     epochs=10,\n",
    "#     # Suppress logging.\n",
    "#      verbose=1,\n",
    "#     validation_data=([images_mini_v, street_mini_v], y_v),\n",
    "#     # Calculate validation results on 20% of the training data.\n",
    "#     #validation_split = 0.2,\n",
    "#     class_weight = class_weight\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "946920ad-d75c-4cdd-905a-d7e22e0939b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7707c3f5-3f2d-4ddd-aaa5-bb4336ad371a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4633ec21-b3fd-473e-a78b-f1e052b3a353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "167aea8d-42bc-4294-9ea3-8f33161abe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = cnn_model.predict([images_mini_v, street_mini_v])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33b7b23c-0188-4166-89b2-5be226d77607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_values1 = []\n",
    "# for i in y_pred: \n",
    "#     input_list = i\n",
    "#     max_value = max(input_list)\n",
    "#     index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "#     pred_values1.append(index[0])\n",
    "# pred_values1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75c99ea9-9e4a-4451-9602-daecdf7cee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = list(y_val)\n",
    "# y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4171cae-c571-434c-99a0-f2b1d5e87e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_true, pred_values1)\n",
    "# df_cm = pd.DataFrame(cm, index = [i for i in \"0123456789\"],\n",
    "#                   columns = [i for i in \"0123456789\"])\n",
    "# df_cm\n",
    "# #plt.figure(figsize = (10,7))\n",
    "# #sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a317ad-47e8-4231-86c5-53050ec292b7",
   "metadata": {},
   "source": [
    "**Model 2.4.2: Class Weights Corrected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6f31c0f-9c01-4eb7-8f51-ec1c3f89da94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ones\n",
      "bins      \n",
      "0     5297\n",
      "1      108\n",
      "2      968\n",
      "3      230\n",
      "4       22\n",
      "5        4\n",
      "6       53\n",
      "7       11\n",
      "8        3\n",
      "9        1\n",
      "10       3\n"
     ]
    }
   ],
   "source": [
    "check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51f2f736-eff9-46cd-a34d-7ad33d220fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.11498790052688486,\n",
       " 1: 5.63973063973064,\n",
       " 2: 0.6292261457550714,\n",
       " 3: 2.6482213438735176,\n",
       " 4: 27.68595041322314,\n",
       " 5: 152.27272727272728,\n",
       " 6: 11.492281303602057,\n",
       " 7: 55.37190082644628,\n",
       " 8: 203.03030303030303,\n",
       " 9: 609.0909090909091,\n",
       " 10: 203.03030303030303}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df382dc-8891-45eb-8c2b-2d596c423b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_Images (InputLayer)      [(None, 148, 188, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 187, 39  663         ['Input_Images[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 95, 95, 39)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " Input_Street (InputLayer)      [(None, 1, 1, 39)]   0           []                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 95, 95, 39)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'Input_Street[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 101, 101, 39  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 48, 48, 64)   122304      ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 48, 48, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " relu1 (ReLU)                   (None, 48, 48, 64)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " maxpool_pad (ZeroPadding2D)    (None, 50, 50, 64)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " maxpool (MaxPooling2D)         (None, 24, 24, 64)   0           ['maxpool_pad[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['maxpool[0][0]']                \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.0.conv1 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.0.bn1 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.0.relu1 (ReLU)          (None, 24, 24, 64)   0           ['layer1.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.0.conv2_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.0.conv2 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.0.bn2 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.0.add (Add)             (None, 24, 24, 64)   0           ['maxpool[0][0]',                \n",
      "                                                                  'layer1.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.0.relu2 (ReLU)          (None, 24, 24, 64)   0           ['layer1.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.1.conv1 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.1.bn1 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.1.relu1 (ReLU)          (None, 24, 24, 64)   0           ['layer1.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.conv2_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.1.conv2 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.1.bn2 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.1.add (Add)             (None, 24, 24, 64)   0           ['layer1.0.relu2[0][0]',         \n",
      "                                                                  'layer1.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.relu2 (ReLU)          (None, 24, 24, 64)   0           ['layer1.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.conv1 (Conv2D)        (None, 12, 12, 128)  73728       ['layer2.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.0.bn1 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.0.relu1 (ReLU)          (None, 12, 12, 128)  0           ['layer2.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.conv2_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.downsample.0 (Conv2D)  (None, 12, 12, 128)  8192       ['layer1.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer2.0.conv2 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.0.downsample.1 (BatchNo  (None, 12, 12, 128)  512        ['layer2.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer2.0.bn2 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.0.add (Add)             (None, 12, 12, 128)  0           ['layer2.0.downsample.1[0][0]',  \n",
      "                                                                  'layer2.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.relu2 (ReLU)          (None, 12, 12, 128)  0           ['layer2.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.conv1_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.1.conv1 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.1.bn1 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.1.relu1 (ReLU)          (None, 12, 12, 128)  0           ['layer2.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.conv2_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.1.conv2 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.1.bn2 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.1.add (Add)             (None, 12, 12, 128)  0           ['layer2.0.relu2[0][0]',         \n",
      "                                                                  'layer2.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.relu2 (ReLU)          (None, 12, 12, 128)  0           ['layer2.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.conv1_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.conv1 (Conv2D)        (None, 6, 6, 256)    294912      ['layer3.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.0.bn1 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.0.relu1 (ReLU)          (None, 6, 6, 256)    0           ['layer3.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.conv2_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.downsample.0 (Conv2D)  (None, 6, 6, 256)   32768       ['layer2.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer3.0.conv2 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.0.downsample.1 (BatchNo  (None, 6, 6, 256)   1024        ['layer3.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer3.0.bn2 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.0.add (Add)             (None, 6, 6, 256)    0           ['layer3.0.downsample.1[0][0]',  \n",
      "                                                                  'layer3.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.relu2 (ReLU)          (None, 6, 6, 256)    0           ['layer3.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.conv1_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.1.conv1 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.1.bn1 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.1.relu1 (ReLU)          (None, 6, 6, 256)    0           ['layer3.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.conv2_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.1.conv2 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.1.bn2 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.1.add (Add)             (None, 6, 6, 256)    0           ['layer3.0.relu2[0][0]',         \n",
      "                                                                  'layer3.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.relu2 (ReLU)          (None, 6, 6, 256)    0           ['layer3.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.conv1_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.0.conv1 (Conv2D)        (None, 3, 3, 512)    1179648     ['layer4.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.0.bn1 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.0.relu1 (ReLU)          (None, 3, 3, 512)    0           ['layer4.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.conv2_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.0.downsample.0 (Conv2D)  (None, 3, 3, 512)   131072      ['layer3.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer4.0.conv2 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.0.downsample.1 (BatchNo  (None, 3, 3, 512)   2048        ['layer4.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer4.0.bn2 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.0.add (Add)             (None, 3, 3, 512)    0           ['layer4.0.downsample.1[0][0]',  \n",
      "                                                                  'layer4.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.relu2 (ReLU)          (None, 3, 3, 512)    0           ['layer4.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.conv1_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.1.conv1 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.1.bn1 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.1.relu1 (ReLU)          (None, 3, 3, 512)    0           ['layer4.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.conv2_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.1.conv2 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.1.bn2 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.1.add (Add)             (None, 3, 3, 512)    0           ['layer4.0.relu2[0][0]',         \n",
      "                                                                  'layer4.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.relu2 (ReLU)          (None, 3, 3, 512)    0           ['layer4.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " avgpool (GlobalAveragePooling2  (None, 512)         0           ['layer4.1.relu2[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 11)           5643        ['avgpool[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 11)           132         ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,305,446\n",
      "Trainable params: 11,295,846\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 01:11:45.691570: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2982732800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/capstone/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "210/210 [==============================] - 20372s 97s/step - loss: 2.5534 - accuracy: 0.6007 - precision: 0.2548 - f1: 0.1240 - val_loss: 1.5345 - val_accuracy: 0.6599 - val_precision: 0.3333 - val_f1: 0.1242\n",
      "Epoch 3/10\n",
      "204/210 [============================>.] - ETA: 9:31 - loss: 2.4032 - accuracy: 0.6255 - precision: 0.2072 - f1: 0.1287 "
     ]
    }
   ],
   "source": [
    "# From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# y: Future collision bin\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,1,39), name='Input_Street') \n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(input1) # layers = street data dimension\n",
    "    pooling = tf.keras.layers.MaxPooling2D((53, 93), strides=1)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "    combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet = resnet18(combined, num_classes=11)\n",
    "    output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(resnet) # units = number of classes\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model1 = create_cnn_model()\n",
    "\n",
    "cnn_model1.summary()\n",
    "\n",
    "f1 = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'macro',\n",
    "    threshold = None,\n",
    "    name = 'f1',\n",
    "    )\n",
    "\n",
    "cnn_model1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy', keras.metrics.Precision(), f1])\n",
    "\n",
    "# calculated in previous block \n",
    "# class_weight = {0: 1,\n",
    "#                 1: 10,\n",
    "#                 2: 10,\n",
    "#                 3: 10,\n",
    "#                 4: 10,\n",
    "#                 5: 10,\n",
    "#                 6: 10,\n",
    "#                 7: 10,\n",
    "#                 8: 10,\n",
    "#                 9: 10,\n",
    "#                 10: 10,\n",
    "#                 # 11: 10,\n",
    "#                }\n",
    "\n",
    "y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "#cnn_model1.load_weights(initial_weights) # initial weights from first or baseline model to make it comparable\n",
    "#cnn_model1.layers[-1].bias.assign([0,0,0,0,0,0,0,0,0,0,0]) # no bias, makes it more comparable to baseline model\n",
    "\n",
    "history = cnn_model1.fit(\n",
    "    [images_mini, street_mini],\n",
    "    y_t,\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    validation_data=([images_mini_v, street_mini_v], y_v),\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    #validation_split = 0.2,\n",
    "    class_weight = class_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24906433-8b57-49a7-bca5-953ce430abbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae047e9-65b4-4f83-bf9d-24a52a6b41fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887aecd8-8007-4c30-88d1-d75e19274646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b6d2b-7e42-4735-9daa-9ddbe03bcec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = cnn_model1.predict([images_mini_v, street_mini_v])\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0a1ba-004e-419e-bb54-dade818b80e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values2 = []\n",
    "for i in y_pred2: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values2.append(index[0])\n",
    "pred_values2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91fa216-9f07-405a-a811-f0ae74bf9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_val)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d96428-d36e-4cc4-86a4-03921ff7e9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values2)\n",
    "ind = max(len(np.unique(y_true)), len(np.unique(pred_values2)))\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "                  columns = [i for i in range(ind)])\n",
    "df_cm\n",
    "#plt.figure(figsize = (10,7))\n",
    "#sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020edd3a-0c97-45f9-875d-3df38db9251f",
   "metadata": {},
   "source": [
    "**Model 2.4.2: Class Weights Corrected 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af93dd1e-4394-4ba2-ac1c-593d00d2bff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ones\n",
      "bins      \n",
      "0     5297\n",
      "1      108\n",
      "2      968\n",
      "3      230\n",
      "4       22\n",
      "5        4\n",
      "6       53\n",
      "7       11\n",
      "8        3\n",
      "9        1\n",
      "10       3\n"
     ]
    }
   ],
   "source": [
    "check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42e82273-164e-45f2-86f3-5c7de058c9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.11498790052688486,\n",
       " 1: 5.63973063973064,\n",
       " 2: 0.6292261457550714,\n",
       " 3: 2.6482213438735176,\n",
       " 4: 27.68595041322314,\n",
       " 5: 152.27272727272728,\n",
       " 6: 11.492281303602057,\n",
       " 7: 55.37190082644628,\n",
       " 8: 203.03030303030303,\n",
       " 9: 609.0909090909091,\n",
       " 10: 203.03030303030303}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91c34f-cb4c-47c3-bb19-4540b41de68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# y: Future collision bin\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,1,39), name='Input_Street') \n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(input1) # layers = street data dimension\n",
    "    pooling = tf.keras.layers.MaxPooling2D((53, 93), strides=1)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "    combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet = resnet18(combined)\n",
    "    output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(resnet) # units = number of classes\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model1 = create_cnn_model()\n",
    "\n",
    "cnn_model1.summary()\n",
    "\n",
    "f1 = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'macro',\n",
    "    threshold = None,\n",
    "    name = 'f1',\n",
    "    )\n",
    "\n",
    "cnn_model1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy', keras.metrics.Precision(), f1])\n",
    "\n",
    "# calculated in previous block \n",
    "# class_weight = {0: 1,\n",
    "#                 1: 10,\n",
    "#                 2: 10,\n",
    "#                 3: 10,\n",
    "#                 4: 10,\n",
    "#                 5: 10,\n",
    "#                 6: 10,\n",
    "#                 7: 10,\n",
    "#                 8: 10,\n",
    "#                 9: 10,\n",
    "#                 10: 10,\n",
    "#                 # 11: 10,\n",
    "#                }\n",
    "\n",
    "y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "#cnn_model1.load_weights(initial_weights) # initial weights from first or baseline model to make it comparable\n",
    "#cnn_model1.layers[-1].bias.assign([0,0,0,0,0,0,0,0,0,0,0]) # no bias, makes it more comparable to baseline model\n",
    "\n",
    "history = cnn_model1.fit(\n",
    "    [images_mini, street_mini],\n",
    "    y_t,\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    validation_data=([images_mini_v, street_mini_v], y_v),\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    #validation_split = 0.2,\n",
    "    class_weight = class_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccdeff-f234-4fe1-b16b-c5db3c38830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c6bdb-832f-43fa-bcf9-d5908aafdb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76d6d6-5d2e-4e47-9563-90edcd9e797b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe81ee-3020-46ca-a1eb-93acd0da22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = cnn_model1.predict([images_mini_v, street_mini_v])\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b563fc-8984-4b33-9ede-bee946fa2f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values2 = []\n",
    "for i in y_pred2: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values2.append(index[0])\n",
    "pred_values2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862034d-b68b-4ebc-92dd-f0cbf5f39c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_val)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a56d10-ec48-4cb6-9e9a-10490eb6ac37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values2)\n",
    "ind = max(len(np.unique(y_true)), len(np.unique(pred_values2)))\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "                  columns = [i for i in range(ind)])\n",
    "df_cm\n",
    "#plt.figure(figsize = (10,7))\n",
    "#sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d6ffa-aa64-4d98-affc-ddfc667a69da",
   "metadata": {},
   "source": [
    "**Model 2.4.3: Initial Bias and Class Weights Corrected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b1ed0-09b0-45ae-ba8f-0a237d153b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial_bias = []\n",
    "# for i in range(len(pivot['ones'])):\n",
    "#     b = np.log(pivot['ones'][i] / (sum(pivot['ones'][:i]) + sum(pivot['ones'][i + 1:])))\n",
    "#     initial_bias.append(b)\n",
    "# initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7726742-7b81-4d17-8342-b1a71538836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight \n",
    "# class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df581b-bf4f-4c60-9c71-51cf40fb8cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# # x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# # y: Future collision bin\n",
    "\n",
    "# # ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# # THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# # REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "# def create_cnn_model3(output_bias = None):\n",
    "\n",
    "#     # INPUT LAYERS\n",
    "#     input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "#     input2 = tf.keras.layers.Input(shape=(1,1,39), name='Input_Street') \n",
    "    \n",
    "#     #CNN FOR IMAGE PROCESSING\n",
    "#     cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(input1) # layers = street data dimension\n",
    "#     pooling = tf.keras.layers.MaxPooling2D((2, 2), strides=1)(cnn)\n",
    "#     images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "#     #ADDING STREET DATA\n",
    "#     #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "#     combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "#     # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "#     resnet = resnet18(combined)\n",
    "    \n",
    "#     if output_bias is not None:\n",
    "#         # initial bias added\n",
    "#         output_bias = tf.keras.initializers.Constant(output_bias)    \n",
    "#         output = tf.keras.layers.Dense(units=11, activation='softmax', name='output', bias_initializer=output_bias)(resnet) # units = number of classes\n",
    "#     else: \n",
    "#         output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(resnet) # units = number of classes\n",
    "        \n",
    "#     #instantiation layer \n",
    "#     cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "#     return cnn_model\n",
    "\n",
    "# # initial bias added\n",
    "# cnn_model3 = create_cnn_model3(output_bias = initial_bias)\n",
    "\n",
    "# cnn_model3.summary()\n",
    "\n",
    "# f1 = tfa.metrics.F1Score(\n",
    "#     num_classes = 11,\n",
    "#     average = 'macro',\n",
    "#     threshold = None,\n",
    "#     name = 'f1',\n",
    "#     )\n",
    "\n",
    "# cnn_model3.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics = ['accuracy', f1])\n",
    "\n",
    "# # class_weight = {0: 1,\n",
    "# #                 1: 10,\n",
    "# #                 2: 10,\n",
    "# #                 3: 10,\n",
    "# #                 4: 10,\n",
    "# #                 5: 10,\n",
    "# #                 6: 10,\n",
    "# #                 7: 10,\n",
    "# #                 8: 10,\n",
    "# #                 9: 10,\n",
    "# #                 10: 10,\n",
    "# #                 # 11: 10,\n",
    "# #                }\n",
    "\n",
    "# y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "# y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "# #cnn_model1.load_weights(initial_weights) # initial weights from first model to make it comparable\n",
    "\n",
    "# history = cnn_model3.fit(\n",
    "#     [images_mini, street_mini],\n",
    "#     y_t,\n",
    "#     epochs=10,\n",
    "#     # Suppress logging.\n",
    "#      verbose=1,\n",
    "#     validation_data=([images_mini_v, street_mini_v], y_v),\n",
    "#     # Calculate validation results on 20% of the training data.\n",
    "#     #validation_split = 0.2,\n",
    "#     class_weight = class_weights\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd2b3e-8460-4366-a55d-3af0e9e1d362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18cab8-9ea1-4722-bd92-011068fa8258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea031884-2ce5-4aac-8b54-96f2ebf7daa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2466dbb-bc1c-4636-bd3f-e5155e751f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = cnn_model3.predict([images_mini_v, street_mini_v])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ec827-e46a-4d5a-8426-1da7d67182c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_values3 = []\n",
    "# for i in y_pred: \n",
    "#     input_list = i\n",
    "#     max_value = max(input_list)\n",
    "#     index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "#     pred_values3.append(index[0])\n",
    "# pred_values3[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8bacb-1e20-40ec-931e-ae8bb873b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = list(y_val)\n",
    "# y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160cc41-2dee-4839-891a-1da933fa23be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_true, pred_values3)\n",
    "# ind = max(len(np.unique(y_true)), len(np.unique(pred_values3)))\n",
    "# df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "#                   columns = [i for i in range(ind)])\n",
    "# df_cm\n",
    "# #plt.figure(figsize = (10,7))\n",
    "# #sn.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
