{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe8314a-60a7-4de8-be72-620b659ef79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install imagecodecs\n",
    "#!pip3 install numpy tensorflow matplotlib scipy\n",
    "#!pip3 install pandas\n",
    "#!pip3 install tifffile\n",
    "#!pip3 install -U scikit-learn scipy matplotlib\n",
    "#!pip3 install tensorflow-addons\n",
    "#!pip3 install tensorflow_decision_forests --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:00:53.648569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 02:00:53.781888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-22 02:00:53.781912: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-22 02:00:54.608481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 02:00:54.608573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 02:00:54.608585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda \n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tifffile\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb3f5e7-1637-45a6-8430-79093f8c6d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_gpu():\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb10982-72ec-439c-9c1a-6c182803eb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3693092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/Tiles_expanded.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tiles \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Data/Tiles_expanded.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tiles_expanded_rv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/Tiles_expanded_road_vector.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m tiles_expanded_rv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(tiles_expanded_rv, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRTTYP\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/capstone/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/Tiles_expanded.csv'"
     ]
    }
   ],
   "source": [
    "tiles = pd.read_csv(r'./Data/Tiles_expanded.csv')\n",
    "tiles_expanded_rv = pd.read_csv(r'./Data/Tiles_expanded_road_vector.csv').drop(['Unnamed: 0'],axis=1)\n",
    "tiles_expanded_rv = pd.get_dummies(tiles_expanded_rv, columns = ['RTTYP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5ddd8-bf87-4021-8274-ee55f64b54a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_expanded_rv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02cf6af-4d7f-4cbe-91f0-6a33a0ba3c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_expanded_rv['Collisions_Future_binary']=tiles_expanded_rv['Collisions_Future'].apply(lambda x: 1 if x > 0 else 0)\n",
    "tiles_expanded_rv['Collisions_Historical_binary']=tiles_expanded_rv['Collisions_Historical'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145981e-fe51-49f8-93e4-b1c07d56a8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f22a15-184e-466c-8edd-448bd974f88d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d6b89-b6a3-4465-ac2b-be220741cea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_col(df, col_name):\n",
    "\n",
    "    norm = (df[col_name] - df[col_name].min()) / (df[col_name].max() - df[col_name].min())\n",
    "    return norm\n",
    "\n",
    "tiles_expanded_rv['Mid_lat_norm'] = normalize_col(tiles_expanded_rv,'Mid_lat')\n",
    "tiles_expanded_rv['Mid_long_norm'] = normalize_col(tiles_expanded_rv,'Mid_long')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863e2c6-24b6-45f2-98a9-82be80805bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_expanded_rv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='linear' # 'linear'\n",
    "\n",
    "if MODEL_TYPE == 'linear':\n",
    "    input_x = ['Tile_ID','Collisions_Historical', 'Mid_lat_norm','Mid_long_norm', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U']\n",
    "    input_y = tiles_expanded_rv['Collisions_Future']\n",
    "elif MODEL_TYPE == 'logistic':\n",
    "    input_x = ['Tile_ID','Collisions_Historical_binary', 'Mid_lat_norm','Mid_long_norm', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U']\n",
    "    input_y = ['Collisions_Future_binary']\n",
    "    \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                    tiles_expanded_rv[input_x], \n",
    "                                    input_y,\n",
    "                                    random_state=104, \n",
    "                                    test_size=0.20, \n",
    "                                    shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765668b-0c61-4d60-8ee0-3c7dbeaf1d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.asarray(x_train[['Collisions_Historical', 'Mid_lat_norm','Mid_long_norm', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U']]).astype('float32').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b09f27-204a-49c0-821b-8ec2cebeeede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e076adb-e79f-4610-99c4-4c93acca73f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b681a-b95b-422a-8a86-c31ecdb9187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5934a5-321d-4d47-b7bd-7caec29eb4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe2d02",
   "metadata": {},
   "source": [
    "Model #1: Linear regression using Historical Collisions, SFMTA Street Characteristics, and Geocoordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "## Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea514649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = '../210_Capstone_Aditya_Arisa_Noriel/Satellite Imagery/Satellite Images Tiled/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c2ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eda\n",
    "img = tifffile.imread('../210_Capstone_Aditya_Arisa_Noriel/Satellite Imagery/Satellite Images Tiled/36.tif')[0:148, 0:188, :]\n",
    "img2 = tifffile.imread('../210_Capstone_Aditya_Arisa_Noriel/Satellite Imagery/Satellite Images Tiled/37.tif')[0:148, 0:188, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97889d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eda\n",
    "print(np.shape(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707270d-76db-4d2c-8891-15d32855f6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c8609",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eda\n",
    "test = []\n",
    "test.append(img[0:148, 0:188, :])\n",
    "test.append(img2[0:148, 0:188, :])\n",
    "print(np.shape(test))\n",
    "test = np.stack(test)\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465a7d8-3427-4b10-b950-2e7070012a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example of accessing RGB digits and storing average in a list\n",
    "\n",
    "list_ = []\n",
    "\n",
    "print(img[0][0])\n",
    "print([np.mean(img[0][0][0:3]), img[0][0][3]])\n",
    "\n",
    "for i in img:\n",
    "    for j in i:\n",
    "        list_.append([np.mean(j[0:3]), j[3]])\n",
    "\n",
    "print(list_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298e629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        #image_grayscale = []\n",
    "\n",
    "        #for i in image:\n",
    "        #    for j in i:\n",
    "        #        image_grayscale.append([np.mean(j[0:3]), j[3]])\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(np.mean(image))\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f77ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THERE IS ONE FILE IN THE \"SATELLITE IMAGES TILED\" FOLDER THAT IS NOT A TIF IMAGE, DELETE THIS FILE\n",
    "images_mini = preprocess_data_part1(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce10975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c112503-e9fe-4ba5-8e6a-f411fcb60291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def preprocess_data_part2(image):\n",
    "#     \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "#     Params:\n",
    "#     -------\n",
    "#     IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     image_grayscale = []\n",
    "\n",
    "#     for i in image:\n",
    "#         for j in i:\n",
    "#             image_grayscale.append([np.mean(j[0:3]), j[3]])\n",
    "            \n",
    "#     # stack images and trasnform to array\n",
    "#     #images_mini = np.stack(image_grayscale)\n",
    "    \n",
    "#     return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefa2da-9747-4844-b228-81b357b843cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_mini = preprocess_data_part2(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb32b75-6953-4e24-954e-b2fedfbff117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_mini2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080b62b-712f-4179-9031-60b561f59b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_mini_reshaped = images_mini.reshape((8376,1,1,111296))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce941b-4766-474c-b49e-c365de2bdb86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_mini_reshaped.shape\n",
    "# len(images_mini_reshaped[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street = np.asarray(x_train[input_x[1:]]).astype('float32')\n",
    "street_mini = []\n",
    "for row in street:\n",
    "    street_mini.append([[row]])\n",
    "street_mini = np.stack(street_mini)\n",
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74f799-994b-4d1e-95bd-4d54ef10a333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street_mini_reshaped = street_mini.reshape(8376,11)\n",
    "np.shape(street_mini_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26ef07-d6bc-49aa-82d7-da480f3750e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#images_mini_reshaped = images_mini.reshape(8376,1)\n",
    "#np.shape(images_mini_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9f21e-6f7b-4abd-a7de-917d89fa085a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street = np.hstack(\n",
    "    (street_mini.reshape((8376,11)),\n",
    "     images_mini.reshape(8376,111296))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a63cdc-90cd-43e2-94f1-d819918c510b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_image_street = input_image_street.reshape((8376,1,1, 111307))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f28dfa-b24a-4a22-8414-94ae3d9828df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270fa6f-aec7-4486-b0fb-c1edb73c43ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41870e1a-cb28-43c8-9624-007cc68f94f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5f1b4-18dd-4385-b515-1af782fb8d35",
   "metadata": {},
   "source": [
    "**Model #3: Random Forest using Historical Collisions, SFMTA Street Characteristics, and Geocoordinates**\n",
    "\n",
    "Helpful sources:\n",
    "\n",
    "https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel\n",
    "https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\n",
    "https://www.youtube.com/watch?v=5qgk9QJ4rdQ&t=181s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973eacec-b76b-4a29-9967-e96e06f7b6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest model.\n",
    "\n",
    "rf_model = tfdf.keras.RandomForestModel(task=2, num_trees=100)\n",
    "\n",
    "rf_model.fit(input_image_street,\n",
    "    y_train,\n",
    "    #validation_data=[x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']], y_test],     \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07cc3b-3599-4271-9e98-355d5a90053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest model.\n",
    "\n",
    "rf_model2 = tfdf.keras.RandomForestModel(task=2, num_trees=300)\n",
    "\n",
    "rf_model2.fit(input_image_street,\n",
    "    y_train,\n",
    "    #validation_data=[x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']], y_test],     \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709a18c-109d-4f55-ae8f-a608976fa4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rf_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd4cd7-7a86-4ddc-94b9-1507a5ee044b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##uncomment to show training log\n",
    "#rf_model_train.make_inspector().training_logs()\n",
    "rf_model2.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b76f2-b53f-4a4e-bd37-4d7b48f79c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cb67b-17d6-43b1-b8a2-6960c8419698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "rf_model2.evaluate(x_test[['Tile_ID', 'Collisions_Historical', 'Mid_lat_norm', 'Mid_long_norm',\n",
    "       'Stop_Signs', 'Paving_historical', 'Bus_stop', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69624a-002f-45d8-9c98-56f748f47673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make predictions from test set\n",
    "pd.DataFrame(rf_model.predict(x_test[['Tile_ID', 'Collisions_Historical', 'Mid_lat_norm', 'Mid_long_norm',\n",
    "       'Stop_Signs', 'Paving_historical', 'Bus_stop', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee826d0-bbd0-4d85-a489-b105571a7fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_model.predict(x_test[['Tile_ID', 'Collisions_Historical', 'Mid_lat_norm', 'Mid_long_norm',\n",
    "       'Stop_Signs', 'Paving_historical', 'Bus_stop', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U']])).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c9be2-c916-4ceb-8c25-dc95899057da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = rf_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"RMSE (out-of-bag)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0ce2c-eb33-41bd-9462-1365b8d2c4fd",
   "metadata": {},
   "source": [
    "**Model #4: Gradient Boosted Tree using Historical Collisions, SFMTA Street Characteristics, and Geocoordinates**\n",
    "\n",
    "Helpful sources:\n",
    "\n",
    "https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel\n",
    "https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a3b75-c42a-4884-a753-fb67fbb82db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbt_model = tfdf.keras.GradientBoostedTreesModel(task=2)\n",
    "\n",
    "gbt_model.fit(input_image_street,\n",
    "    y_train,\n",
    "    #validation_data=[x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']], y_test],     \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698518a2-921a-43a1-b56f-094235a8dadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(gbt_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e1eda-544a-476e-ac0b-b64989c66d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##uncomment to show training log\n",
    "#gbt_model.make_inspector().training_logs()\n",
    "gbt_model.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabec000-4306-4cdd-8aac-9b1bba1665d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = gbt_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbb5f6-7340-45fd-8ef3-7f1447d5bbda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = gbt_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7db2b-b3f8-472a-98ef-80ebd5789791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "#gbt_model.evaluate(x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe76a47-522d-447e-876e-32da16c3b3af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make predictions from test set\n",
    "#pd.DataFrame(gbt_model.predict(x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1314ab-fb10-454d-bc3a-e8c3ab5bafa9",
   "metadata": {},
   "source": [
    "**Baseline Linear Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29df16f-55e2-4949-9011-cf6cb49f28d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "def create_linear_model():\n",
    "    # DENSE LAYERS \n",
    "    input = tf.keras.layers.Input(shape=(12,))\n",
    "\n",
    "    outputs = layers.Dense(1)(input)\n",
    "\n",
    "    linear_model = tf.keras.models.Model(inputs=input, outputs=outputs, name=\"linear_model\")\n",
    "\n",
    "    linear_model.summary()\n",
    "\n",
    "    linear_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse'\n",
    "        )\n",
    "    \n",
    "    return linear_model\n",
    "\n",
    "linear_model = create_linear_model()\n",
    "\n",
    "history = linear_model.fit(input_image_street,\n",
    "     y_train,\n",
    "    epochs=100,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb522b8e-0182-426c-91f8-566d5675a5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd3785-3ac9-4516-bfed-85fe15a6f151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def build_model1():\n",
    "#     model = keras.Sequential([\n",
    "#         layers.Dense(64, activation=tf.nn.relu, input_shape=(12,)),\n",
    "#         layers.Dense(64, activation=tf.nn.relu),\n",
    "#         layers.Dense(1)\n",
    "#     ])\n",
    "    \n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "#     model.compile(loss='mse',\n",
    "#                   optimizer=optimizer,\n",
    "#                   metrics=['mse'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fc215-a967-4d26-87de-6359a90a3ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model1 = build_model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a453227-9237-42f7-81a0-13f06df6cd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9b6fa-c54c-4654-8827-aa2003b6dc95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history1 = model1.fit(\n",
    "#     input_image_street,\n",
    "#      y_train,\n",
    "#     epochs=100,\n",
    "#     # Suppress logging.\n",
    "#      verbose=1,\n",
    "#     # Calculate validation results on 20% of the training data.\n",
    "#     validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
