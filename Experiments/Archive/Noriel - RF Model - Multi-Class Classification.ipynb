{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 03:27:01.993395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 03:27:02.130074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-22 03:27:02.130100: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-22 03:27:02.911340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 03:27:02.911438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 03:27:02.911450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "#_____\n",
    "from numba import cuda \n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3693092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Long2</th>\n",
       "      <th>Lat2</th>\n",
       "      <th>Long1</th>\n",
       "      <th>Lat1</th>\n",
       "      <th>Mid_lat</th>\n",
       "      <th>Mid_long</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Paving_future</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.776925</td>\n",
       "      <td>37.777377</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tile_ID       Long2       Lat2       Long1       Lat1    Mid_lat  \\\n",
       "0       36 -122.514446  37.779636 -122.513306  37.778732  37.779184   \n",
       "1       37 -122.514446  37.778732 -122.513306  37.777829  37.778280   \n",
       "2      151 -122.513306  37.779636 -122.512166  37.778732  37.779184   \n",
       "3      152 -122.513306  37.778732 -122.512166  37.777829  37.778280   \n",
       "4      153 -122.513306  37.777829 -122.512166  37.776925  37.777377   \n",
       "\n",
       "     Mid_long  Stop_Signs  Paving_historical  Paving_future  ...  94129  \\\n",
       "0 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "1 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "2 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "3 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "4 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "\n",
       "   94130  94131 94132  94133  94134  94141  94143  94158  94188  \n",
       "0      0      0     0      0      0      0      0      0      0  \n",
       "1      0      0     0      0      0      0      0      0      0  \n",
       "2      0      0     0      0      0      0      0      0      0  \n",
       "3      0      0     0      0      0      0      0      0      0  \n",
       "4      0      0     0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = pd.read_csv(r'./Data/Tiles_binned_zipcode.csv')\n",
    "tiles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e18162b-88f8-4b5d-b4c1-e7bd9c3ca7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
       "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
       "       'Collisions_Future', 'Collisions_Historical', 'bin', 'RTTYP_I',\n",
       "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
       "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
       "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
       "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
       "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
       "       '94134', '94141', '94143', '94158', '94188'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tiles[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I',\n",
    "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']], \n",
    "                                   tiles['bin'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    data_mini_test = []\n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        #grayscale\n",
    "        for i in image:\n",
    "            for j in i:\n",
    "                data_mini.append([np.mean(j[0:3]), j[3]])\n",
    "        \n",
    "        # append to images\n",
    "        #data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    for id in x_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        #grayscale\n",
    "        for i in image:\n",
    "            for j in i:\n",
    "                data_mini_test.append([np.mean(j[0:3]), j[3]])\n",
    "        \n",
    "        # append to images\n",
    "        #data_mini_test.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini_test = np.stack(data_mini_test)\n",
    "    \n",
    "    return images_mini, images_mini_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mini, images_mini_test = preprocess_data_part1(IMAGE_PATH)\n",
    "print('train ', np.shape(images_mini))\n",
    "print('test ', np.shape(image_mini_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street = np.asarray(x_train[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']]).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "print('train ', np.shape(street_mini))\n",
    "\n",
    "street_test = np.asarray(x_test[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']]).astype('float32')\n",
    "street_mini_test = []\n",
    "for row in range(len(street_test)):\n",
    "    street_mini_test.append([[street_test[row]]])\n",
    "street_mini_test = np.stack(street_mini_test)\n",
    "print('test ',np.shape(street_mini_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275800-edf8-4225-a07c-998b25870208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street = np.hstack(\n",
    "    (street_mini.reshape((8376,52)),\n",
    "     images_mini.reshape(8376,148*188*4))\n",
    ")\n",
    "np.shape(input_image_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771ebca-a17e-4a7f-b8b6-0ebbf258a123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street_test = np.hstack(\n",
    "    (street_mini_test.reshape((2095,52)),\n",
    "     images_mini_test.reshape(2095,148*188*4))\n",
    ")\n",
    "np.shape(input_image_street_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0d0a-47df-45ce-8bd4-9c31ed9d0cc3",
   "metadata": {},
   "source": [
    "**Noriel's Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e660c-d9ed-4991-ba6a-c0cece399b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217a2b4-a4fb-4407-8f08-cf72e15cdbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e009aa6-17b0-4b25-a570-aba1ce6100ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c3787-63c6-4417-a626-e29615e3ed26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(input_image_street)\n",
    "# X_scaled = scaler.transform(input_image_street)\n",
    "# X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4029c-9726-4105-bbb9-932ab1baad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],'max_depth': [20,30,40, 100, 110],\n",
    "#     'max_features': ['sqrt'],'min_samples_leaf': [5,10,15],\n",
    "#     'min_samples_split': [40,50,60], 'n_estimators': [150, 200, 250]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestClassifier()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaff37d-b624-434a-9b5c-0c20630e075d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_search.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701c4cd-dfe9-4d74-a69b-b030194b187b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4f0f7-a7dc-43f6-94db-d59f5b204b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model = tfdf.keras.RandomForestModel(categorical_algorithm = 'CART', num_trees=300, max_depth = 110)\n",
    "\n",
    "rf_model.fit(input_image_street,\n",
    "    y_train,    \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14110520-7657-467c-83af-ca78d8e431de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rf_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b594c40-eec6-4cff-afc6-c93870de0de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##uncomment to show training log\n",
    "#rf_model_train.make_inspector().training_logs()\n",
    "rf_model.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3edc9-2e32-4bc8-8c5b-5bf3085d8060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = rf_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.evaluation.num_examples for log in logs], [log.evaluation.loss for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d39f5-7211-436d-8355-6775818e613b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = rf_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.evaluation.num_examples for log in logs], [log.evaluation.accuracy for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078a13f-031f-4516-befd-3e8bbad12679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "rf_model.evaluate(input_image_street_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227c76c-58ef-4dc8-a5d9-e6b0ab3048af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model.predict(input_image_street_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be5ae4-5e10-443a-a589-87386a3f493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = rf_model.predict(input_image_street_test)\n",
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac777f1-1203-446d-a2dd-ff2d702d933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = tfa.metrics.F1Score(num_classes=3, threshold=0.5)\n",
    "# y_true = np.array([[1, 1, 1],\n",
    "#                    [1, 0, 0],\n",
    "#                    [1, 1, 0]], np.int32)\n",
    "# y_pred = np.array([[0.2, 0.6, 0.7],\n",
    "#                    [0.2, 0.6, 0.6],\n",
    "#                    [0.6, 0.8, 0.0]], np.float32)\n",
    "# metric.update_state(y_true, y_pred)\n",
    "# result = metric.result()\n",
    "# result.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b653ae-6f91-40a2-bdc4-353ca93d8969",
   "metadata": {},
   "source": [
    "**Gradient Boosted Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5545f1-c7c7-4345-901c-fc6d6e471f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbt_model = tfdf.keras.GradientBoostedTreesModel(categorical_algorithm = 'CART')\n",
    "\n",
    "gbt_model.fit(input_image_street,\n",
    "    y_train,\n",
    "    #validation_data=[x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']], y_test],     \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0ab68-088d-42bf-9969-056c5c730567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(gbt_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec998745-a7da-4057-84fa-b3516fc532ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##uncomment to show training log\n",
    "#gbt_model.make_inspector().training_logs()\n",
    "gbt_model.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ad9aa-418c-4651-a273-da7ba9a6de7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = gbt_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c70244-4ee6-4aae-8f71-31242038b22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbt_model.evaluate(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab95c06-64fc-4e5e-afbc-5a1afd6c0105",
   "metadata": {},
   "source": [
    "Random Forest With Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea2148-a646-4175-8e77-0510f32f03d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "def create_linear_model():\n",
    "    # DENSE LAYERS \n",
    "    input = tf.keras.layers.Input(shape=(52,)) # (111307,))\n",
    "\n",
    "    outputs = layers.Dense(1)(input)\n",
    "\n",
    "    linear_model = tf.keras.models.Model(inputs=input, outputs=outputs, name=\"linear_model\")\n",
    "\n",
    "    linear_model.summary()\n",
    "\n",
    "    linear_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "        )\n",
    "    \n",
    "    return linear_model\n",
    "\n",
    "linear_model = create_linear_model()\n",
    "\n",
    "history = linear_model.fit(\n",
    "    input_image_street,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582a952-65fa-464d-9b85-fee9e601910f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55e377-251c-4fb2-96fe-dacfb5c9df2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.shape(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661fd88-4dea-4527-83d7-0dc57ce5fd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_result = linear_model.predict(x_test)\n",
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6646a98-35b8-454d-9cb1-38e01d557b67",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178f9ab-ed0e-46ab-89af-482db92fd48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "def create_logistic_model():\n",
    "    # DENSE LAYERS \n",
    "    input = tf.keras.layers.Input(shape=(53,))\n",
    "    \n",
    "    # input = keras.layers.Flatten()(input)\n",
    "\n",
    "    outputs = keras.layers.Dense(units = 1, activation = 'sigmoid')(input)\n",
    "\n",
    "    log_model = tf.keras.models.Model(inputs=input, outputs=outputs, name=\"logistic_model\")\n",
    "\n",
    "    log_model.summary()\n",
    "\n",
    "    log_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"bce\",\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return log_model\n",
    "\n",
    "logistic_model = create_logistic_model()\n",
    "\n",
    "class_weight = {0: 1,\n",
    "                1: 100000,\n",
    "                2: 100000,\n",
    "                3: 100000,\n",
    "                4: 100000,\n",
    "                5: 100000,\n",
    "                6: 100000,\n",
    "                7: 100000,\n",
    "                8: 100000,\n",
    "                9: 100000,\n",
    "                10: 100000,\n",
    "                #11: 100000,\n",
    "               }\n",
    "\n",
    "history = logistic_model.fit(\n",
    "    input_image_street,\n",
    "    y_train,\n",
    "     # y_train_2,\n",
    "    epochs=50,\n",
    "    # Suppress logging.\n",
    "     # verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2,\n",
    "    # class_weight = class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8b5b1-4469-4d74-9883-099b8f529fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
