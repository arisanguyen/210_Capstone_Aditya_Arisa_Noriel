{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer, normalize\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c28e4eda-dfba-490b-9fd5-8f6f6cf61454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_f1_macro(history):\n",
    "    plt.plot(history.history['f1_macro'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1_macro'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1_macro']),\n",
    "                max(history.history['val_f1_macro'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Macro F1 Score')\n",
    "    plt.title('Macro F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78d60b67-24b2-4399-bbed-8bdfa6687f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_weighted(history):\n",
    "    plt.plot(history.history['f1_weighted'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1_weighted'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1_weighted']),\n",
    "                max(history.history['val_f1_weighted'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Weighted F1 Score')\n",
    "    plt.title('Weighted F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd28b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x1 = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x2 = make_layer(x1, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x3 = make_layer(x2, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x4 = make_layer(x3, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x4)\n",
    "    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    return resnet(x, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Pulling in Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_train = pd.read_csv(r'./Data/Tiles_TRAIN.csv')\n",
    "#x_train = tiles_train.drop(['bins_numeric'], axis = 1)\n",
    "#y_train = tiles_train['bins_numeric']\n",
    "#x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6453b058-407b-4097-a463-b18eb8ebb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(tiles_train.drop(['bins_numeric'], axis = 1), tiles_train['bins_numeric'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "718117b7-698f-4b5a-b598-3b4b302c01e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5297, 2: 968, 3: 230, 1: 108, 6: 53, 4: 22, 7: 11, 5: 4, 10: 3, 8: 3, 9: 1})\n",
      "Counter({0: 5297, 2: 968, 3: 230, 1: 230, 6: 150, 7: 100, 10: 100, 4: 100, 5: 100, 8: 100, 9: 100})\n"
     ]
    }
   ],
   "source": [
    "# upsample with SMOGN\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "ros = RandomOverSampler(random_state=0,sampling_strategy={0:5297, 2:968, 3:230, 1:230, 6:150, 4:100, 7:100, 5:100,10:100,8:100,9:100}) # 0.77\n",
    "# ros = RandomOverSampler(random_state=0,sampling_strategy={0:5297, 2:2400, 3:419, 1:108, 6:150, 4:100, 7:44, 5:40,10:30,8:30,9:10})\n",
    "x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "counter_sampled = Counter(y_train)\n",
    "print(counter_sampled)\n",
    "# smote_enn = SMOTEENN(random_state=0,sampling_strategy='minority')\n",
    "\n",
    "# x_train_sampled, y_train_sampled = smote_enn.fit_resample(x_train, y_train)\n",
    "# print(sorted(Counter(y_train_sampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2dc5623-e4cd-45b2-9190-e7c3e097de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7475, 40)\n",
      "(7475,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a31ede27-1d89-41fa-a5ae-eef112e01fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "0     1526         0.0                0.0       0.0                    0.0   \n",
       "1    11426         0.0                7.0       0.0                    8.0   \n",
       "2    13993         0.0                0.0       0.0                    0.0   \n",
       "3     3201         0.0                0.0       0.0                    0.0   \n",
       "4    13779         0.0                0.0       0.0                    0.0   \n",
       "\n",
       "   RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "0        0        1        0        0        0  ...      0      0      0   \n",
       "1        0        1        0        0        0  ...      0      0      0   \n",
       "2        0        1        0        0        0  ...      0      0      0   \n",
       "3        0        1        0        0        0  ...      0      0      0   \n",
       "4        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "   94132  94133  94134  94141  94143  94158  94188  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      1  \n",
       "3      1      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5971c10e-9c78-4cd5-bf77-a213f4e70ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>7123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>12171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td>1096</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "2732     2948         0.0                0.0       0.0                    0.0   \n",
       "630      2945         4.0                0.0       2.0                    1.0   \n",
       "2887     7123         1.0                0.0       0.0                    0.0   \n",
       "752     12171         0.0                0.0       2.0                    1.0   \n",
       "8106     1096         2.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "2732        0        1        0        0        0  ...      0      0      0   \n",
       "630         0        1        0        0        0  ...      0      0      0   \n",
       "2887        0        1        0        0        0  ...      0      0      0   \n",
       "752         0        1        0        0        0  ...      0      0      0   \n",
       "8106        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "2732      0      0      0      0      0      0      0  \n",
       "630       0      0      0      0      0      0      0  \n",
       "2887      0      0      0      0      0      0      0  \n",
       "752       0      0      0      0      0      0      0  \n",
       "8106      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d18a322c-14fa-44a5-89ec-8b6ae7411008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>94101</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  RTTYP_I  \\\n",
       "0         0.0                0.0       0.0                    0.0        0   \n",
       "1         1.0                0.0       3.0                    6.0        0   \n",
       "2         0.0                0.0       0.0                    0.0        0   \n",
       "3         0.0                0.0       0.0                    0.0        0   \n",
       "4         0.0                0.0       0.0                    0.0        0   \n",
       "\n",
       "   RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  94101  ...  94129  94130  94131  94132  \\\n",
       "0        1        0        0        0      0  ...      0      0      0      1   \n",
       "1        1        0        0        0      0  ...      0      0      0      0   \n",
       "2        1        0        0        0      0  ...      0      0      0      0   \n",
       "3        1        0        0        0      0  ...      0      1      0      0   \n",
       "4        1        0        0        0      0  ...      0      0      0      0   \n",
       "\n",
       "   94133  94134  94141  94143  94158  94188  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      1      0      0      0      0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_test = pd.read_csv(r'./Data/Tiles_TEST.csv')\n",
    "x_test = tiles_test.drop(['Tile_ID','bins_numeric'], axis = 1)\n",
    "y_test = tiles_test['bins_numeric']\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7475, 148, 188, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini = preprocess_data_part1(IMAGE_PATH)\n",
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51e4bbbe-914b-47dd-9e82-93722404f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84e1f01e-fc42-4bb8-9d18-e40fe8d215c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part15(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_val['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "#     images_mini = normalize(images_mini.reshape(6700,-1))\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fcfd6d0-bf6d-48b1-a404-00afbc2b9633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 148, 188, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_v = preprocess_data_part15(IMAGE_PATH)\n",
    "np.shape(images_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96c499c7-9ec4-4f6c-8e9c-482de86f536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23790420-0c98-426f-8580-23f7d96e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part2(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in tiles_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc8e3f65-2368-4092-9b09-ecda4e0a35d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 148, 188, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_t = preprocess_data_part2(IMAGE_PATH)\n",
    "np.shape(images_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7475, 1, 1, 39)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "street = np.asarray(x_train).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c923520c-ed3c-4165-abd9-7b3cc932b35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 1, 1, 39)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAL SET \n",
    "\n",
    "street_v = np.asarray(x_val).astype('float32')\n",
    "street_mini_v = []\n",
    "for row in range(len(street_v)):\n",
    "    street_mini_v.append([[street_v[row]]])\n",
    "street_mini_v = np.stack(street_mini_v)\n",
    "np.shape(street_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c28b0428-174b-4e10-b151-1354cf44bf79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 1, 1, 39)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST SET \n",
    "\n",
    "street_t = np.asarray(x_test).astype('float32')\n",
    "street_mini_t = []\n",
    "for row in range(len(street_t)):\n",
    "    street_mini_t.append([[street_t[row]]])\n",
    "street_mini_t = np.stack(street_mini_t)\n",
    "np.shape(street_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0dbb-2532-4c3a-b053-1f6f687be79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f8956",
   "metadata": {},
   "source": [
    "Helpful Links: <br>\n",
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 <br>\n",
    "https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py <BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020edd3a-0c97-45f9-875d-3df38db9251f",
   "metadata": {},
   "source": [
    "**Model 2.7.0: Resnet = 1000 classes, checkpoint added, 10 epochs, LR scheduler added**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af93dd1e-4394-4ba2-ac1c-593d00d2bff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ones\n",
      "bins      \n",
      "0     5297\n",
      "1      230\n",
      "2      968\n",
      "3      230\n",
      "4      100\n",
      "5      100\n",
      "6      150\n",
      "7      100\n",
      "8      100\n",
      "9      100\n",
      "10     100\n"
     ]
    }
   ],
   "source": [
    "check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42e82273-164e-45f2-86f3-5c7de058c9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.12828873976693497,\n",
       " 1: 2.9545454545454546,\n",
       " 2: 0.7020097670924117,\n",
       " 3: 2.9545454545454546,\n",
       " 4: 6.795454545454546,\n",
       " 5: 6.795454545454546,\n",
       " 6: 4.53030303030303,\n",
       " 7: 6.795454545454546,\n",
       " 8: 6.795454545454546,\n",
       " 9: 6.795454545454546,\n",
       " 10: 6.795454545454546}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91c34f-cb4c-47c3-bb19-4540b41de68a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 02:18:18.318971: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/home/ubuntu/capstone/lib/python3.10/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_Images (InputLayer)      [(None, 148, 188, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 147, 187, 39  663         ['Input_Images[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 95, 95, 39)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " Input_Street (InputLayer)      [(None, 1, 1, 39)]   0           []                               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 95, 95, 39)   0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'Input_Street[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 101, 101, 39  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 48, 48, 64)   122304      ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 48, 48, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " relu1 (ReLU)                   (None, 48, 48, 64)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " maxpool_pad (ZeroPadding2D)    (None, 50, 50, 64)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " maxpool (MaxPooling2D)         (None, 24, 24, 64)   0           ['maxpool_pad[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['maxpool[0][0]']                \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.0.conv1 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.0.bn1 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.0.relu1 (ReLU)          (None, 24, 24, 64)   0           ['layer1.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.0.conv2_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.0.conv2 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.0.bn2 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.0.add (Add)             (None, 24, 24, 64)   0           ['maxpool[0][0]',                \n",
      "                                                                  'layer1.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.0.relu2 (ReLU)          (None, 24, 24, 64)   0           ['layer1.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.1.conv1 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.1.bn1 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.1.relu1 (ReLU)          (None, 24, 24, 64)   0           ['layer1.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.conv2_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.1.conv2 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.1.bn2 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.1.add (Add)             (None, 24, 24, 64)   0           ['layer1.0.relu2[0][0]',         \n",
      "                                                                  'layer1.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.relu2 (ReLU)          (None, 24, 24, 64)   0           ['layer1.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.conv1 (Conv2D)        (None, 12, 12, 128)  73728       ['layer2.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.0.bn1 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.0.relu1 (ReLU)          (None, 12, 12, 128)  0           ['layer2.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.conv2_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.downsample.0 (Conv2D)  (None, 12, 12, 128)  8192       ['layer1.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer2.0.conv2 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.0.downsample.1 (BatchNo  (None, 12, 12, 128)  512        ['layer2.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer2.0.bn2 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.0.add (Add)             (None, 12, 12, 128)  0           ['layer2.0.downsample.1[0][0]',  \n",
      "                                                                  'layer2.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.relu2 (ReLU)          (None, 12, 12, 128)  0           ['layer2.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.conv1_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.1.conv1 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.1.bn1 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.1.relu1 (ReLU)          (None, 12, 12, 128)  0           ['layer2.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.conv2_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.1.conv2 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.1.bn2 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.1.add (Add)             (None, 12, 12, 128)  0           ['layer2.0.relu2[0][0]',         \n",
      "                                                                  'layer2.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.relu2 (ReLU)          (None, 12, 12, 128)  0           ['layer2.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.conv1_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.conv1 (Conv2D)        (None, 6, 6, 256)    294912      ['layer3.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.0.bn1 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.0.relu1 (ReLU)          (None, 6, 6, 256)    0           ['layer3.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.conv2_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.downsample.0 (Conv2D)  (None, 6, 6, 256)   32768       ['layer2.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer3.0.conv2 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.0.downsample.1 (BatchNo  (None, 6, 6, 256)   1024        ['layer3.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer3.0.bn2 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.0.add (Add)             (None, 6, 6, 256)    0           ['layer3.0.downsample.1[0][0]',  \n",
      "                                                                  'layer3.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.relu2 (ReLU)          (None, 6, 6, 256)    0           ['layer3.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.conv1_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.1.conv1 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.1.bn1 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.1.relu1 (ReLU)          (None, 6, 6, 256)    0           ['layer3.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.conv2_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.1.conv2 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.1.bn2 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.1.add (Add)             (None, 6, 6, 256)    0           ['layer3.0.relu2[0][0]',         \n",
      "                                                                  'layer3.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.relu2 (ReLU)          (None, 6, 6, 256)    0           ['layer3.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.conv1_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.0.conv1 (Conv2D)        (None, 3, 3, 512)    1179648     ['layer4.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.0.bn1 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.0.relu1 (ReLU)          (None, 3, 3, 512)    0           ['layer4.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.conv2_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.0.downsample.0 (Conv2D)  (None, 3, 3, 512)   131072      ['layer3.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer4.0.conv2 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.0.downsample.1 (BatchNo  (None, 3, 3, 512)   2048        ['layer4.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer4.0.bn2 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.0.add (Add)             (None, 3, 3, 512)    0           ['layer4.0.downsample.1[0][0]',  \n",
      "                                                                  'layer4.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.relu2 (ReLU)          (None, 3, 3, 512)    0           ['layer4.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.conv1_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.1.conv1 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.1.bn1 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.1.relu1 (ReLU)          (None, 3, 3, 512)    0           ['layer4.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.conv2_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.1.conv2 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.1.bn2 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.1.add (Add)             (None, 3, 3, 512)    0           ['layer4.0.relu2[0][0]',         \n",
      "                                                                  'layer4.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.relu2 (ReLU)          (None, 3, 3, 512)    0           ['layer4.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " avgpool (GlobalAveragePooling2  (None, 512)         0           ['layer4.1.relu2[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 1000)         513000      ['avgpool[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 11)           11011       ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,823,682\n",
      "Trainable params: 11,814,082\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/capstone/lib/python3.10/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2023-04-05 02:18:19.083814: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3327750400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 1.6431 - accuracy: 0.5637 - precision: 0.7698 - f1_macro: 0.3784 - f1_weighted: 0.6192 \n",
      "Epoch 1: val_f1_weighted improved from -inf to 0.66213, saving model to model.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Images, Input_Street with unsupported characters which will be renamed to input_images, input_street in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 8356s 36s/step - loss: 1.6431 - accuracy: 0.5637 - precision: 0.7698 - f1_macro: 0.3784 - f1_weighted: 0.6192 - val_loss: 1.1526 - val_accuracy: 0.5901 - val_precision: 0.7510 - val_f1_macro: 0.1516 - val_f1_weighted: 0.6621 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "112/234 [=============>................] - ETA: 1:11:19 - loss: 1.0637 - accuracy: 0.6359 - precision: 0.7729 - f1_macro: 0.5272 - f1_weighted: 0.6840"
     ]
    }
   ],
   "source": [
    "# From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# y: Future collision bin\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,1,39), name='Input_Street') \n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(input1) # layers = street data dimension\n",
    "    pooling = tf.keras.layers.MaxPooling2D((53, 93), strides=1)(cnn)\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    #combined = tf.keras.layers.Concatenate(axis = 2)([images.output, input2])\n",
    "    combined = tf.keras.layers.Add()([images.output, input2])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet = resnet18(combined)\n",
    "    output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(resnet) # units = number of classes\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "f1_m = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'macro',\n",
    "    threshold = None,\n",
    "    name = 'f1_macro',\n",
    "    )\n",
    "\n",
    "f1_w = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'weighted',\n",
    "    threshold = None,\n",
    "    name = 'f1_weighted',\n",
    "    )\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), #learning rate defined by scheduler\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy', keras.metrics.Precision(), f1_m, f1_w])\n",
    "\n",
    "y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"model.8\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_weighted', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_check = checkpoint\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return 0.0001\n",
    "    elif epoch < 6:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [images_mini, street_mini],\n",
    "    y_t,\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    validation_data=([images_mini_v, street_mini_v], y_v),\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    #validation_split = 0.2,\n",
    "    class_weight = class_weights,\n",
    "    callbacks=[callback, callbacks_check],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d91844-64dc-4348-b024-783281f26bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving last epoch model just in case \n",
    "cnn_model.save('model.8.last.epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccdeff-f234-4fe1-b16b-c5db3c38830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c6bdb-832f-43fa-bcf9-d5908aafdb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805e4cd-dcb7-4568-845a-2e4e62d8a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_macro(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08e9fe-11ef-4aea-9cea-d4cd5bc26312",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_weighted(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe81ee-3020-46ca-a1eb-93acd0da22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = cnn_model.predict([images_mini_v, street_mini_v])\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b563fc-8984-4b33-9ede-bee946fa2f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values2 = []\n",
    "for i in y_pred2: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values2.append(index[0])\n",
    "pred_values2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862034d-b68b-4ebc-92dd-f0cbf5f39c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_val)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a56d10-ec48-4cb6-9e9a-10490eb6ac37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values2)\n",
    "ind = max(len(np.unique(y_true)), len(np.unique(pred_values2)))\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "                  columns = [i for i in range(ind)])\n",
    "df_cm\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "sn.heatmap(df_cm, annot=True, fmt='.3g',cmap=\"OrRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0227cb4-905c-45e5-9c0b-953ad84542bc",
   "metadata": {},
   "source": [
    "**Loading best model from checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8434f5-19c5-4783-bc21-8d8dcd440e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "filepath = \"model.8\"\n",
    "new_model = load_model(filepath)\n",
    "# assert_allclose(cnn_model.predict([images_mini_v, street_mini_v]),\n",
    "#                 new_model.predict([images_mini_v, street_mini_v]),\n",
    "#                 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d497d-5651-430c-ad29-aff2ee2b4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = new_model.predict([images_mini_t, street_mini_t])\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df76559-50fd-4862-825e-f3f3feb0e17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values3 = []\n",
    "for i in y_pred3: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values3.append(index[0])\n",
    "pred_values3[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7053df3-dd77-4d2f-bc6a-48eb5af9f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_test)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b54ba-c10c-4c10-9522-d8cdf4091ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values3)\n",
    "ind = max(len(np.unique(y_true)), len(np.unique(pred_values3)))\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(11)],\n",
    "                  columns = [i for i in range(11)])\n",
    "df_cm\n",
    "# plt.figure(figsize = (10,7))\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('Actual Values')\n",
    "# plt.xlabel('Predicted Values')\n",
    "# sn.heatmap(df_cm, annot=True, fmt='.3g',cmap=\"OrRd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195caf63-241e-4192-8c6c-6c9fd6883518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.f1_score(y_true, pred_values3, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8baada5-5fb4-4f5b-9e1c-3cc37b4ee32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(y_true, pred_values3, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6a585-5b16-4cbc-b528-9861d0a44355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(y_true, pred_values3, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
