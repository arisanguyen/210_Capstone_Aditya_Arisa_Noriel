{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab39d93a-0a73-49d1-80fa-4fa51f6ec437",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 22:03:49.054911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-25 22:03:49.185267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-25 22:03:49.185290: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-25 22:03:50.008441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 22:03:50.008549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 22:03:50.008560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3693092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Long2</th>\n",
       "      <th>Lat2</th>\n",
       "      <th>Long1</th>\n",
       "      <th>Lat1</th>\n",
       "      <th>Mid_lat</th>\n",
       "      <th>Mid_long</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Paving_future</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.776925</td>\n",
       "      <td>37.777377</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tile_ID       Long2       Lat2       Long1       Lat1    Mid_lat  \\\n",
       "0       36 -122.514446  37.779636 -122.513306  37.778732  37.779184   \n",
       "1       37 -122.514446  37.778732 -122.513306  37.777829  37.778280   \n",
       "2      151 -122.513306  37.779636 -122.512166  37.778732  37.779184   \n",
       "3      152 -122.513306  37.778732 -122.512166  37.777829  37.778280   \n",
       "4      153 -122.513306  37.777829 -122.512166  37.776925  37.777377   \n",
       "\n",
       "     Mid_long  Stop_Signs  Paving_historical  Paving_future  ...  94129  \\\n",
       "0 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "1 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "2 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "3 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "4 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "\n",
       "   94130  94131 94132  94133  94134  94141  94143  94158  94188  \n",
       "0      0      0     0      0      0      0      0      0      0  \n",
       "1      0      0     0      0      0      0      0      0      0  \n",
       "2      0      0     0      0      0      0      0      0      0  \n",
       "3      0      0     0      0      0      0      0      0      0  \n",
       "4      0      0     0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = pd.read_csv(r'./Data/Tiles_binned_zipcode.csv')\n",
    "tiles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tiles[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I',\n",
    "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']], \n",
    "                                   tiles['bin'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    data_mini_test = []\n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    for id in x_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        # append to images\n",
    "        data_mini_test.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini_test = np.stack(data_mini_test)\n",
    "    \n",
    "    return images_mini, images_mini_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mini, images_mini_test = preprocess_data_part1(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bd0d021-1c1d-4276-bff0-1f688168e3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  (8376, 148, 188, 4)\n",
      "test  (2095, 148, 188, 4)\n"
     ]
    }
   ],
   "source": [
    "print('train ', np.shape(images_mini))\n",
    "print('test ', np.shape(images_mini_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  (8376, 1, 1, 52)\n",
      "test  (2095, 1, 1, 52)\n"
     ]
    }
   ],
   "source": [
    "street = np.asarray(x_train[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']]).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "print('train ', np.shape(street_mini))\n",
    "\n",
    "street_test = np.asarray(x_test[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']]).astype('float32')\n",
    "street_mini_test = []\n",
    "for row in range(len(street_test)):\n",
    "    street_mini_test.append([[street_test[row]]])\n",
    "street_mini_test = np.stack(street_mini_test)\n",
    "print('test ',np.shape(street_mini_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5275800-edf8-4225-a07c-998b25870208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 111348)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image_street = np.hstack(\n",
    "    (street_mini.reshape((8376,52)),\n",
    "     images_mini.reshape(8376,148*188*4))\n",
    ")\n",
    "np.shape(input_image_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0771ebca-a17e-4a7f-b8b6-0ebbf258a123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 111348)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image_street_test = np.hstack(\n",
    "    (street_mini_test.reshape((2095,52)),\n",
    "     images_mini_test.reshape(2095,148*188*4))\n",
    ")\n",
    "np.shape(input_image_street_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7964c7a-cf51-4862-b868-402e6943589d",
   "metadata": {},
   "source": [
    "Pre-process Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a13e660c-d9ed-4991-ba6a-c0cece399b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8419     C\n",
       "10129    B\n",
       "7641     A\n",
       "5215     A\n",
       "7784     A\n",
       "Name: bin, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7217a2b4-a4fb-4407-8f08-cf72e15cdbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e009aa6-17b0-4b25-a570-aba1ce6100ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77c3787-63c6-4417-a626-e29615e3ed26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(input_image_street)\n",
    "# X_scaled = scaler.transform(input_image_street)\n",
    "# X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94e4029c-9726-4105-bbb9-932ab1baad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],'max_depth': [20,30,40, 100, 110],\n",
    "#     'max_features': ['sqrt'],'min_samples_leaf': [5,10,15],\n",
    "#     'min_samples_split': [40,50,60], 'n_estimators': [150, 200, 250]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestClassifier()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdaff37d-b624-434a-9b5c-0c20630e075d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_search.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9701c4cd-dfe9-4d74-a69b-b030194b187b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6646a98-35b8-454d-9cb1-38e01d557b67",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0d0a-47df-45ce-8bd4-9c31ed9d0cc3",
   "metadata": {},
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c9257cc-c1de-40e8-9ea6-5a06399692e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weight = {0: 100,\n",
    "                1: 1000,\n",
    "                2: 1000,\n",
    "                3: 1000,\n",
    "                4: 1000,\n",
    "                5: 1000,\n",
    "                6: 1000,\n",
    "                7: 1000,\n",
    "                8: 1000,\n",
    "                9: 1000,\n",
    "                10: 1000,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178f9ab-ed0e-46ab-89af-482db92fd48b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"logistic_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 111348)]          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 11)                1224839   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,224,839\n",
      "Trainable params: 1,224,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 22:05:49.892513: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2984126400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 11ms/step - loss: 1705497.8750 - accuracy: 0.3290 - val_loss: 4005.5066 - val_accuracy: 0.0913\n",
      "Epoch 2/30\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 1276796.1250 - accuracy: 0.3916 - val_loss: 1436.3971 - val_accuracy: 0.7924\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 854950.5625 - accuracy: 0.4121 - val_loss: 5930.2231 - val_accuracy: 0.1307\n",
      "Epoch 4/30\n",
      "193/210 [==========================>...] - ETA: 0s - loss: 837643.1875 - accuracy: 0.4335"
     ]
    }
   ],
   "source": [
    "# x: 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U'\n",
    "# y: 'Collisions_Future'\n",
    "tf.keras.backend.clear_session()\n",
    "def create_logistic_model():\n",
    "    # DENSE LAYERS \n",
    "    input = tf.keras.layers.Input(shape=(111348,))\n",
    "    \n",
    "    # input = keras.layers.Flatten()(input)\n",
    "\n",
    "    outputs = keras.layers.Dense(units = 11, activation = 'softmax')(input)\n",
    "\n",
    "    log_model = tf.keras.models.Model(inputs=input, outputs=outputs, name=\"logistic_model\")\n",
    "\n",
    "    log_model.summary()\n",
    "\n",
    "    log_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return log_model\n",
    "\n",
    "logistic_model = create_logistic_model()\n",
    "\n",
    "history = logistic_model.fit(\n",
    "    input_image_street,\n",
    "    y_train,\n",
    "     # y_train_2,\n",
    "    epochs=30,\n",
    "    # Suppress logging.\n",
    "     # verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2,\n",
    "    class_weight = class_weight\n",
    "    )\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8b5b1-4469-4d74-9883-099b8f529fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5281b-5d3f-453a-91b5-01bd4ff9da75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_result = history.model.predict(input_image_street_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972e688-e927-4e57-9645-58da136cbd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in range(len(predict_result)):\n",
    "    predictions.append(np.argmax(predict_result[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e023-1ebe-4244-b232-0dee9dfad65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None, sample_weight=None, zero_division='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4248e6-c15c-45a0-85c3-cb04729caf9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None, sample_weight=None, zero_division='warn').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc287494-c95f-4fb5-95cc-18a30fdebbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
