{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0aa97e-f85b-4890-8261-4a411c7f11c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/ubuntu/capstone/lib/python3.10/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/ubuntu/capstone/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /home/ubuntu/capstone/lib/python3.10/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/capstone/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/capstone/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/capstone/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 06:16:16.812463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 06:16:17.883790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-07 06:16:17.883836: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-07 06:16:20.584141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-07 06:16:20.584876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-07 06:16:20.584891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer, normalize\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28e4eda-dfba-490b-9fd5-8f6f6cf61454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_f1_macro(history):\n",
    "    plt.plot(history.history['f1_macro'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1_macro'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1_macro']),\n",
    "                max(history.history['val_f1_macro'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Macro F1 Score')\n",
    "    plt.title('Macro F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d60b67-24b2-4399-bbed-8bdfa6687f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_weighted(history):\n",
    "    plt.plot(history.history['f1_weighted'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1_weighted'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1_weighted']),\n",
    "                max(history.history['val_f1_weighted'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Weighted F1 Score')\n",
    "    plt.title('Weighted F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd28b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x1 = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x2 = make_layer(x1, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x3 = make_layer(x2, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x4 = make_layer(x3, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x4)\n",
    "    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    return resnet(x, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Pulling in Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_train = pd.read_csv(r'./Data/Tiles_TRAIN.csv')\n",
    "#x_train = tiles_train.drop(['bins_numeric'], axis = 1)\n",
    "#y_train = tiles_train['bins_numeric']\n",
    "#x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6453b058-407b-4097-a463-b18eb8ebb124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>11426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>13993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>3201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>13779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "1762     1526         0.0                0.0       0.0                    0.0   \n",
       "4603    11426         0.0                7.0       0.0                    8.0   \n",
       "6484    13993         0.0                0.0       0.0                    0.0   \n",
       "6950     3201         0.0                0.0       0.0                    0.0   \n",
       "4254    13779         0.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "1762        0        1        0        0        0  ...      0      0      0   \n",
       "4603        0        1        0        0        0  ...      0      0      0   \n",
       "6484        0        1        0        0        0  ...      0      0      0   \n",
       "6950        0        1        0        0        0  ...      0      0      0   \n",
       "4254        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "1762      0      0      0      0      0      0      0  \n",
       "4603      0      0      0      0      0      0      0  \n",
       "6484      0      0      0      0      0      0      1  \n",
       "6950      1      0      0      0      0      0      0  \n",
       "4254      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(tiles_train.drop(['bins_numeric'], axis = 1), tiles_train['bins_numeric'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5971c10e-9c78-4cd5-bf77-a213f4e70ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>7123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>12171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td>1096</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "2732     2948         0.0                0.0       0.0                    0.0   \n",
       "630      2945         4.0                0.0       2.0                    1.0   \n",
       "2887     7123         1.0                0.0       0.0                    0.0   \n",
       "752     12171         0.0                0.0       2.0                    1.0   \n",
       "8106     1096         2.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "2732        0        1        0        0        0  ...      0      0      0   \n",
       "630         0        1        0        0        0  ...      0      0      0   \n",
       "2887        0        1        0        0        0  ...      0      0      0   \n",
       "752         0        1        0        0        0  ...      0      0      0   \n",
       "8106        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "2732      0      0      0      0      0      0      0  \n",
       "630       0      0      0      0      0      0      0  \n",
       "2887      0      0      0      0      0      0      0  \n",
       "752       0      0      0      0      0      0      0  \n",
       "8106      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18a322c-14fa-44a5-89ec-8b6ae7411008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>94101</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  RTTYP_I  \\\n",
       "0         0.0                0.0       0.0                    0.0        0   \n",
       "1         1.0                0.0       3.0                    6.0        0   \n",
       "2         0.0                0.0       0.0                    0.0        0   \n",
       "3         0.0                0.0       0.0                    0.0        0   \n",
       "4         0.0                0.0       0.0                    0.0        0   \n",
       "\n",
       "   RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  94101  ...  94129  94130  94131  94132  \\\n",
       "0        1        0        0        0      0  ...      0      0      0      1   \n",
       "1        1        0        0        0      0  ...      0      0      0      0   \n",
       "2        1        0        0        0      0  ...      0      0      0      0   \n",
       "3        1        0        0        0      0  ...      0      1      0      0   \n",
       "4        1        0        0        0      0  ...      0      0      0      0   \n",
       "\n",
       "   94133  94134  94141  94143  94158  94188  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      1      0      0      0      0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_test = pd.read_csv(r'./Data/Tiles_TEST.csv')\n",
    "x_test = tiles_test.drop(['Tile_ID','bins_numeric'], axis = 1)\n",
    "y_test = tiles_test['bins_numeric']\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 148, 188, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini = preprocess_data_part1(IMAGE_PATH)\n",
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51e4bbbe-914b-47dd-9e82-93722404f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84e1f01e-fc42-4bb8-9d18-e40fe8d215c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part15(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_val['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "#     images_mini = normalize(images_mini.reshape(6700,-1))\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fcfd6d0-bf6d-48b1-a404-00afbc2b9633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 148, 188, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_v = preprocess_data_part15(IMAGE_PATH)\n",
    "np.shape(images_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c499c7-9ec4-4f6c-8e9c-482de86f536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23790420-0c98-426f-8580-23f7d96e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part2(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in tiles_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc8e3f65-2368-4092-9b09-ecda4e0a35d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 148, 188, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_t = preprocess_data_part2(IMAGE_PATH)\n",
    "np.shape(images_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 1, 1, 39)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "street = np.asarray(x_train).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c923520c-ed3c-4165-abd9-7b3cc932b35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 1, 1, 39)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAL SET \n",
    "\n",
    "street_v = np.asarray(x_val).astype('float32')\n",
    "street_mini_v = []\n",
    "for row in range(len(street_v)):\n",
    "    street_mini_v.append([[street_v[row]]])\n",
    "street_mini_v = np.stack(street_mini_v)\n",
    "np.shape(street_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c28b0428-174b-4e10-b151-1354cf44bf79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 1, 1, 39)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST SET \n",
    "\n",
    "street_t = np.asarray(x_test).astype('float32')\n",
    "street_mini_t = []\n",
    "for row in range(len(street_t)):\n",
    "    street_mini_t.append([[street_t[row]]])\n",
    "street_mini_t = np.stack(street_mini_t)\n",
    "np.shape(street_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0dbb-2532-4c3a-b053-1f6f687be79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f8956",
   "metadata": {},
   "source": [
    "Helpful Links: <br>\n",
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 <br>\n",
    "https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py <BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020edd3a-0c97-45f9-875d-3df38db9251f",
   "metadata": {},
   "source": [
    "**Model 2.9.0: Simplified CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af93dd1e-4394-4ba2-ac1c-593d00d2bff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ones\n",
      "bins      \n",
      "0     5297\n",
      "1      108\n",
      "2      968\n",
      "3      230\n",
      "4       22\n",
      "5        4\n",
      "6       53\n",
      "7       11\n",
      "8        3\n",
      "9        1\n",
      "10       3\n"
     ]
    }
   ],
   "source": [
    "check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42e82273-164e-45f2-86f3-5c7de058c9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.11498790052688486,\n",
       " 1: 5.63973063973064,\n",
       " 2: 0.6292261457550714,\n",
       " 3: 2.6482213438735176,\n",
       " 4: 27.68595041322314,\n",
       " 5: 152.27272727272728,\n",
       " 6: 11.492281303602057,\n",
       " 7: 55.37190082644628,\n",
       " 8: 203.03030303030303,\n",
       " 9: 609.0909090909091,\n",
       " 10: 203.03030303030303}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d656426-1f37-4a04-a8fe-f3f08160cf51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 50, 50, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_mini_2 = [] \n",
    "for k in range(len(street)):\n",
    "    for i in range(50): \n",
    "        for j in range(50):\n",
    "            street_mini_2.append(street[k])\n",
    "street_mini_2 = np.reshape(street_mini_2, (len(street),50,50,39))\n",
    "np.shape(street_mini_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9cd3b05-a13a-4f51-be78-5831b546deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 50, 50, 39)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_mini_2_v = [] \n",
    "for k in range(len(street_v)):\n",
    "    for i in range(50): \n",
    "        for j in range(50):\n",
    "            street_mini_2_v.append(street_v[k])\n",
    "street_mini_2_v = np.reshape(street_mini_2_v, (len(street_v),50,50,39))\n",
    "np.shape(street_mini_2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91c34f-cb4c-47c3-bb19-4540b41de68a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_Images (InputLayer)      [(None, 148, 188, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 146, 186, 6)  222         ['Input_Images[0][0]']           \n",
      "                                                                                                  \n",
      " Input_Street (InputLayer)      [(None, 50, 50, 39)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 48, 48, 6)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 48, 48, 2)    704         ['Input_Street[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 48, 48, 8)    0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 47, 47, 39)   1287        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " avgpool (GlobalAveragePooling2  (None, 39)          0           ['conv2d_2[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 11)           440         ['avgpool[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,653\n",
      "Trainable params: 2,653\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 06:18:25.429546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-07 06:18:25.429595: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-07 06:18:25.429628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-13-91): /proc/driver/nvidia/version does not exist\n",
      "2023-04-07 06:18:25.430937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 06:18:25.687816: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2982732800 exceeds 10% of free system memory.\n",
      "2023-04-07 06:18:27.853505: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2613000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/ubuntu/capstone/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "210/210 [==============================] - ETA: 0s - loss: 2.4409 - accuracy: 0.0540 - precision: 0.0000e+00 - f1_macro: 0.0178 - f1_weighted: 0.0228 \n",
      "Epoch 1: val_f1_weighted improved from -inf to 0.02604, saving model to model.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Images, Input_Street with unsupported characters which will be renamed to input_images, input_street in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4038s 19s/step - loss: 2.4409 - accuracy: 0.0540 - precision: 0.0000e+00 - f1_macro: 0.0178 - f1_weighted: 0.0228 - val_loss: 2.2197 - val_accuracy: 0.0770 - val_precision: 0.0000e+00 - val_f1_macro: 0.0204 - val_f1_weighted: 0.0260 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "210/210 [==============================] - ETA: 0s - loss: 2.4100 - accuracy: 0.4719 - precision: 0.0000e+00 - f1_macro: 0.0837 - f1_weighted: 0.5461 \n",
      "Epoch 2: val_f1_weighted improved from 0.02604 to 0.71850, saving model to model.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Images, Input_Street with unsupported characters which will be renamed to input_images, input_street in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4036s 19s/step - loss: 2.4100 - accuracy: 0.4719 - precision: 0.0000e+00 - f1_macro: 0.0837 - f1_weighted: 0.5461 - val_loss: 1.9510 - val_accuracy: 0.7381 - val_precision: 0.0000e+00 - val_f1_macro: 0.1078 - val_f1_weighted: 0.7185 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "210/210 [==============================] - ETA: 0s - loss: 2.3483 - accuracy: 0.7884 - precision: 0.0000e+00 - f1_macro: 0.1140 - f1_weighted: 0.7296 \n",
      "Epoch 3: val_f1_weighted improved from 0.71850 to 0.74736, saving model to model.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Images, Input_Street with unsupported characters which will be renamed to input_images, input_street in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4034s 19s/step - loss: 2.3483 - accuracy: 0.7884 - precision: 0.0000e+00 - f1_macro: 0.1140 - f1_weighted: 0.7296 - val_loss: 1.6077 - val_accuracy: 0.8085 - val_precision: 0.0000e+00 - val_f1_macro: 0.1217 - val_f1_weighted: 0.7474 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "210/210 [==============================] - ETA: 0s - loss: 2.2865 - accuracy: 0.8006 - precision: 0.5000 - f1_macro: 0.1198 - f1_weighted: 0.7358 \n",
      "Epoch 4: val_f1_weighted improved from 0.74736 to 0.75559, saving model to model.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Images, Input_Street with unsupported characters which will be renamed to input_images, input_street in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4035s 19s/step - loss: 2.2865 - accuracy: 0.8006 - precision: 0.5000 - f1_macro: 0.1198 - f1_weighted: 0.7358 - val_loss: 1.4512 - val_accuracy: 0.8091 - val_precision: 1.0000 - val_f1_macro: 0.1208 - val_f1_weighted: 0.7556 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "210/210 [==============================] - ETA: 0s - loss: 2.2451 - accuracy: 0.8009 - precision: 0.7812 - f1_macro: 0.1256 - f1_weighted: 0.7373 \n",
      "Epoch 5: val_f1_weighted did not improve from 0.75559\n",
      "210/210 [==============================] - 4032s 19s/step - loss: 2.2451 - accuracy: 0.8009 - precision: 0.7812 - f1_macro: 0.1256 - f1_weighted: 0.7373 - val_loss: 1.3216 - val_accuracy: 0.8109 - val_precision: 0.8333 - val_f1_macro: 0.1178 - val_f1_weighted: 0.7546 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "210/210 [==============================] - ETA: 0s - loss: 2.2088 - accuracy: 0.8001 - precision: 0.8077 - f1_macro: 0.1153 - f1_weighted: 0.7344 \n",
      "Epoch 6: val_f1_weighted did not improve from 0.75559\n",
      "210/210 [==============================] - 4035s 19s/step - loss: 2.2088 - accuracy: 0.8001 - precision: 0.8077 - f1_macro: 0.1153 - f1_weighted: 0.7344 - val_loss: 1.2807 - val_accuracy: 0.8067 - val_precision: 0.9000 - val_f1_macro: 0.1198 - val_f1_weighted: 0.7501 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "144/210 [===================>..........] - ETA: 20:53 - loss: 1.9938 - accuracy: 0.7993 - precision: 0.6316 - f1_macro: 0.1206 - f1_weighted: 0.7372"
     ]
    }
   ],
   "source": [
    "# From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# y: Future collision bin\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(50,50,39), name='Input_Street') \n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(6, (3,3), activation=\"relu\")(input1) # layers = street data dimension, changed dimensions to be according to paper\n",
    "    pooling = tf.keras.layers.MaxPooling2D((99, 139), strides=1)(cnn) #downsizing, per paper\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    cnn2 = tf.keras.layers.Conv2D(2, (3,3), activation=\"relu\")(input2)\n",
    "    street = tf.keras.models.Model(inputs=input2, outputs=cnn2)\n",
    "    \n",
    "    combined = tf.keras.layers.Concatenate(axis = 3)([images.output, street.output])\n",
    "    #combined = tf.keras.layers.Add()([images.output, street.output])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    #resnet = resnet18(combined)\n",
    "    \n",
    "    cnn = tf.keras.layers.Conv2D(39, (2,2), activation=\"relu\")(combined) # layers = street data dimension\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(cnn)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(x) # units = number of classes\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "f1_m = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'macro',\n",
    "    threshold = None,\n",
    "    name = 'f1_macro',\n",
    "    )\n",
    "\n",
    "f1_w = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'weighted',\n",
    "    threshold = None,\n",
    "    name = 'f1_weighted',\n",
    "    )\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), #learning rate defined by scheduler\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy', keras.metrics.Precision(), f1_m, f1_w])\n",
    "\n",
    "y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"model.9\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_weighted', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_check = checkpoint\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 8:\n",
    "        return 0.0001\n",
    "    elif epoch < 13:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [images_mini, street_mini_2],\n",
    "    y_t,\n",
    "    epochs=15,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    validation_data=([images_mini_v, street_mini_2_v], y_v),\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    #validation_split = 0.2,\n",
    "    class_weight = class_weights,\n",
    "    callbacks=[callback, callbacks_check],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d91844-64dc-4348-b024-783281f26bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving last epoch model just in case \n",
    "cnn_model.save('model.9.last.epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccdeff-f234-4fe1-b16b-c5db3c38830e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c6bdb-832f-43fa-bcf9-d5908aafdb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805e4cd-dcb7-4568-845a-2e4e62d8a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_macro(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08e9fe-11ef-4aea-9cea-d4cd5bc26312",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_weighted(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023511e5",
   "metadata": {},
   "source": [
    "**Analysis of Best Checkpoint Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6468f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "filepath = \"model.9\"\n",
    "best_model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe81ee-3020-46ca-a1eb-93acd0da22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict([images_mini_v, street_mini_2_v])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b563fc-8984-4b33-9ede-bee946fa2f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values = []\n",
    "for i in y_pred: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values.append(index[0])\n",
    "pred_values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862034d-b68b-4ebc-92dd-f0cbf5f39c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_val)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a56d10-ec48-4cb6-9e9a-10490eb6ac37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values)\n",
    "ind = max(max(np.unique(y_true)), max(np.unique(pred_values))) + 1\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "                  columns = [i for i in range(ind)])\n",
    "df_cm\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "sn.heatmap(df_cm, annot=True, fmt='.3g',cmap=\"OrRd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
