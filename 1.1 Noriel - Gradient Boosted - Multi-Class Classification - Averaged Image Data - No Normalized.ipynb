{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2712fb1-0724-488c-9068-22bdc9a45423",
   "metadata": {},
   "source": [
    "**Gradient Boosted Tree - Multi-Class Classification - Averaged Image Data - Not Normalized Data Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 17:27:10.058607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-25 17:27:11.192444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-25 17:27:11.192479: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-25 17:27:14.137577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 17:27:14.137692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 17:27:14.137703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3693092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Long2</th>\n",
       "      <th>Lat2</th>\n",
       "      <th>Long1</th>\n",
       "      <th>Lat1</th>\n",
       "      <th>Mid_lat</th>\n",
       "      <th>Mid_long</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Paving_future</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.776925</td>\n",
       "      <td>37.777377</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tile_ID       Long2       Lat2       Long1       Lat1    Mid_lat  \\\n",
       "0       36 -122.514446  37.779636 -122.513306  37.778732  37.779184   \n",
       "1       37 -122.514446  37.778732 -122.513306  37.777829  37.778280   \n",
       "2      151 -122.513306  37.779636 -122.512166  37.778732  37.779184   \n",
       "3      152 -122.513306  37.778732 -122.512166  37.777829  37.778280   \n",
       "4      153 -122.513306  37.777829 -122.512166  37.776925  37.777377   \n",
       "\n",
       "     Mid_long  Stop_Signs  Paving_historical  Paving_future  ...  94129  \\\n",
       "0 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "1 -122.513876         0.0                0.0            0.0  ...      0   \n",
       "2 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "3 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "4 -122.512736         0.0                0.0            0.0  ...      0   \n",
       "\n",
       "   94130  94131 94132  94133  94134  94141  94143  94158  94188  \n",
       "0      0      0     0      0      0      0      0      0      0  \n",
       "1      0      0     0      0      0      0      0      0      0  \n",
       "2      0      0     0      0      0      0      0      0      0  \n",
       "3      0      0     0      0      0      0      0      0      0  \n",
       "4      0      0     0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = pd.read_csv(r'./Data/Tiles_binned_zipcode.csv')\n",
    "tiles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tiles[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I',\n",
    "       'RTTYP_M', 'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']], \n",
    "                                   tiles['bin'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    data_mini_test = []\n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        \n",
    "        # append to images\n",
    "        data_mini.append(np.mean(image))\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    for id in x_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "        \n",
    "        # append to images\n",
    "        data_mini_test.append(np.mean(image))\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini_test = np.stack(data_mini_test)\n",
    "    \n",
    "    return images_mini, images_mini_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mini, images_mini_test = preprocess_data_part1(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48699797-0b48-44ec-b81a-86020373a8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  (8376,)\n",
      "test  (2095,)\n"
     ]
    }
   ],
   "source": [
    "print('train ', np.shape(images_mini))\n",
    "print('test ', np.shape(images_mini_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  (8376, 1, 1, 52)\n",
      "test  (2095, 1, 1, 52)\n"
     ]
    }
   ],
   "source": [
    "street = np.asarray(x_train[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']]).astype('float32')\n",
    "street_mini = []\n",
    "for row in range(len(street)):\n",
    "    street_mini.append([[street[row]]])\n",
    "street_mini = np.stack(street_mini)\n",
    "print('train ', np.shape(street_mini))\n",
    "\n",
    "street_test = np.asarray(x_test[['Tile_ID', 'Long2', 'Lat2', 'Long1', 'Lat1', 'Mid_lat', 'Mid_long',\n",
    "       'Stop_Signs', 'Paving_historical', 'Paving_future', 'Bus_stop',\n",
    "       'Collisions_Future', 'Collisions_Historical', 'RTTYP_I', 'RTTYP_M',\n",
    "       'RTTYP_O', 'RTTYP_S', 'RTTYP_U', 'Collisions_Future_binary',\n",
    "       'Collisions_Historical_binary', 'bins_numeric', 'zip_code', '94101',\n",
    "       '94102', '94104', '94105', '94107', '94108', '94109', '94110', '94111',\n",
    "       '94112', '94114', '94115', '94116', '94117', '94118', '94121', '94122',\n",
    "       '94123', '94124', '94127', '94129', '94130', '94131', '94132', '94133',\n",
    "       '94134', '94141', '94143', '94158', '94188']]).astype('float32')\n",
    "street_mini_test = []\n",
    "for row in range(len(street_test)):\n",
    "    street_mini_test.append([[street_test[row]]])\n",
    "street_mini_test = np.stack(street_mini_test)\n",
    "print('test ',np.shape(street_mini_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5275800-edf8-4225-a07c-998b25870208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image_street = np.hstack(\n",
    "    (street_mini.reshape((8376,52)),\n",
    "     images_mini.reshape(8376,1))\n",
    ")\n",
    "np.shape(input_image_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0771ebca-a17e-4a7f-b8b6-0ebbf258a123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 53)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image_street_test = np.hstack(\n",
    "    (street_mini_test.reshape((2095,52)),\n",
    "     images_mini_test.reshape(2095,1))\n",
    ")\n",
    "np.shape(input_image_street_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0d0a-47df-45ce-8bd4-9c31ed9d0cc3",
   "metadata": {},
   "source": [
    "Pre-process Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13e660c-d9ed-4991-ba6a-c0cece399b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8419     C\n",
       "10129    B\n",
       "7641     A\n",
       "5215     A\n",
       "7784     A\n",
       "Name: bin, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7217a2b4-a4fb-4407-8f08-cf72e15cdbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e009aa6-17b0-4b25-a570-aba1ce6100ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77c3787-63c6-4417-a626-e29615e3ed26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(input_image_street)\n",
    "# X_scaled = scaler.transform(input_image_street)\n",
    "# X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e4029c-9726-4105-bbb9-932ab1baad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],'max_depth': [20,30,40, 100, 110],\n",
    "#     'max_features': ['sqrt'],'min_samples_leaf': [5,10,15],\n",
    "#     'min_samples_split': [40,50,60], 'n_estimators': [150, 200, 250]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestClassifier()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdaff37d-b624-434a-9b5c-0c20630e075d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_search.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9701c4cd-dfe9-4d74-a69b-b030194b187b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b653ae-6f91-40a2-bdc4-353ca93d8969",
   "metadata": {},
   "source": [
    "**Gradient Boosted Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f5545f1-c7c7-4345-901c-fc6d6e471f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpw68ssrg5 as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 17:28:44.796484: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-25 17:28:44.797542: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-25 17:28:44.797579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-13-91): /proc/driver/nvidia/version does not exist\n",
      "2023-03-25 17:28:44.799543: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/capstone/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/capstone/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:05.040442. Found 8376 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 17:28:49.972868: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1790] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2023-03-25 17:28:49.972911: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1800] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2023-03-25 17:28:49.972920: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1814] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "2023-03-25 17:28:49.975966: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:452] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "2023-03-25 17:28:49.976015: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1077] Training gradient boosted tree on 8376 example(s) and 53 feature(s).\n",
      "2023-03-25 17:28:49.980888: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1120] 7555 examples used for training and 821 examples used for validation\n",
      "2023-03-25 17:28:50.132043: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1518] \tnum-trees:1 train-loss:1.465770 train-accuracy:0.999603 valid-loss:1.466043 valid-accuracy:0.998782\n",
      "2023-03-25 17:28:50.260897: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1520] \tnum-trees:2 train-loss:1.110881 train-accuracy:0.999603 valid-loss:1.111232 valid-accuracy:0.998782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:13.906887\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 17:29:03.753573: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1568] Create final snapshot of the model at iteration 78\n",
      "2023-03-25 17:29:03.766773: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:247] Truncates the model to 836 tree(s) i.e. 76  iteration(s).\n",
      "2023-03-25 17:29:03.766921: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:309] Final model num-trees:76 valid-loss:0.000681 valid-accuracy:1.000000\n",
      "[INFO 2023-03-25T17:29:03.802217218+00:00 kernel.cc:1214] Loading model from path /tmp/tmpw68ssrg5/model/ with prefix 364356b9124149c8\n",
      "[INFO 2023-03-25T17:29:03.854146998+00:00 decision_forest.cc:661] Model loaded with 836 root(s), 18330 node(s), and 28 input feature(s).\n",
      "[INFO 2023-03-25T17:29:03.854180435+00:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 2023-03-25T17:29:03.854214204+00:00 kernel.cc:1046] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fb10cf81fc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fb10cf81fc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fb10cf81fc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb10aee7130>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model = tfdf.keras.GradientBoostedTreesModel() #categorical_algorithm = 'CART'\n",
    "\n",
    "gbt_model.fit(input_image_street,\n",
    "    y_train,\n",
    "    #validation_data=[x_test[['Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop']], y_test],     \n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ba0ab68-088d-42bf-9969-056c5c730567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (53):\n",
      "\tdata:0.0\n",
      "\tdata:0.1\n",
      "\tdata:0.10\n",
      "\tdata:0.11\n",
      "\tdata:0.12\n",
      "\tdata:0.13\n",
      "\tdata:0.14\n",
      "\tdata:0.15\n",
      "\tdata:0.16\n",
      "\tdata:0.17\n",
      "\tdata:0.18\n",
      "\tdata:0.19\n",
      "\tdata:0.2\n",
      "\tdata:0.20\n",
      "\tdata:0.21\n",
      "\tdata:0.22\n",
      "\tdata:0.23\n",
      "\tdata:0.24\n",
      "\tdata:0.25\n",
      "\tdata:0.26\n",
      "\tdata:0.27\n",
      "\tdata:0.28\n",
      "\tdata:0.29\n",
      "\tdata:0.3\n",
      "\tdata:0.30\n",
      "\tdata:0.31\n",
      "\tdata:0.32\n",
      "\tdata:0.33\n",
      "\tdata:0.34\n",
      "\tdata:0.35\n",
      "\tdata:0.36\n",
      "\tdata:0.37\n",
      "\tdata:0.38\n",
      "\tdata:0.39\n",
      "\tdata:0.4\n",
      "\tdata:0.40\n",
      "\tdata:0.41\n",
      "\tdata:0.42\n",
      "\tdata:0.43\n",
      "\tdata:0.44\n",
      "\tdata:0.45\n",
      "\tdata:0.46\n",
      "\tdata:0.47\n",
      "\tdata:0.48\n",
      "\tdata:0.49\n",
      "\tdata:0.5\n",
      "\tdata:0.50\n",
      "\tdata:0.51\n",
      "\tdata:0.52\n",
      "\tdata:0.6\n",
      "\tdata:0.7\n",
      "\tdata:0.8\n",
      "\tdata:0.9\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1. \"data:0.11\"  0.387506 ################\n",
      "    2. \"data:0.20\"  0.345532 ############\n",
      "    3. \"data:0.12\"  0.317391 #########\n",
      "    4. \"data:0.10\"  0.258335 ####\n",
      "    5. \"data:0.23\"  0.217354 #\n",
      "    6.  \"data:0.0\"  0.210568 \n",
      "    7.  \"data:0.8\"  0.210355 \n",
      "    8. \"data:0.52\"  0.209374 \n",
      "    9. \"data:0.18\"  0.208967 \n",
      "   10.  \"data:0.6\"  0.205308 \n",
      "   11.  \"data:0.3\"  0.205128 \n",
      "   12.  \"data:0.1\"  0.204903 \n",
      "   13.  \"data:0.7\"  0.204682 \n",
      "   14.  \"data:0.4\"  0.204498 \n",
      "   15.  \"data:0.2\"  0.204326 \n",
      "   16.  \"data:0.5\"  0.204277 \n",
      "   17. \"data:0.21\"  0.204104 \n",
      "   18. \"data:0.22\"  0.203827 \n",
      "   19. \"data:0.33\"  0.203462 \n",
      "   20. \"data:0.36\"  0.203109 \n",
      "   21. \"data:0.19\"  0.203095 \n",
      "   22.  \"data:0.9\"  0.203076 \n",
      "   23. \"data:0.45\"  0.203072 \n",
      "   24. \"data:0.25\"  0.203061 \n",
      "   25. \"data:0.24\"  0.203060 \n",
      "   26. \"data:0.17\"  0.203053 \n",
      "   27. \"data:0.44\"  0.203053 \n",
      "   28. \"data:0.28\"  0.203052 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"data:0.20\" 319.000000 ################\n",
      "    2. \"data:0.11\" 297.000000 ##############\n",
      "    3. \"data:0.12\" 112.000000 #####\n",
      "    4. \"data:0.23\" 56.000000 ##\n",
      "    5. \"data:0.18\" 26.000000 #\n",
      "    6. \"data:0.10\" 20.000000 \n",
      "    7. \"data:0.22\"  4.000000 \n",
      "    8. \"data:0.21\"  2.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1. \"data:0.12\" 1913.000000 ################\n",
      "    2. \"data:0.11\" 1815.000000 ###############\n",
      "    3. \"data:0.20\" 1232.000000 ##########\n",
      "    4. \"data:0.10\" 1105.000000 #########\n",
      "    5. \"data:0.52\" 489.000000 ####\n",
      "    6.  \"data:0.0\" 480.000000 ####\n",
      "    7.  \"data:0.8\" 292.000000 ##\n",
      "    8. \"data:0.23\" 210.000000 #\n",
      "    9.  \"data:0.6\" 168.000000 #\n",
      "   10.  \"data:0.7\" 161.000000 #\n",
      "   11.  \"data:0.3\" 148.000000 #\n",
      "   12.  \"data:0.1\" 144.000000 #\n",
      "   13.  \"data:0.4\" 132.000000 #\n",
      "   14.  \"data:0.5\" 122.000000 #\n",
      "   15.  \"data:0.2\" 108.000000 \n",
      "   16. \"data:0.18\" 93.000000 \n",
      "   17. \"data:0.21\" 73.000000 \n",
      "   18. \"data:0.33\" 35.000000 \n",
      "   19. \"data:0.19\"  7.000000 \n",
      "   20.  \"data:0.9\"  5.000000 \n",
      "   21. \"data:0.22\"  4.000000 \n",
      "   22. \"data:0.36\"  3.000000 \n",
      "   23. \"data:0.24\"  2.000000 \n",
      "   24. \"data:0.45\"  2.000000 \n",
      "   25. \"data:0.17\"  1.000000 \n",
      "   26. \"data:0.25\"  1.000000 \n",
      "   27. \"data:0.28\"  1.000000 \n",
      "   28. \"data:0.44\"  1.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1. \"data:0.20\" 7047.064212 ################\n",
      "    2. \"data:0.11\" 2084.774361 ####\n",
      "    3. \"data:0.18\" 993.517065 ##\n",
      "    4. \"data:0.12\"  1.555504 \n",
      "    5. \"data:0.10\"  0.205127 \n",
      "    6.  \"data:0.3\"  0.137740 \n",
      "    7.  \"data:0.1\"  0.123836 \n",
      "    8.  \"data:0.6\"  0.094143 \n",
      "    9.  \"data:0.0\"  0.088784 \n",
      "   10. \"data:0.23\"  0.013095 \n",
      "   11. \"data:0.52\"  0.001719 \n",
      "   12. \"data:0.21\"  0.000698 \n",
      "   13.  \"data:0.7\"  0.000573 \n",
      "   14.  \"data:0.4\"  0.000317 \n",
      "   15.  \"data:0.5\"  0.000101 \n",
      "   16.  \"data:0.2\"  0.000020 \n",
      "   17. \"data:0.22\"  0.000001 \n",
      "   18.  \"data:0.8\"  0.000000 \n",
      "   19. \"data:0.19\"  0.000000 \n",
      "   20. \"data:0.33\"  0.000000 \n",
      "   21.  \"data:0.9\"  0.000000 \n",
      "   22. \"data:0.36\"  0.000000 \n",
      "   23. \"data:0.45\"  0.000000 \n",
      "   24. \"data:0.25\"  0.000000 \n",
      "   25. \"data:0.24\"  0.000000 \n",
      "   26. \"data:0.44\"  0.000000 \n",
      "   27. \"data:0.17\"  0.000000 \n",
      "   28. \"data:0.28\"  0.000000 \n",
      "\n",
      "\n",
      "\n",
      "Loss: MULTINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 0.000681253\n",
      "Number of trees per iteration: 11\n",
      "Node format: NOT_SET\n",
      "Number of trees: 836\n",
      "Total number of nodes: 18330\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 836 Average: 21.9258 StdDev: 8.02742\n",
      "Min: 7 Max: 41 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  7,  8)   1   0.12%   0.12%\n",
      "[  8, 10)  10   1.20%   1.32% #\n",
      "[ 10, 12)  62   7.42%   8.73% ####\n",
      "[ 12, 14)  85  10.17%  18.90% ######\n",
      "[ 14, 15)   0   0.00%  18.90%\n",
      "[ 15, 17) 147  17.58%  36.48% ##########\n",
      "[ 17, 19)  30   3.59%  40.07% ##\n",
      "[ 19, 21)  53   6.34%  46.41% ####\n",
      "[ 21, 22)  39   4.67%  51.08% ###\n",
      "[ 22, 24)  61   7.30%  58.37% ####\n",
      "[ 24, 26)  43   5.14%  63.52% ###\n",
      "[ 26, 28)  94  11.24%  74.76% ######\n",
      "[ 28, 29)   0   0.00%  74.76%\n",
      "[ 29, 31)  75   8.97%  83.73% #####\n",
      "[ 31, 33)  25   2.99%  86.72% ##\n",
      "[ 33, 35)  24   2.87%  89.59% ##\n",
      "[ 35, 36)  52   6.22%  95.81% ####\n",
      "[ 36, 38)  21   2.51%  98.33% #\n",
      "[ 38, 40)  12   1.44%  99.76% #\n",
      "[ 40, 41]   2   0.24% 100.00%\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 9583 Average: 4.0552 StdDev: 1.12876\n",
      "Min: 1 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)  288   3.01%   3.01% #\n",
      "[ 2, 3)  820   8.56%  11.56% ##\n",
      "[ 3, 4) 1667  17.40%  28.96% ####\n",
      "[ 4, 5) 2108  22.00%  50.95% ####\n",
      "[ 5, 5] 4700  49.05% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 9583 Average: 659.082 StdDev: 1961.3\n",
      "Min: 5 Max: 7525 Ignored: 0\n",
      "----------------------------------------------\n",
      "[    5,  381) 8463  88.31%  88.31% ##########\n",
      "[  381,  757)   51   0.53%  88.84%\n",
      "[  757, 1133)  107   1.12%  89.96%\n",
      "[ 1133, 1509)   51   0.53%  90.49%\n",
      "[ 1509, 1885)   50   0.52%  91.02%\n",
      "[ 1885, 2261)    6   0.06%  91.08%\n",
      "[ 2261, 2637)    3   0.03%  91.11%\n",
      "[ 2637, 3013)   13   0.14%  91.24%\n",
      "[ 3013, 3389)    8   0.08%  91.33%\n",
      "[ 3389, 3765)    5   0.05%  91.38%\n",
      "[ 3765, 4141)    7   0.07%  91.45%\n",
      "[ 4141, 4517)   13   0.14%  91.59%\n",
      "[ 4517, 4893)    2   0.02%  91.61%\n",
      "[ 4893, 5269)    7   0.07%  91.68%\n",
      "[ 5269, 5645)   20   0.21%  91.89%\n",
      "[ 5645, 6021)  135   1.41%  93.30%\n",
      "[ 6021, 6397)    9   0.09%  93.39%\n",
      "[ 6397, 6773)   21   0.22%  93.61%\n",
      "[ 6773, 7149)  107   1.12%  94.73%\n",
      "[ 7149, 7525]  505   5.27% 100.00% #\n",
      "\n",
      "Attribute in nodes:\n",
      "\t1913 : data:0.12 [NUMERICAL]\n",
      "\t1815 : data:0.11 [NUMERICAL]\n",
      "\t1232 : data:0.20 [NUMERICAL]\n",
      "\t1105 : data:0.10 [NUMERICAL]\n",
      "\t489 : data:0.52 [NUMERICAL]\n",
      "\t480 : data:0.0 [NUMERICAL]\n",
      "\t292 : data:0.8 [NUMERICAL]\n",
      "\t210 : data:0.23 [NUMERICAL]\n",
      "\t168 : data:0.6 [NUMERICAL]\n",
      "\t161 : data:0.7 [NUMERICAL]\n",
      "\t148 : data:0.3 [NUMERICAL]\n",
      "\t144 : data:0.1 [NUMERICAL]\n",
      "\t132 : data:0.4 [NUMERICAL]\n",
      "\t122 : data:0.5 [NUMERICAL]\n",
      "\t108 : data:0.2 [NUMERICAL]\n",
      "\t93 : data:0.18 [NUMERICAL]\n",
      "\t73 : data:0.21 [NUMERICAL]\n",
      "\t35 : data:0.33 [NUMERICAL]\n",
      "\t7 : data:0.19 [NUMERICAL]\n",
      "\t5 : data:0.9 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t3 : data:0.36 [NUMERICAL]\n",
      "\t2 : data:0.45 [NUMERICAL]\n",
      "\t2 : data:0.24 [NUMERICAL]\n",
      "\t1 : data:0.44 [NUMERICAL]\n",
      "\t1 : data:0.28 [NUMERICAL]\n",
      "\t1 : data:0.25 [NUMERICAL]\n",
      "\t1 : data:0.17 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t319 : data:0.20 [NUMERICAL]\n",
      "\t297 : data:0.11 [NUMERICAL]\n",
      "\t112 : data:0.12 [NUMERICAL]\n",
      "\t56 : data:0.23 [NUMERICAL]\n",
      "\t26 : data:0.18 [NUMERICAL]\n",
      "\t20 : data:0.10 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t2 : data:0.21 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t762 : data:0.11 [NUMERICAL]\n",
      "\t609 : data:0.20 [NUMERICAL]\n",
      "\t432 : data:0.12 [NUMERICAL]\n",
      "\t241 : data:0.10 [NUMERICAL]\n",
      "\t56 : data:0.23 [NUMERICAL]\n",
      "\t27 : data:0.0 [NUMERICAL]\n",
      "\t26 : data:0.18 [NUMERICAL]\n",
      "\t21 : data:0.52 [NUMERICAL]\n",
      "\t17 : data:0.8 [NUMERICAL]\n",
      "\t6 : data:0.3 [NUMERICAL]\n",
      "\t6 : data:0.1 [NUMERICAL]\n",
      "\t4 : data:0.6 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t3 : data:0.4 [NUMERICAL]\n",
      "\t3 : data:0.21 [NUMERICAL]\n",
      "\t3 : data:0.2 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t1114 : data:0.11 [NUMERICAL]\n",
      "\t878 : data:0.12 [NUMERICAL]\n",
      "\t817 : data:0.20 [NUMERICAL]\n",
      "\t616 : data:0.10 [NUMERICAL]\n",
      "\t144 : data:0.0 [NUMERICAL]\n",
      "\t121 : data:0.8 [NUMERICAL]\n",
      "\t112 : data:0.52 [NUMERICAL]\n",
      "\t59 : data:0.3 [NUMERICAL]\n",
      "\t56 : data:0.23 [NUMERICAL]\n",
      "\t54 : data:0.6 [NUMERICAL]\n",
      "\t43 : data:0.1 [NUMERICAL]\n",
      "\t27 : data:0.18 [NUMERICAL]\n",
      "\t24 : data:0.7 [NUMERICAL]\n",
      "\t21 : data:0.21 [NUMERICAL]\n",
      "\t19 : data:0.4 [NUMERICAL]\n",
      "\t19 : data:0.2 [NUMERICAL]\n",
      "\t14 : data:0.5 [NUMERICAL]\n",
      "\t14 : data:0.33 [NUMERICAL]\n",
      "\t6 : data:0.19 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t2 : data:0.36 [NUMERICAL]\n",
      "\t1 : data:0.45 [NUMERICAL]\n",
      "\t1 : data:0.44 [NUMERICAL]\n",
      "\t1 : data:0.25 [NUMERICAL]\n",
      "\t1 : data:0.17 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t1557 : data:0.12 [NUMERICAL]\n",
      "\t1424 : data:0.11 [NUMERICAL]\n",
      "\t947 : data:0.20 [NUMERICAL]\n",
      "\t814 : data:0.10 [NUMERICAL]\n",
      "\t331 : data:0.0 [NUMERICAL]\n",
      "\t325 : data:0.52 [NUMERICAL]\n",
      "\t185 : data:0.8 [NUMERICAL]\n",
      "\t116 : data:0.6 [NUMERICAL]\n",
      "\t112 : data:0.23 [NUMERICAL]\n",
      "\t110 : data:0.3 [NUMERICAL]\n",
      "\t99 : data:0.1 [NUMERICAL]\n",
      "\t74 : data:0.4 [NUMERICAL]\n",
      "\t68 : data:0.5 [NUMERICAL]\n",
      "\t64 : data:0.7 [NUMERICAL]\n",
      "\t47 : data:0.2 [NUMERICAL]\n",
      "\t43 : data:0.18 [NUMERICAL]\n",
      "\t35 : data:0.21 [NUMERICAL]\n",
      "\t28 : data:0.33 [NUMERICAL]\n",
      "\t6 : data:0.19 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t2 : data:0.45 [NUMERICAL]\n",
      "\t2 : data:0.36 [NUMERICAL]\n",
      "\t1 : data:0.44 [NUMERICAL]\n",
      "\t1 : data:0.25 [NUMERICAL]\n",
      "\t1 : data:0.24 [NUMERICAL]\n",
      "\t1 : data:0.17 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t1913 : data:0.12 [NUMERICAL]\n",
      "\t1815 : data:0.11 [NUMERICAL]\n",
      "\t1232 : data:0.20 [NUMERICAL]\n",
      "\t1105 : data:0.10 [NUMERICAL]\n",
      "\t489 : data:0.52 [NUMERICAL]\n",
      "\t480 : data:0.0 [NUMERICAL]\n",
      "\t292 : data:0.8 [NUMERICAL]\n",
      "\t210 : data:0.23 [NUMERICAL]\n",
      "\t168 : data:0.6 [NUMERICAL]\n",
      "\t161 : data:0.7 [NUMERICAL]\n",
      "\t148 : data:0.3 [NUMERICAL]\n",
      "\t144 : data:0.1 [NUMERICAL]\n",
      "\t132 : data:0.4 [NUMERICAL]\n",
      "\t122 : data:0.5 [NUMERICAL]\n",
      "\t108 : data:0.2 [NUMERICAL]\n",
      "\t93 : data:0.18 [NUMERICAL]\n",
      "\t73 : data:0.21 [NUMERICAL]\n",
      "\t35 : data:0.33 [NUMERICAL]\n",
      "\t7 : data:0.19 [NUMERICAL]\n",
      "\t5 : data:0.9 [NUMERICAL]\n",
      "\t4 : data:0.22 [NUMERICAL]\n",
      "\t3 : data:0.36 [NUMERICAL]\n",
      "\t2 : data:0.45 [NUMERICAL]\n",
      "\t2 : data:0.24 [NUMERICAL]\n",
      "\t1 : data:0.44 [NUMERICAL]\n",
      "\t1 : data:0.28 [NUMERICAL]\n",
      "\t1 : data:0.25 [NUMERICAL]\n",
      "\t1 : data:0.17 [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t8747 : HigherCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t836 : HigherCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t2220 : HigherCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t4168 : HigherCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t6397 : HigherCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t8747 : HigherCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 76\n",
      "\tIter:1 train-loss:1.465770 valid-loss:1.466043  train-accuracy:0.999603 valid-accuracy:0.998782\n",
      "\tIter:2 train-loss:1.110881 valid-loss:1.111232  train-accuracy:0.999603 valid-accuracy:0.998782\n",
      "\tIter:3 train-loss:0.876572 valid-loss:0.876947  train-accuracy:0.999603 valid-accuracy:0.998782\n",
      "\tIter:4 train-loss:0.705116 valid-loss:0.705527  train-accuracy:0.999603 valid-accuracy:0.998782\n",
      "\tIter:5 train-loss:0.573510 valid-loss:0.573930  train-accuracy:0.999603 valid-accuracy:0.998782\n",
      "\tIter:6 train-loss:0.469754 valid-loss:0.470198  train-accuracy:0.999603 valid-accuracy:0.998782\n",
      "\tIter:16 train-loss:0.072671 valid-loss:0.073368  train-accuracy:0.999735 valid-accuracy:0.998782\n",
      "\tIter:26 train-loss:0.012000 valid-loss:0.013491  train-accuracy:1.000000 valid-accuracy:0.998782\n",
      "\tIter:36 train-loss:0.002050 valid-loss:0.004816  train-accuracy:1.000000 valid-accuracy:0.998782\n",
      "\tIter:46 train-loss:0.000365 valid-loss:0.003350  train-accuracy:1.000000 valid-accuracy:0.998782\n",
      "\tIter:56 train-loss:0.000069 valid-loss:0.001830  train-accuracy:1.000000 valid-accuracy:0.998782\n",
      "\tIter:66 train-loss:0.000015 valid-loss:0.000933  train-accuracy:1.000000 valid-accuracy:0.998782\n",
      "\tIter:76 train-loss:0.000004 valid-loss:0.000681  train-accuracy:1.000000 valid-accuracy:1.000000\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gbt_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec998745-a7da-4057-84fa-b3516fc532ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrainLog(num_trees=1, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=1.4660427570343018, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=2, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=1.1112316846847534, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=3, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.8769471049308777, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=4, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.705527126789093, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=5, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.5739298462867737, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=6, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.4701980650424957, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=7, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.38703325390815735, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=8, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.3196476399898529, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=9, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.2646600902080536, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=10, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.2195257842540741, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=11, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.18236839771270752, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=12, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.15166661143302917, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=13, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.12629711627960205, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=14, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.10528607666492462, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=15, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.08784352242946625, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=16, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.07336810231208801, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=17, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.061330486088991165, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=18, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.05137503147125244, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=19, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.04310769587755203, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=20, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.03622855246067047, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=21, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.030459722504019737, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=22, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.02570497617125511, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=23, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.02176680602133274, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=24, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.018573792651295662, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=25, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.015802301466464996, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=26, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.013491335324943066, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=27, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.011628063395619392, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=28, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.010157065466046333, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=29, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.008954762481153011, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=30, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.007844280451536179, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=31, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.006978150457143784, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=32, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.006340045016258955, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=33, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.005826406646519899, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=34, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0054127369076013565, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=35, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.005097109824419022, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=36, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004816198721528053, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=37, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004628020338714123, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=38, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004502152558416128, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=39, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004503487143665552, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=40, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004333255346864462, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=41, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004316240083426237, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=42, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.004205950535833836, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=43, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0040364572778344154, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=44, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.003753168974071741, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=45, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0035986448638141155, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=46, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0033503638114780188, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=47, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.003118168329820037, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=48, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0030023131985217333, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=49, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0027954052202403545, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=50, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0026029828004539013, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=51, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0025131849106401205, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=52, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0023012554738670588, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=53, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0020992590580135584, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=54, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.002054930664598942, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=55, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0019831836689263582, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=56, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0018301097443327308, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=57, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0016878466121852398, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=58, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0016303494339808822, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=59, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0014659564476460218, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=60, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0014120250707492232, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=61, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0012902686139568686, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=62, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.001242321915924549, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=63, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0011039364617317915, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=64, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0009751634788699448, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=65, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0009592369315214455, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=66, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0009326094295829535, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=67, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0008962256833910942, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=68, evaluation=Evaluation(num_examples=None, accuracy=0.9987819790840149, loss=0.0008702141931280494, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=69, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0008363410015590489, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=70, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0008028607699088752, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=71, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0008057874510996044, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=72, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0007631713524460793, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=73, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0007341995951719582, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=74, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0007362478063441813, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=75, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.000707963714376092, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=76, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0006812526844441891, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=77, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0007164202979765832, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=78, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0006890934891998768, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
       " TrainLog(num_trees=79, evaluation=Evaluation(num_examples=None, accuracy=1.0, loss=0.0006829899502918124, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##uncomment to show training log\n",
    "gbt_model.make_inspector().training_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53a7b368-4fd5-41b2-a5bd-252034d9aff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(num_examples=None, accuracy=1.0, loss=0.0006812526844441891, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee2ad9aa-418c-4651-a273-da7ba9a6de7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = gbt_model.make_inspector().training_logs()\n",
    "\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs], label=\"training data\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68c70244-4ee6-4aae-8f71-31242038b22d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model.evaluate(input_image_street_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7cb3da7-68d3-43cf-8cb7-94958367d80a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9999869e-01, 1.3076559e-07, 1.3076559e-07, ..., 1.3076559e-07,\n",
       "        1.3076559e-07, 1.3076559e-07],\n",
       "       [3.3789513e-06, 1.4183739e-06, 2.7112071e-06, ..., 5.9613376e-07,\n",
       "        1.0303917e-06, 5.1483762e-06],\n",
       "       [9.9999869e-01, 1.3076559e-07, 1.3076559e-07, ..., 1.3076559e-07,\n",
       "        1.3076559e-07, 1.3076559e-07],\n",
       "       ...,\n",
       "       [9.9999869e-01, 1.3076559e-07, 1.3076559e-07, ..., 1.3076559e-07,\n",
       "        1.3076559e-07, 1.3076559e-07],\n",
       "       [9.9999869e-01, 1.3076559e-07, 1.3076559e-07, ..., 1.3076559e-07,\n",
       "        1.3076559e-07, 1.3076559e-07],\n",
       "       [9.9999493e-01, 1.3766743e-06, 6.5541963e-07, ..., 2.6117988e-07,\n",
       "        8.5221666e-07, 4.5617762e-07]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model.predict(input_image_street_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b661fd88-4dea-4527-83d7-0dc57ce5fd23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n",
      "macro f1:  0.7878787878787878\n",
      "f1 by class:  [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.66666667 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "predicted_result = gbt_model.predict(input_image_street_test)\n",
    "test_values = []\n",
    "for i in predicted_result: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    test_values.append(index[0])\n",
    "print('macro f1: ', f1_score(y_test, test_values, average = 'macro' ))\n",
    "print('f1 by class: ', f1_score(y_test, test_values, average = None ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d7710-a1d3-43ac-8dfc-879350674225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
