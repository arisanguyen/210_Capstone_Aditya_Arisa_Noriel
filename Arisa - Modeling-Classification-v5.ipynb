{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow_addons as tfa\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459b53d-c4e9-4304-9ea5-699ebb32f4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_f1(history):\n",
    "    plt.plot(history.history['f1'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1']),\n",
    "                max(history.history['val_f1'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x1 = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x2 = make_layer(x1, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x3 = make_layer(x2, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x4 = make_layer(x3, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    #x = layers.GlobalAveragePooling2D(name='avgpool')(x4)\n",
    "    #initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    #x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x1, x2, x3, x4\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    return resnet(x, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Pulling in Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_train = pd.read_csv(r'./Data/Tiles_TRAIN.csv')\n",
    "#x_train = tiles_train.drop(['bins_numeric'], axis = 1)\n",
    "#y_train = tiles_train['bins_numeric']\n",
    "#x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453b058-407b-4097-a463-b18eb8ebb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(tiles_train.drop(['bins_numeric'], axis = 1), tiles_train['bins_numeric'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971c10e-9c78-4cd5-bf77-a213f4e70ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a322c-14fa-44a5-89ec-8b6ae7411008",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_test = pd.read_csv(r'./Data/Tiles_TEST.csv')\n",
    "x_test = tiles_test.drop(['Tile_ID','bins_numeric'], axis = 1)\n",
    "y_test = tiles_test['bins_numeric']\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mini = preprocess_data_part1(IMAGE_PATH)\n",
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4bbbe-914b-47dd-9e82-93722404f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1f01e-fc42-4bb8-9d18-e40fe8d215c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part15(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_val['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfd6d0-bf6d-48b1-a404-00afbc2b9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mini_v = preprocess_data_part15(IMAGE_PATH)\n",
    "np.shape(images_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c499c7-9ec4-4f6c-8e9c-482de86f536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23790420-0c98-426f-8580-23f7d96e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part2(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in tiles_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e3f65-2368-4092-9b09-ecda4e0a35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_mini_t = preprocess_data_part2(IMAGE_PATH)\n",
    "# np.shape(images_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "street = np.asarray(x_train).astype('float32')\n",
    "# street_mini = []\n",
    "# for row in range(len(street)):\n",
    "#     street_mini.append([[street[row]]])\n",
    "# street_mini = np.stack(street_mini)\n",
    "# np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923520c-ed3c-4165-abd9-7b3cc932b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "street_v = np.asarray(x_val).astype('float32')\n",
    "# street_mini_v = []\n",
    "# for row in range(len(street_v)):\n",
    "#     street_mini_v.append([[street_v[row]]])\n",
    "# street_mini_v = np.stack(street_mini_v)\n",
    "# np.shape(street_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b0428-174b-4e10-b151-1354cf44bf79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST SET \n",
    "\n",
    "# street_t = np.asarray(x_test).astype('float32')\n",
    "# street_mini_t = []\n",
    "# for row in range(len(street_t)):\n",
    "#     street_mini_t.append([[street_t[row]]])\n",
    "# street_mini_t = np.stack(street_mini_t)\n",
    "# np.shape(street_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0dbb-2532-4c3a-b053-1f6f687be79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f8956",
   "metadata": {},
   "source": [
    "Helpful Links: <br>\n",
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 <br>\n",
    "https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py <BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b3df3-7bf5-461b-ae34-6477dae4f045",
   "metadata": {},
   "source": [
    "**Model 2.5.0: Class Weights Corrected, Copying Paper, Pooling + 3 More Conv Layers, Normalized Pixels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391fd79a-d6a9-4a8e-93a7-e097bc3a7abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed845fbf-e8ef-42d1-9a7a-2ec469673a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3420cb-a963-4aa0-9acf-5553c257b1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "street_mini_2 = [] \n",
    "for k in range(len(street)):\n",
    "    for i in range(96): \n",
    "        for j in range(96):\n",
    "            street_mini_2.append(street[k])\n",
    "street_mini_2 = np.reshape(street_mini_2, (len(street),96,96,39))\n",
    "np.shape(street_mini_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4dff01-abe6-453e-a2fc-1b68637537d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_mini_2_v = [] \n",
    "for k in range(len(street_v)):\n",
    "    for i in range(96): \n",
    "        for j in range(96):\n",
    "            street_mini_2_v.append(street_v[k])\n",
    "street_mini_2_v = np.reshape(street_mini_2_v, (len(street_v),96,96,39))\n",
    "np.shape(street_mini_2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0de1ee-0fcd-4f52-9045-907a1903fcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# y: Future collision bin\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model4():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(96,96,39), name='Input_Street') \n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(6, (3,3), activation=\"relu\")(input1) # layers = street data dimension, changed dimensions to be according to paper\n",
    "    pooling = tf.keras.layers.MaxPooling2D((101, 141), strides=1)(cnn) #downsizing, per paper\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    cnn2 = tf.keras.layers.Conv2D(2, (3,3), activation=\"relu\")(input2)\n",
    "    street = tf.keras.models.Model(inputs=input2, outputs=cnn2)\n",
    "    \n",
    "    combined = tf.keras.layers.Concatenate(axis = 3)([images.output, street.output])\n",
    "    #combined = tf.keras.layers.Add()([images.output, street.output])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet1, resnet2, resnet3, resnet4 = resnet18(combined, num_classes = 11)\n",
    "    \n",
    "    resnet2 = tf.keras.layers.UpSampling2D(size=(2,2))(resnet2) # added this per paper\n",
    "    resnet3 = tf.keras.layers.UpSampling2D(size=(4,4))(resnet3) # added this per paper\n",
    "    resnet4 = tf.keras.layers.UpSampling2D(size=(8,8))(resnet4) # added this per paper\n",
    "    \n",
    "    resnet = tf.keras.layers.Concatenate(axis = 3)([resnet1, resnet2, resnet3, resnet4]) # added this per paper\n",
    "    \n",
    "    cnn = tf.keras.layers.Conv2D(960, (3,3), activation=\"relu\")(resnet) # added cnn, per paper\n",
    "    cnn = tf.keras.layers.Conv2D(960, (3,3), activation=\"relu\")(cnn) # added cnn, per paper\n",
    "    cnn = tf.keras.layers.Conv2D(2, (3,3), activation=\"relu\")(cnn) # added cnn, per paper\n",
    "    \n",
    "    shape = tf.reshape(cnn, [-1,648], name=\"reshape\")\n",
    "    \n",
    "    output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(shape) # units = number of classes\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model4 = create_cnn_model4()\n",
    "\n",
    "cnn_model4.summary()\n",
    "\n",
    "f1 = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'macro',\n",
    "    threshold = None,\n",
    "    name = 'f1',\n",
    "    )\n",
    "\n",
    "cnn_model4.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy', keras.metrics.Precision(), f1])\n",
    "\n",
    "# calculated in previous block \n",
    "# class_weight = {0: 1,\n",
    "#                 1: 10,\n",
    "#                 2: 10,\n",
    "#                 3: 10,\n",
    "#                 4: 10,\n",
    "#                 5: 10,\n",
    "#                 6: 10,\n",
    "#                 7: 10,\n",
    "#                 8: 10,\n",
    "#                 9: 10,\n",
    "#                 10: 10,\n",
    "#                 # 11: 10,\n",
    "#                }\n",
    "\n",
    "y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "#cnn_model1.load_weights(initial_weights) # initial weights from first or baseline model to make it comparable\n",
    "#cnn_model4.layers[-1].bias.assign([0,0,0,0,0,0,0,0,0,0,0]) # no bias, makes it more comparable to baseline model\n",
    "\n",
    "history = cnn_model4.fit(\n",
    "    [images_mini, street_mini_2],\n",
    "    y_t,\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    validation_data=([images_mini_v, street_mini_2_v], y_v),\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    #validation_split = 0.2,\n",
    "    class_weight = class_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed0337-c274-417d-91b7-470a18511886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3374f-0443-4fac-aade-026879e89c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3119f-65af-4ca2-af67-a9eb0049254f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36ab92-86da-4028-8a3e-7104fb7345db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = cnn_model4.predict([images_mini_v, street_mini_2_v])\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a016b7b-f9d7-4403-b3cf-9882ce9f153e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values2 = []\n",
    "for i in y_pred2: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values2.append(index[0])\n",
    "pred_values2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0d0d7-f2ad-4d0f-995b-bf144261b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_val)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c2971-d768-46c5-b8db-3d3a905c603f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values2)\n",
    "ind = max(len(np.unique(y_true)), len(np.unique(pred_values2)))\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "                  columns = [i for i in range(ind)])\n",
    "df_cm\n",
    "#plt.figure(figsize = (10,7))\n",
    "#sn.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
