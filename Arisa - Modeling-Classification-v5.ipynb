{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eabcba-5ca5-4fa8-bde3-8224131c3a6a",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 00:47:58.491912: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 00:47:58.646696: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-26 00:47:58.646727: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-26 00:47:59.581524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-26 00:47:59.581646: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-26 00:47:59.581658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow_addons as tfa\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166dc2-360e-4118-9f65-0996bbc163a1",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c1eeab-df74-4a28-8b0f-7d937d42028c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d27acab-1145-4120-9a1c-c7da15f505d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "   # plt.plot(history.history['loss'], label='loss')\n",
    "   # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['accuracy']),\n",
    "                max(history.history['val_accuracy'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9459b53d-c4e9-4304-9ea5-699ebb32f4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_f1(history):\n",
    "    plt.plot(history.history['f1'], label='train_f1')\n",
    "    plt.plot(history.history['val_f1'], label='val_f1')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['f1']),\n",
    "                max(history.history['val_f1'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd28b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x1 = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x2 = make_layer(x1, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x3 = make_layer(x2, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x4 = make_layer(x3, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x4)\n",
    "    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x1, x2, x3, x4\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    return resnet(x, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b49-a808-4d41-ad4b-ae9469b994ea",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Pulling in Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_train = pd.read_csv(r'./Data/Tiles_TRAIN.csv')\n",
    "#x_train = tiles_train.drop(['bins_numeric'], axis = 1)\n",
    "#y_train = tiles_train['bins_numeric']\n",
    "#x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6453b058-407b-4097-a463-b18eb8ebb124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>11426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>13993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>3201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>13779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "1762     1526         0.0                0.0       0.0                    0.0   \n",
       "4603    11426         0.0                7.0       0.0                    8.0   \n",
       "6484    13993         0.0                0.0       0.0                    0.0   \n",
       "6950     3201         0.0                0.0       0.0                    0.0   \n",
       "4254    13779         0.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "1762        0        1        0        0        0  ...      0      0      0   \n",
       "4603        0        1        0        0        0  ...      0      0      0   \n",
       "6484        0        1        0        0        0  ...      0      0      0   \n",
       "6950        0        1        0        0        0  ...      0      0      0   \n",
       "4254        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "1762      0      0      0      0      0      0      0  \n",
       "4603      0      0      0      0      0      0      0  \n",
       "6484      0      0      0      0      0      0      1  \n",
       "6950      1      0      0      0      0      0      0  \n",
       "4254      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(tiles_train.drop(['bins_numeric'], axis = 1), tiles_train['bins_numeric'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5971c10e-9c78-4cd5-bf77-a213f4e70ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>7123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>12171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td>1096</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tile_ID  Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  \\\n",
       "2732     2948         0.0                0.0       0.0                    0.0   \n",
       "630      2945         4.0                0.0       2.0                    1.0   \n",
       "2887     7123         1.0                0.0       0.0                    0.0   \n",
       "752     12171         0.0                0.0       2.0                    1.0   \n",
       "8106     1096         2.0                0.0       0.0                    0.0   \n",
       "\n",
       "      RTTYP_I  RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  ...  94129  94130  94131  \\\n",
       "2732        0        1        0        0        0  ...      0      0      0   \n",
       "630         0        1        0        0        0  ...      0      0      0   \n",
       "2887        0        1        0        0        0  ...      0      0      0   \n",
       "752         0        1        0        0        0  ...      0      0      0   \n",
       "8106        0        1        0        0        0  ...      0      0      0   \n",
       "\n",
       "      94132  94133  94134  94141  94143  94158  94188  \n",
       "2732      0      0      0      0      0      0      0  \n",
       "630       0      0      0      0      0      0      0  \n",
       "2887      0      0      0      0      0      0      0  \n",
       "752       0      0      0      0      0      0      0  \n",
       "8106      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18a322c-14fa-44a5-89ec-8b6ae7411008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "      <th>94101</th>\n",
       "      <th>...</th>\n",
       "      <th>94129</th>\n",
       "      <th>94130</th>\n",
       "      <th>94131</th>\n",
       "      <th>94132</th>\n",
       "      <th>94133</th>\n",
       "      <th>94134</th>\n",
       "      <th>94141</th>\n",
       "      <th>94143</th>\n",
       "      <th>94158</th>\n",
       "      <th>94188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stop_Signs  Paving_historical  Bus_stop  Collisions_Historical  RTTYP_I  \\\n",
       "0         0.0                0.0       0.0                    0.0        0   \n",
       "1         1.0                0.0       3.0                    6.0        0   \n",
       "2         0.0                0.0       0.0                    0.0        0   \n",
       "3         0.0                0.0       0.0                    0.0        0   \n",
       "4         0.0                0.0       0.0                    0.0        0   \n",
       "\n",
       "   RTTYP_M  RTTYP_O  RTTYP_S  RTTYP_U  94101  ...  94129  94130  94131  94132  \\\n",
       "0        1        0        0        0      0  ...      0      0      0      1   \n",
       "1        1        0        0        0      0  ...      0      0      0      0   \n",
       "2        1        0        0        0      0  ...      0      0      0      0   \n",
       "3        1        0        0        0      0  ...      0      1      0      0   \n",
       "4        1        0        0        0      0  ...      0      0      0      0   \n",
       "\n",
       "   94133  94134  94141  94143  94158  94188  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      1      0      0      0      0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_test = pd.read_csv(r'./Data/Tiles_TEST.csv')\n",
    "x_test = tiles_test.drop(['Tile_ID','bins_numeric'], axis = 1)\n",
    "y_test = tiles_test['bins_numeric']\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9298e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d8f77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 148, 188, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini = preprocess_data_part1(IMAGE_PATH)\n",
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e4bbbe-914b-47dd-9e82-93722404f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e1f01e-fc42-4bb8-9d18-e40fe8d215c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part15(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_val['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcfd6d0-bf6d-48b1-a404-00afbc2b9633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 148, 188, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_v = preprocess_data_part15(IMAGE_PATH)\n",
    "np.shape(images_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c499c7-9ec4-4f6c-8e9c-482de86f536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.drop(['Tile_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23790420-0c98-426f-8580-23f7d96e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "\n",
    "IMAGE_PATH = './Satellite Imagery/Satellite Images Tiled/' \n",
    "\n",
    "def preprocess_data_part2(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in tiles_test['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]/255\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8e3f65-2368-4092-9b09-ecda4e0a35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_mini_t = preprocess_data_part2(IMAGE_PATH)\n",
    "# np.shape(images_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "street = np.asarray(x_train).astype('float32')\n",
    "# street_mini = []\n",
    "# for row in range(len(street)):\n",
    "#     street_mini.append([[street[row]]])\n",
    "# street_mini = np.stack(street_mini)\n",
    "# np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c923520c-ed3c-4165-abd9-7b3cc932b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL SET \n",
    "\n",
    "street_v = np.asarray(x_val).astype('float32')\n",
    "# street_mini_v = []\n",
    "# for row in range(len(street_v)):\n",
    "#     street_mini_v.append([[street_v[row]]])\n",
    "# street_mini_v = np.stack(street_mini_v)\n",
    "# np.shape(street_mini_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c28b0428-174b-4e10-b151-1354cf44bf79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST SET \n",
    "\n",
    "# street_t = np.asarray(x_test).astype('float32')\n",
    "# street_mini_t = []\n",
    "# for row in range(len(street_t)):\n",
    "#     street_mini_t.append([[street_t[row]]])\n",
    "# street_mini_t = np.stack(street_mini_t)\n",
    "# np.shape(street_mini_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0dbb-2532-4c3a-b053-1f6f687be79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f8956",
   "metadata": {},
   "source": [
    "Helpful Links: <br>\n",
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/ <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 <br>\n",
    "https://github.com/jimmyyhwu/resnet18-tf2/blob/master/resnet.py <BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b3df3-7bf5-461b-ae34-6477dae4f045",
   "metadata": {},
   "source": [
    "**Model 2.5.0: Class Weights Corrected, Copying Paper, Pooling + 3 More Conv Layers, Normalized Pixels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "391fd79a-d6a9-4a8e-93a7-e097bc3a7abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ones\n",
      "bins      \n",
      "0     5297\n",
      "1      108\n",
      "2      968\n",
      "3      230\n",
      "4       22\n",
      "5        4\n",
      "6       53\n",
      "7       11\n",
      "8        3\n",
      "9        1\n",
      "10       3\n"
     ]
    }
   ],
   "source": [
    "check = pd.DataFrame({'bins': y_train, 'ones': np.ones(len(y_train))}, columns=['bins', 'ones'])\n",
    "pivot = check.pivot_table(index=['bins'], values=['ones'], aggfunc=len)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed845fbf-e8ef-42d1-9a7a-2ec469673a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.11498790052688486,\n",
       " 1: 5.63973063973064,\n",
       " 2: 0.6292261457550714,\n",
       " 3: 2.6482213438735176,\n",
       " 4: 27.68595041322314,\n",
       " 5: 152.27272727272728,\n",
       " 6: 11.492281303602057,\n",
       " 7: 55.37190082644628,\n",
       " 8: 203.03030303030303,\n",
       " 9: 609.0909090909091,\n",
       " 10: 203.03030303030303}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f3420cb-a963-4aa0-9acf-5553c257b1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 96, 96, 39)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_mini_2 = [] \n",
    "for k in range(len(street)):\n",
    "    for i in range(96): \n",
    "        for j in range(96):\n",
    "            street_mini_2.append(street[k])\n",
    "street_mini_2 = np.reshape(street_mini_2, (len(street),96,96,39))\n",
    "np.shape(street_mini_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e4dff01-abe6-453e-a2fc-1b68637537d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 96, 96, 39)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_mini_2_v = [] \n",
    "for k in range(len(street_v)):\n",
    "    for i in range(96): \n",
    "        for j in range(96):\n",
    "            street_mini_2_v.append(street_v[k])\n",
    "street_mini_2_v = np.reshape(street_mini_2_v, (len(street_v),96,96,39))\n",
    "np.shape(street_mini_2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0de1ee-0fcd-4f52-9045-907a1903fcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 00:50:02.274461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-26 00:50:02.274508: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-26 00:50:02.274539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-82-179): /proc/driver/nvidia/version does not exist\n",
      "2023-03-26 00:50:02.274810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu/capstone/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_Images (InputLayer)      [(None, 148, 188, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 146, 186, 6)  222         ['Input_Images[0][0]']           \n",
      "                                                                                                  \n",
      " Input_Street (InputLayer)      [(None, 96, 96, 39)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 94, 94, 6)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 94, 94, 2)    704         ['Input_Street[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 94, 94, 8)    0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 100, 100, 8)  0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 47, 47, 64)   25088       ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 47, 47, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " relu1 (ReLU)                   (None, 47, 47, 64)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " maxpool_pad (ZeroPadding2D)    (None, 49, 49, 64)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " maxpool (MaxPooling2D)         (None, 24, 24, 64)   0           ['maxpool_pad[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['maxpool[0][0]']                \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.0.conv1 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.0.bn1 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.0.relu1 (ReLU)          (None, 24, 24, 64)   0           ['layer1.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.0.conv2_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.0.conv2 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.0.bn2 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.0.add (Add)             (None, 24, 24, 64)   0           ['maxpool[0][0]',                \n",
      "                                                                  'layer1.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.0.relu2 (ReLU)          (None, 24, 24, 64)   0           ['layer1.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.1.conv1 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.1.bn1 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.1.relu1 (ReLU)          (None, 24, 24, 64)   0           ['layer1.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.conv2_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer1.1.conv2 (Conv2D)        (None, 24, 24, 64)   36864       ['layer1.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer1.1.bn2 (BatchNormalizati  (None, 24, 24, 64)  256         ['layer1.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer1.1.add (Add)             (None, 24, 24, 64)   0           ['layer1.0.relu2[0][0]',         \n",
      "                                                                  'layer1.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer1.1.relu2 (ReLU)          (None, 24, 24, 64)   0           ['layer1.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.conv1_pad (ZeroPaddin  (None, 26, 26, 64)  0           ['layer1.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.conv1 (Conv2D)        (None, 12, 12, 128)  73728       ['layer2.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.0.bn1 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/capstone/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer2.0.relu1 (ReLU)          (None, 12, 12, 128)  0           ['layer2.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.conv2_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.downsample.0 (Conv2D)  (None, 12, 12, 128)  8192       ['layer1.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer2.0.conv2 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.0.downsample.1 (BatchNo  (None, 12, 12, 128)  512        ['layer2.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer2.0.bn2 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.0.add (Add)             (None, 12, 12, 128)  0           ['layer2.0.downsample.1[0][0]',  \n",
      "                                                                  'layer2.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.0.relu2 (ReLU)          (None, 12, 12, 128)  0           ['layer2.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.conv1_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.1.conv1 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.1.bn1 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.1.relu1 (ReLU)          (None, 12, 12, 128)  0           ['layer2.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.conv2_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.1.conv2 (Conv2D)        (None, 12, 12, 128)  147456      ['layer2.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer2.1.bn2 (BatchNormalizati  (None, 12, 12, 128)  512        ['layer2.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer2.1.add (Add)             (None, 12, 12, 128)  0           ['layer2.0.relu2[0][0]',         \n",
      "                                                                  'layer2.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer2.1.relu2 (ReLU)          (None, 12, 12, 128)  0           ['layer2.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.conv1_pad (ZeroPaddin  (None, 14, 14, 128)  0          ['layer2.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.conv1 (Conv2D)        (None, 6, 6, 256)    294912      ['layer3.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.0.bn1 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.0.relu1 (ReLU)          (None, 6, 6, 256)    0           ['layer3.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.conv2_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.downsample.0 (Conv2D)  (None, 6, 6, 256)   32768       ['layer2.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer3.0.conv2 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.0.downsample.1 (BatchNo  (None, 6, 6, 256)   1024        ['layer3.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer3.0.bn2 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.0.add (Add)             (None, 6, 6, 256)    0           ['layer3.0.downsample.1[0][0]',  \n",
      "                                                                  'layer3.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.0.relu2 (ReLU)          (None, 6, 6, 256)    0           ['layer3.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.conv1_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.1.conv1 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.1.bn1 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.1.relu1 (ReLU)          (None, 6, 6, 256)    0           ['layer3.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.conv2_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.1.conv2 (Conv2D)        (None, 6, 6, 256)    589824      ['layer3.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer3.1.bn2 (BatchNormalizati  (None, 6, 6, 256)   1024        ['layer3.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer3.1.add (Add)             (None, 6, 6, 256)    0           ['layer3.0.relu2[0][0]',         \n",
      "                                                                  'layer3.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer3.1.relu2 (ReLU)          (None, 6, 6, 256)    0           ['layer3.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.conv1_pad (ZeroPaddin  (None, 8, 8, 256)   0           ['layer3.1.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.0.conv1 (Conv2D)        (None, 3, 3, 512)    1179648     ['layer4.0.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.0.bn1 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.0.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.0.relu1 (ReLU)          (None, 3, 3, 512)    0           ['layer4.0.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.conv2_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.0.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.0.downsample.0 (Conv2D)  (None, 3, 3, 512)   131072      ['layer3.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " layer4.0.conv2 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.0.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.0.downsample.1 (BatchNo  (None, 3, 3, 512)   2048        ['layer4.0.downsample.0[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer4.0.bn2 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.0.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.0.add (Add)             (None, 3, 3, 512)    0           ['layer4.0.downsample.1[0][0]',  \n",
      "                                                                  'layer4.0.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.0.relu2 (ReLU)          (None, 3, 3, 512)    0           ['layer4.0.add[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.conv1_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.0.relu2[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.1.conv1 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.1.conv1_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.1.bn1 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.1.conv1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.1.relu1 (ReLU)          (None, 3, 3, 512)    0           ['layer4.1.bn1[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.conv2_pad (ZeroPaddin  (None, 5, 5, 512)   0           ['layer4.1.relu1[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer4.1.conv2 (Conv2D)        (None, 3, 3, 512)    2359296     ['layer4.1.conv2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " layer4.1.bn2 (BatchNormalizati  (None, 3, 3, 512)   2048        ['layer4.1.conv2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " layer4.1.add (Add)             (None, 3, 3, 512)    0           ['layer4.0.relu2[0][0]',         \n",
      "                                                                  'layer4.1.bn2[0][0]']           \n",
      "                                                                                                  \n",
      " layer4.1.relu2 (ReLU)          (None, 3, 3, 512)    0           ['layer4.1.add[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 24, 24, 128)  0           ['layer2.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 24, 24, 256)  0          ['layer3.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 24, 24, 512)  0          ['layer4.1.relu2[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 24, 24, 960)  0           ['layer1.1.relu2[0][0]',         \n",
      "                                                                  'up_sampling2d[0][0]',          \n",
      "                                                                  'up_sampling2d_1[0][0]',        \n",
      "                                                                  'up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 22, 22, 960)  8295360     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 20, 20, 960)  8295360     ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 18, 18, 2)    17282       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 648)          0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 11)           7139        ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,817,859\n",
      "Trainable params: 27,808,259\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 00:50:03.505110: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2982732800 exceeds 10% of free system memory.\n",
      "2023-03-26 00:50:05.699830: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 9632563200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/ubuntu/capstone/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "  5/210 [..............................] - ETA: 32:59 - loss: 0.9151 - accuracy: 0.6812 - precision: 0.0000e+00 - f1: 0.0950    "
     ]
    }
   ],
   "source": [
    "# From previous experiments, adding layers and using ResNet-18 yielded best results \n",
    "\n",
    "# x: Satellite Images, 'Stop_Signs', 'Paving_historical', 'Bus_stop', 'Collisions_Historical', Road type (one hot), Zipcode (ont hot)\n",
    "# y: Future collision bin\n",
    "\n",
    "# ACCORDING TO THE PAPER, THEY DOWNSIZED THE IMAGES FIRST INTO SMALLER MATRICES \n",
    "# THEN ADDED THE STREET CHARACTERISTICS TO THE SMALLER MATRIX\n",
    "# REFERENCE THE DIAGRAM ON THE PAPER\n",
    "\n",
    "def create_cnn_model4():\n",
    "\n",
    "    # INPUT LAYERS\n",
    "    input1 = tf.keras.layers.Input(shape=(148, 188, 4), name='Input_Images')\n",
    "    input2 = tf.keras.layers.Input(shape=(96,96,39), name='Input_Street') \n",
    "    \n",
    "    #CNN FOR IMAGE PROCESSING\n",
    "    cnn = tf.keras.layers.Conv2D(6, (3,3), activation=\"relu\")(input1) # layers = street data dimension, changed dimensions to be according to paper\n",
    "    pooling = tf.keras.layers.MaxPooling2D((53, 93), strides=1)(cnn) #downsizing, per paper\n",
    "    images = tf.keras.models.Model(inputs=input1, outputs=pooling)\n",
    "    \n",
    "    #ADDING STREET DATA\n",
    "    cnn2 = tf.keras.layers.Conv2D(2, (3,3), activation=\"relu\")(input2)\n",
    "    street = tf.keras.models.Model(inputs=input2, outputs=cnn2)\n",
    "    \n",
    "    combined = tf.keras.layers.Concatenate(axis = 3)([images.output, street.output])\n",
    "    #combined = tf.keras.layers.Add()([images.output, street.output])\n",
    "    \n",
    "    # PAPER USES RESNET-18 FOR THE REST OF THE MODEL WITH THE COMBINED DATA\n",
    "    resnet1, resnet2, resnet3, resnet4 = resnet18(combined, num_classes = 11)\n",
    "    \n",
    "    resnet2 = tf.keras.layers.UpSampling2D(size=(2,2))(resnet2) # added this per paper\n",
    "    resnet3 = tf.keras.layers.UpSampling2D(size=(4,4))(resnet3) # added this per paper\n",
    "    resnet4 = tf.keras.layers.UpSampling2D(size=(8,8))(resnet4) # added this per paper\n",
    "    \n",
    "    resnet = tf.keras.layers.Concatenate(axis = 3)([resnet1, resnet2, resnet3, resnet4]) # added this per paper\n",
    "    \n",
    "    cnn = tf.keras.layers.Conv2D(960, (3,3), activation=\"relu\")(resnet) # added cnn, per paper\n",
    "    cnn = tf.keras.layers.Conv2D(960, (3,3), activation=\"relu\")(cnn) # added cnn, per paper\n",
    "    cnn = tf.keras.layers.Conv2D(2, (3,3), activation=\"relu\")(cnn) # added cnn, per paper\n",
    "    \n",
    "    shape = tf.reshape(cnn, [-1,648], name=\"reshape\")\n",
    "    \n",
    "    output = tf.keras.layers.Dense(units=11, activation='softmax', name='output')(shape) # units = number of classes\n",
    "    \n",
    "    #instantiation layer \n",
    "    cnn_model = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "cnn_model4 = create_cnn_model4()\n",
    "\n",
    "cnn_model4.summary()\n",
    "\n",
    "f1 = tfa.metrics.F1Score(\n",
    "    num_classes = 11,\n",
    "    average = 'macro',\n",
    "    threshold = None,\n",
    "    name = 'f1',\n",
    "    )\n",
    "\n",
    "cnn_model4.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy', keras.metrics.Precision(), f1])\n",
    "\n",
    "# calculated in previous block \n",
    "# class_weight = {0: 1,\n",
    "#                 1: 10,\n",
    "#                 2: 10,\n",
    "#                 3: 10,\n",
    "#                 4: 10,\n",
    "#                 5: 10,\n",
    "#                 6: 10,\n",
    "#                 7: 10,\n",
    "#                 8: 10,\n",
    "#                 9: 10,\n",
    "#                 10: 10,\n",
    "#                 # 11: 10,\n",
    "#                }\n",
    "\n",
    "y_t = tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
    "\n",
    "y_v = tf.keras.utils.to_categorical(y_val, num_classes=11)\n",
    "\n",
    "#cnn_model1.load_weights(initial_weights) # initial weights from first or baseline model to make it comparable\n",
    "#cnn_model4.layers[-1].bias.assign([0,0,0,0,0,0,0,0,0,0,0]) # no bias, makes it more comparable to baseline model\n",
    "\n",
    "history = cnn_model4.fit(\n",
    "    [images_mini, street_mini_2],\n",
    "    y_t,\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "     verbose=1,\n",
    "    validation_data=([images_mini_v, street_mini_2_v], y_v),\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    #validation_split = 0.2,\n",
    "    class_weight = class_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed0337-c274-417d-91b7-470a18511886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3374f-0443-4fac-aade-026879e89c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3119f-65af-4ca2-af67-a9eb0049254f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_f1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36ab92-86da-4028-8a3e-7104fb7345db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = cnn_model4.predict([images_mini_v, street_mini_2_v])\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a016b7b-f9d7-4403-b3cf-9882ce9f153e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_values2 = []\n",
    "for i in y_pred2: \n",
    "    input_list = i\n",
    "    max_value = max(input_list)\n",
    "    index = [index for index, item in enumerate(input_list) if item == max_value]\n",
    "    pred_values2.append(index[0])\n",
    "pred_values2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0d0d7-f2ad-4d0f-995b-bf144261b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_val)\n",
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c2971-d768-46c5-b8db-3d3a905c603f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, pred_values2)\n",
    "ind = max(len(np.unique(y_true)), len(np.unique(pred_values2)))\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in range(ind)],\n",
    "                  columns = [i for i in range(ind)])\n",
    "df_cm\n",
    "#plt.figure(figsize = (10,7))\n",
    "#sn.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
