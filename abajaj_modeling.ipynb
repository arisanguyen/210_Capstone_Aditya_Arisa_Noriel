{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356025b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 04:16:57.281437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 04:16:58.229794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-03-13 04:16:58.229945: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-03-13 04:16:58.229957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow_addons as tfa\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "import tifffile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe8314a-60a7-4de8-be72-620b659ef79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install numpy tensorflow matplotlib scipy\n",
    "# # !pip install pandas\n",
    "# !pip install tifffile\n",
    "# !pip install scikit-learn\n",
    "# !pip install imagecodecs\n",
    "# !pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb10982-72ec-439c-9c1a-6c182803eb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "   # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "   # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, \n",
    "            max(\n",
    "                max(history.history['loss']),\n",
    "                max(history.history['val_loss'])\n",
    "            )])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3693092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles = pd.read_csv(r'Data/Tiles_expanded.csv')\n",
    "tiles_expanded_rv = pd.read_csv(r'Data/Tiles_expanded_road_vector.csv').drop(['Unnamed: 0'],axis=1)\n",
    "tiles_expanded_rv = pd.get_dummies(tiles_expanded_rv, columns = ['RTTYP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e5ddd8-bf87-4021-8274-ee55f64b54a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tile_ID</th>\n",
       "      <th>Long2</th>\n",
       "      <th>Lat2</th>\n",
       "      <th>Long1</th>\n",
       "      <th>Lat1</th>\n",
       "      <th>Mid_lat</th>\n",
       "      <th>Mid_long</th>\n",
       "      <th>Stop_Signs</th>\n",
       "      <th>Paving_historical</th>\n",
       "      <th>Paving_future</th>\n",
       "      <th>Bus_stop</th>\n",
       "      <th>Collisions_Future</th>\n",
       "      <th>Collisions_Historical</th>\n",
       "      <th>RTTYP_I</th>\n",
       "      <th>RTTYP_M</th>\n",
       "      <th>RTTYP_O</th>\n",
       "      <th>RTTYP_S</th>\n",
       "      <th>RTTYP_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>-122.514446</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.513876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.779636</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>37.779184</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.778732</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>37.778280</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-122.513306</td>\n",
       "      <td>37.777829</td>\n",
       "      <td>-122.512166</td>\n",
       "      <td>37.776925</td>\n",
       "      <td>37.777377</td>\n",
       "      <td>-122.512736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tile_ID       Long2       Lat2       Long1       Lat1    Mid_lat  \\\n",
       "0       36 -122.514446  37.779636 -122.513306  37.778732  37.779184   \n",
       "1       37 -122.514446  37.778732 -122.513306  37.777829  37.778280   \n",
       "2      151 -122.513306  37.779636 -122.512166  37.778732  37.779184   \n",
       "3      152 -122.513306  37.778732 -122.512166  37.777829  37.778280   \n",
       "4      153 -122.513306  37.777829 -122.512166  37.776925  37.777377   \n",
       "\n",
       "     Mid_long  Stop_Signs  Paving_historical  Paving_future  Bus_stop  \\\n",
       "0 -122.513876         0.0                0.0            0.0       0.0   \n",
       "1 -122.513876         0.0                0.0            0.0       0.0   \n",
       "2 -122.512736         0.0                0.0            0.0       0.0   \n",
       "3 -122.512736         0.0                0.0            0.0       0.0   \n",
       "4 -122.512736         0.0                0.0            0.0       0.0   \n",
       "\n",
       "   Collisions_Future  Collisions_Historical  RTTYP_I  RTTYP_M  RTTYP_O  \\\n",
       "0                0.0                    0.0        0        1        0   \n",
       "1                0.0                    0.0        0        1        0   \n",
       "2                0.0                    0.0        0        1        0   \n",
       "3                0.0                    0.0        0        1        0   \n",
       "4                0.0                    0.0        0        1        0   \n",
       "\n",
       "   RTTYP_S  RTTYP_U  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        0        0  \n",
       "4        0        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_expanded_rv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02cf6af-4d7f-4cbe-91f0-6a33a0ba3c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiles_expanded_rv['Collisions_Future_binary']=tiles_expanded_rv['Collisions_Future'].apply(lambda x: 1 if x > 0 else 0)\n",
    "tiles_expanded_rv['Collisions_Historical_binary']=tiles_expanded_rv['Collisions_Historical'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f22a15-184e-466c-8edd-448bd974f88d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2d6b89-b6a3-4465-ac2b-be220741cea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_col(df, col_name):\n",
    "\n",
    "    norm = (df[col_name] - df[col_name].min()) / (df[col_name].max() - df[col_name].min())\n",
    "    return norm\n",
    "\n",
    "tiles_expanded_rv['Mid_lat_norm'] = normalize_col(tiles_expanded_rv,'Mid_lat')\n",
    "tiles_expanded_rv['Mid_long_norm'] = normalize_col(tiles_expanded_rv,'Mid_long')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6b82c",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d50fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='logistic' # 'linear'\n",
    "\n",
    "if MODEL_TYPE == 'linear':\n",
    "    input_x = ['Tile_ID','Collisions_Historical', 'Mid_lat_norm','Mid_long_norm', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U']\n",
    "    input_y = tiles_expanded_rv['Collisions_Future']\n",
    "elif MODEL_TYPE == 'logistic':\n",
    "    input_x = ['Tile_ID','Collisions_Historical_binary', 'Mid_lat_norm','Mid_long_norm', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U']\n",
    "    input_y = ['Collisions_Future_binary']\n",
    "    \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                    tiles_expanded_rv[input_x], \n",
    "                                    tiles_expanded_rv[input_y],\n",
    "                                    random_state=104, \n",
    "                                    test_size=0.20, \n",
    "                                    shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8765668b-0c61-4d60-8ee0-3c7dbeaf1d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.asarray(x_train[['Collisions_Historical', 'Mid_lat_norm','Mid_long_norm', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U']]).astype('float32').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe2d02",
   "metadata": {},
   "source": [
    "Model #1: Linear regression using Historical Collisions, SFMTA Street Characteristics, and Geocoordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf220283",
   "metadata": {},
   "source": [
    "## Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea514649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'Satellite_Imagery/Satellite_Images_Tiled/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b40c2ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " #eda\n",
    "img = tifffile.imread('Satellite_Imagery/Satellite_Images_Tiled/36.tif')[0:148, 0:188, :]\n",
    "img2 = tifffile.imread('Satellite_Imagery/Satellite_Images_Tiled/37.tif')[0:148, 0:188, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97889d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 188, 4)\n"
     ]
    }
   ],
   "source": [
    "# eda\n",
    "print(np.shape(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545c8609",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 148, 188, 4)\n",
      "(2, 148, 188, 4)\n"
     ]
    }
   ],
   "source": [
    "# eda\n",
    "test = []\n",
    "test.append(img[0:148, 0:188, :])\n",
    "test.append(img2[0:148, 0:188, :])\n",
    "print(np.shape(test))\n",
    "test = np.stack(test)\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9298e629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data_part1(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 149 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    data_mini = []\n",
    "    \n",
    "    for id in x_train['Tile_ID']:    \n",
    "                    \n",
    "        # read image and store as matrix            \n",
    "        # Index at the end makes all images the same size (they sometimes differ by 1 pixel)\n",
    "        image = tifffile.imread(IMAGE_PATH + str(id) + '.tif')[0:148, 0:188, :]\n",
    "            \n",
    "        # append to images\n",
    "        data_mini.append(image)\n",
    " \n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(data_mini)\n",
    "    \n",
    "    return images_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8f77ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THERE IS ONE FILE IN THE \"SATELLITE IMAGES TILED\" FOLDER THAT IS NOT A TIF IMAGE, DELETE THIS FILE\n",
    "images_mini = preprocess_data_part1(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ce10975",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 148, 188, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0080b62b-712f-4179-9031-60b561f59b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_mini_reshaped = images_mini.reshape((8376,1,1,111296))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fce941b-4766-474c-b49e-c365de2bdb86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_mini_reshaped.shape\n",
    "# len(images_mini_reshaped[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135842",
   "metadata": {},
   "source": [
    "Street Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dce0686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 1, 1, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street = np.asarray(x_train[input_x[1:]]).astype('float32')\n",
    "street_mini = []\n",
    "for row in street:\n",
    "    street_mini.append([[row]])\n",
    "street_mini = np.stack(street_mini)\n",
    "np.shape(street_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b9f21e-6f7b-4abd-a7de-917d89fa085a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_street = np.hstack(\n",
    "    (street_mini.reshape((8376,11)),\n",
    "     images_mini.reshape(8376,111296))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2a63cdc-90cd-43e2-94f1-d819918c510b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_image_street = input_image_street.reshape((8376,1,1, 111307))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1270fa6f-aec7-4486-b0fb-c1edb73c43ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8376, 111307)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image_street.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9176acd-0672-4bd9-92c8-f67618b33321",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04589b85-dbc4-4309-a243-608fb7f793e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x: 'Collisions_Historical', 'Mid_lat','Mid_long', 'Stop_Signs', 'Paving_historical', 'Bus_stop','RTTYP_I','RTTYP_M','RTTYP_O','RTTYP_S','RTTYP_U'\n",
    "# y: 'Collisions_Future'\n",
    "\n",
    "def create_linear_model():\n",
    "    # DENSE LAYERS \n",
    "    input = tf.keras.layers.Input(shape=(111307,))\n",
    "\n",
    "    outputs = layers.Dense(1)(input)\n",
    "\n",
    "    linear_model = tf.keras.models.Model(inputs=input, outputs=outputs, name=\"linear_model\")\n",
    "\n",
    "    linear_model.summary()\n",
    "\n",
    "    linear_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "        )\n",
    "    \n",
    "    return linear_model\n",
    "\n",
    "# linear_model = create_linear_model()\n",
    "\n",
    "# history = linear_model.fit(\n",
    "#     input_image_street,\n",
    "#      np.stack(y_train),\n",
    "#     epochs=100,\n",
    "#     # Suppress logging.\n",
    "#      verbose=1,\n",
    "#     # Calculate validation results on 20% of the training data.\n",
    "#     validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aab7b35b-71ff-4966-b602-45bb0e4bc6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76293faa-4ad4-4467-adcf-75a6e9c9cfb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LOGISTIC MODEL WITH IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77720819-1254-4495-a662-aec9445e4fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def log_loss(y_pred, y):\n",
    "#   # Compute the log loss function\n",
    "#   ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_pred)\n",
    "#   return tf.reduce_mean(ce)\n",
    "\n",
    "# class LogisticRegression(tf.Module):\n",
    "\n",
    "#   def __init__(self):\n",
    "#     self.built = False\n",
    "\n",
    "#   def __call__(self, x, train=True):\n",
    "#     # Initialize the model parameters on the first call\n",
    "#     if not self.built:\n",
    "#       # Randomly generate the weights and the bias term\n",
    "#       rand_w = tf.random.uniform(shape=[x.shape[-1], 1], seed=22)\n",
    "#       rand_b = tf.random.uniform(shape=[], seed=22)\n",
    "#       self.w = tf.Variable(rand_w)\n",
    "#       self.b = tf.Variable(rand_b)\n",
    "#       self.built = True\n",
    "#     # Compute the model output\n",
    "#     z = tf.add(tf.matmul(x, self.w), self.b)\n",
    "#     z = tf.squeeze(z, axis=1)\n",
    "#     if train:\n",
    "#       return z\n",
    "#     return tf.sigmoid(z)\n",
    "\n",
    "# log_reg = LogisticRegression()\n",
    "\n",
    "# def predict_class(y_pred, thresh=0.5):\n",
    "#   # Return a tensor with  `1` if `y_pred` > `0.5`, and `0` otherwise\n",
    "#   return tf.cast(y_pred > thresh, tf.float32)\n",
    "\n",
    "# def accuracy(y_pred, y):\n",
    "#   # Return the proportion of matches between `y_pred` and `y`\n",
    "#   y_pred = tf.math.sigmoid(y_pred)\n",
    "#   y_pred_class = predict_class(y_pred)\n",
    "#   check_equal = tf.cast(y_pred_class == y,tf.float32)\n",
    "#   acc_val = tf.reduce_mean(check_equal)\n",
    "#   return acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e09bb67-ac68-494f-a221-9f1d0b784100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = log_reg(input_image_street[0:5], train=False)\n",
    "# y_pred.numpy()\n",
    "# # input_image_street.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53774f86-e884-40e7-a4c6-59eabad1eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Our vectorized labels\n",
    "# y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "# # y_test = np.asarray(test_labels).astype('float32').reshape((-1,1))\n",
    "# batch_size = 2 #  64\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((input_image_street, y_train))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=input_image_street.shape[0]).batch(batch_size)\n",
    "# # test_dataset = tf.data.Dataset.from_tensor_slices((input_image_street, y_test))\n",
    "# # test_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b33bdbd9-903e-4451-b3ec-077006b455a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9a02d3-2f19-4d49-af7f-0cbea330465b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set training parameters\n",
    "# epochs = 3 # 200\n",
    "# learning_rate = 0.01\n",
    "# train_losses, test_losses = [], []\n",
    "# train_accs, test_accs = [], []\n",
    "\n",
    "# # Set up the training loop and begin training\n",
    "# for epoch in range(epochs):\n",
    "#   batch_losses_train, batch_accs_train = [], []\n",
    "#   batch_losses_test, batch_accs_test = [], []\n",
    "\n",
    "#   # Iterate over the training data\n",
    "#   for x_batch, y_batch in train_dataset:\n",
    "#     with tf.GradientTape() as tape:\n",
    "#       y_pred_batch = log_reg(x_batch)\n",
    "#       # print(f'y_pred_batch: {y_pred_batch.numpy().reshape((2,1)).shape}')\n",
    "#       print(f'y_batch: {y_batch.shape}')\n",
    "#       y_pred_batch = y_pred_batch.numpy().reshape((2,1))\n",
    "#       batch_loss = log_loss(y_pred_batch, y_batch)\n",
    "#     batch_acc = accuracy(y_pred_batch, y_batch)\n",
    "#     # Update the parameters with respect to the gradient calculations\n",
    "#     grads = tape.gradient(batch_loss, log_reg.variables)\n",
    "#     for g,v in zip(grads, log_reg.variables):\n",
    "#       print(g,v)  \n",
    "#       v.assign_sub(learning_rate * g)\n",
    "#     # Keep track of batch-level training performance\n",
    "#     batch_losses_train.append(batch_loss)\n",
    "#     batch_accs_train.append(batch_acc)\n",
    "\n",
    "#   # Iterate over the testing data\n",
    "#   for x_batch, y_batch in test_dataset:\n",
    "#     y_pred_batch = log_reg(x_batch)\n",
    "#     batch_loss = log_loss(y_pred_batch, y_batch)\n",
    "#     batch_acc = accuracy(y_pred_batch, y_batch)\n",
    "#     # Keep track of batch-level testing performance\n",
    "#     batch_losses_test.append(batch_loss)\n",
    "#     batch_accs_test.append(batch_acc)\n",
    "\n",
    "#   # Keep track of epoch-level model performance\n",
    "#   train_loss, train_acc = tf.reduce_mean(batch_losses_train), tf.reduce_mean(batch_accs_train)\n",
    "#   test_loss, test_acc = tf.reduce_mean(batch_losses_test), tf.reduce_mean(batch_accs_test)\n",
    "#   train_losses.append(train_loss)\n",
    "#   train_accs.append(train_acc)\n",
    "#   test_losses.append(test_loss)\n",
    "#   test_accs.append(test_acc)\n",
    "#   if epoch % 20 == 0:\n",
    "#     print(f\"Epoch: {epoch}, Training log loss: {train_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc0d5ace-613d-4a4f-9d7b-f7cc8bedf507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression(random_state=0,max_iter=1000).fit(input_image_street, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d59d1f10-ef4f-4c0e-8ec9-6c9e453d88c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 04:17:51.621443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:51.628037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:51.628277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:51.628798: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 04:17:51.629775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:51.630003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:51.630208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:52.113903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:52.114172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:52.114388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-13 04:17:52.114556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6703 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 04:17:59.434755: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fdbc40029f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-13 04:17:59.434805: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2\n",
      "2023-03-13 04:17:59.440973: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-13 04:17:59.573107: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 3s 6ms/step - loss: 2620.0410 - accuracy: 0.6652\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2228.5356 - accuracy: 0.6843\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2284.6404 - accuracy: 0.6771\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2228.3333 - accuracy: 0.6889\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2176.4548 - accuracy: 0.6910\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 2150.1602 - accuracy: 0.6973\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2131.2012 - accuracy: 0.6962\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2052.5291 - accuracy: 0.7028\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 2061.6191 - accuracy: 0.7016\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 2011.0575 - accuracy: 0.7045\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 2018.1084 - accuracy: 0.7043\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1986.4353 - accuracy: 0.7064\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1953.9292 - accuracy: 0.7138\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1942.1749 - accuracy: 0.7114\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1930.3739 - accuracy: 0.7126\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1899.9149 - accuracy: 0.7154\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1866.0991 - accuracy: 0.7217\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1898.1802 - accuracy: 0.7172\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1853.2505 - accuracy: 0.7179\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1822.5509 - accuracy: 0.7203\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1791.5043 - accuracy: 0.7265\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1845.6317 - accuracy: 0.7197\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1766.3826 - accuracy: 0.7233\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1711.4884 - accuracy: 0.7362\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1749.2212 - accuracy: 0.7311\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1748.9344 - accuracy: 0.7333\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1721.4991 - accuracy: 0.7307\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1663.2849 - accuracy: 0.7364\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1743.9423 - accuracy: 0.7285\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1713.8785 - accuracy: 0.7364\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1688.2025 - accuracy: 0.7322\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1662.8285 - accuracy: 0.7387\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1655.2391 - accuracy: 0.7360\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1698.4604 - accuracy: 0.7332\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1590.0503 - accuracy: 0.7457\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1564.0123 - accuracy: 0.7487\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1577.3148 - accuracy: 0.7507\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1536.1428 - accuracy: 0.7530\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1516.4089 - accuracy: 0.7590\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1594.9503 - accuracy: 0.7471\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1468.5477 - accuracy: 0.7612\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1569.9393 - accuracy: 0.7464\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1509.3265 - accuracy: 0.7544\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1444.3754 - accuracy: 0.7670\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1476.5093 - accuracy: 0.7659\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1482.9066 - accuracy: 0.7562\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1466.7255 - accuracy: 0.7619\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1449.8300 - accuracy: 0.7576\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 1479.0990 - accuracy: 0.7518\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 1s 6ms/step - loss: 1484.6367 - accuracy: 0.7486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde78463970>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='bce', metrics=['accuracy'])\n",
    "model.fit(input_image_street, y_train['Collisions_Future_binary'].to_numpy(), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efb0a602-4759-4458-9ea4-8dfc68c9ca10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "559b1638-8204-4a71-959b-b15328b6956a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_SCALAR_UPRANKING_ON',\n",
       " '_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_trackable',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_auto_get_config',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_autographed_call',\n",
       " '_base_model_initialized',\n",
       " '_build_graph_network_for_inferred_shape',\n",
       " '_build_input_shape',\n",
       " '_call_spec',\n",
       " '_callable_losses',\n",
       " '_captured_weight_regularizer',\n",
       " '_cast_single_input',\n",
       " '_check_call_args',\n",
       " '_check_sample_weight_warning',\n",
       " '_checkpoint',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_cluster_coordinator',\n",
       " '_compile_config',\n",
       " '_compile_from_config',\n",
       " '_compile_was_called',\n",
       " '_compiled_trainable_state',\n",
       " '_compute_dtype',\n",
       " '_compute_dtype_object',\n",
       " '_compute_output_and_mask_jointly',\n",
       " '_compute_tensor_usage_count',\n",
       " '_configure_steps_per_execution',\n",
       " '_conform_to_reference_input',\n",
       " '_created_nodes',\n",
       " '_dedup_weights',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_distribute_reduction_method',\n",
       " '_distribution_strategy',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_losses',\n",
       " '_enable_dict_to_input_mapping',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_export_to_saved_model_graph',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_flatten_modules',\n",
       " '_flatten_to_reference_inputs',\n",
       " '_functional_construction_call',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_callback_model',\n",
       " '_get_cell_name',\n",
       " '_get_compile_args',\n",
       " '_get_existing_metric',\n",
       " '_get_input_masks',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_optimizer',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_get_unnested_name_scope',\n",
       " '_graph_initialized',\n",
       " '_graph_network_add_loss',\n",
       " '_graph_network_add_metric',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_deferred_layer_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_has_explicit_input_shape',\n",
       " '_in_multi_worker_mode',\n",
       " '_inbound_nodes',\n",
       " '_inbound_nodes_value',\n",
       " '_infer_output_signature',\n",
       " '_inferred_input_shape',\n",
       " '_init_batch_counters',\n",
       " '_init_call_fn_args',\n",
       " '_init_graph_network',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_coordinates',\n",
       " '_input_dtype',\n",
       " '_input_layers',\n",
       " '_input_spec',\n",
       " '_insert_layers',\n",
       " '_instrument_layer_creation',\n",
       " '_instrumented_keras_api',\n",
       " '_instrumented_keras_layer_class',\n",
       " '_instrumented_keras_model_class',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_is_layer',\n",
       " '_is_layer_name_unique',\n",
       " '_is_model_for_instrumentation',\n",
       " '_jit_compile',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_layer_call_argspecs',\n",
       " '_layer_checkpoint_dependencies',\n",
       " '_layout_map',\n",
       " '_load_own_variables',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_map_resources',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_counters_from_ckpt',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_must_restore_from_config',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_name_scope_on_declaration',\n",
       " '_nested_inputs',\n",
       " '_nested_outputs',\n",
       " '_network_nodes',\n",
       " '_no_dependency',\n",
       " '_nodes_by_depth',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_outbound_nodes_value',\n",
       " '_output_coordinates',\n",
       " '_output_layers',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_predict_counter',\n",
       " '_preload_simple_restoration',\n",
       " '_preserve_input_structure_in_config',\n",
       " '_reset_compile_cache',\n",
       " '_restore_from_tensors',\n",
       " '_run_eagerly',\n",
       " '_run_internal_graph',\n",
       " '_save_experimental',\n",
       " '_save_own_variables',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_tracked_trackables',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_inputs',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_output_names',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_should_compute_mask',\n",
       " '_should_eval',\n",
       " '_stateful',\n",
       " '_steps_per_execution',\n",
       " '_supports_masking',\n",
       " '_tensor_usage_count',\n",
       " '_test_counter',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_track_variable',\n",
       " '_track_variables',\n",
       " '_trackable_children',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_train_counter',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_training_state',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_undeduplicated_weights',\n",
       " '_update_trackables',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " '_use_input_spec_as_call_signature',\n",
       " '_use_legacy_deferred_behavior',\n",
       " '_validate_and_get_metrics_result',\n",
       " '_validate_compile',\n",
       " '_validate_graph_inputs_and_outputs',\n",
       " '_validate_target_and_loss',\n",
       " 'activity_regularizer',\n",
       " 'add',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compiled_loss',\n",
       " 'compiled_metrics',\n",
       " 'compute_dtype',\n",
       " 'compute_loss',\n",
       " 'compute_mask',\n",
       " 'compute_metrics',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'distribute_reduction_method',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dynamic',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'finalize_state',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_metrics_result',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_weight_paths',\n",
       " 'get_weights',\n",
       " 'history',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'losses',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'pop',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'run_eagerly',\n",
       " 'save',\n",
       " 'save_spec',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stop_training',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'train_tf_function',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8bf16-2c15-401e-8a5f-bff877aaa7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
